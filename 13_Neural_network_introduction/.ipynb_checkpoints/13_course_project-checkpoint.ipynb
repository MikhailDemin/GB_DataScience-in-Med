{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWcUWSWpt0Rl"
   },
   "source": [
    "# Практическое задание к курсу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7FBavh7yj77"
   },
   "source": [
    "### <span class=\"burk\">Задание 1.</span>\n",
    "**Обучите нейронную сеть любой архитектуры, которой не было на курсе, либо нейронную\n",
    "сеть разобранной архитектуры, но на том датасете, которого не было на уроках. Сделайте\n",
    "анализ того, что вам помогло в улучшения работы нейронной сети.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UY3IVQhZyj8E"
   },
   "source": [
    "### <span class=\"burk\">Задание 2.</span>\n",
    "**Сделайте краткий обзор научной работы, посвящённой алгоритму нейронных сетей, не рассматриваемому ранее на курсе.**\n",
    "\n",
    "Проведите анализ: \n",
    " - чем отличается выбранная архитектура от других?\n",
    " - в чём плюсы и минусы данной архитектуры?\n",
    " - какие могут возникнуть трудности при её применении на практике?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SpineNet** — это backbone нейросетевая архитектура для задачи распознавания объекта. Разработкой модели занимались исследователи из Google Research. Модель обходит state-of-the-art подходы на задаче распознавания объектов на данных COCO. При этом SpineNet производит на 60% меньше вычислений и обходит ResNet-FPN на 6% по AP. Предложенную архитектуру также используют для классификации. SpineNet обходит state-of-the-art на 6% в точности на датасете iNaturalist.\n",
    "\n",
    " * Обычно backbone характеризует сеть с уменьшающимся масштабом в архитектуре “энкодер-декодер”, т.е. энкодер. \n",
    " * Поскольку задача энкодера состоит в вычислении представлений признаков на основе вводных данных, backbone с уменьшающимся масштабом не сможет удерживать пространственную информацию. \n",
    " * По мере углубления слоёв признаки будут становиться всё более абстрактными и менее локализованными, тем самым усложняя извлечение декодером точных необходимых признаков. \n",
    "\n",
    "С целью преодоления сложности получения и извлечения многомасштабных признаков для локализации была представлена модель с пермутируемыми масштабами и межмасштабными связями, предлагающая следующие улучшения:\n",
    "\n",
    "1. Масштабы карт признаков в этой архитектуре получили возможность увеличения или уменьшения в любой момент времени посредством пермутации блоков, что противоположно прежнему шаблону, подразумевавшему только уменьшение. Это позволило сохранять пространственную информацию. \n",
    "2. Связям карт признаков разрешено пересекать масштабы признаков для выполнения слияния признаков из разных масштабов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Summary:_**  \n",
    "\n",
    "__Чем SpineNet отличается от предыдущих backbone-сетей?__  \n",
    "В то время как для обнаружения присутствия признака может потребоваться высокое разрешение, для определения его локализации такая же точность не требуется.  \n",
    "\n",
    "**SpineNet учится на разномасштабных изображениях за счет смешения слоев**\n",
    "\n",
    "**_Плюсы архитектуры:_**\n",
    "\n",
    "1. Использование SpineNet позволяет добиться хорошей точности при меньших затратах вычислительных ресурсов по сравнению с архитектурой ResNet\n",
    "2. При использовании SpineNet во время энкодинга теряется меньше информации с изображения\n",
    "3. Архитектура масштабируется: в [статье](https://arxiv.org/pdf/1912.05027.pdf) приводятся архитектуры SpineNet-49, SpineNet-96, SpineNet-143, SpineNet-190\n",
    "\n",
    "**_Минусы архитектуры:_**  \n",
    "1. SpineNet строится на основе архитектуры ResNet, следовательно все недостатки и ошибки ResNet присущи и SpineNet \n",
    "2. Размеры слоев подбирались с помощью нейронного поиска архитектур (NAS) что добавляет сложности при разработке модели\n",
    "\n",
    "\n",
    "**_Вероятные сложности при практической реализации:_** \n",
    "\n",
    "- В связи с использованием в SpineNet слоев переменных масштабов потребуется дополнительные затраты времени для создания пермутированных слоев которые являются переходными между слоями с разными размерами изображения и количеством признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ссылки\n",
    "\n",
    "1. Подробное объяснение архитектуры [SpineNet](https://www.youtube.com/watch?v=qFRfnIRMNlk) [EN]\n",
    "2. Статья [SpineNet: Learning Scale-Permuted Backbone for Recognition and Localization](https://arxiv.org/pdf/1912.05027.pdf) [EN]\n",
    "3. Разбор [SpineNet: нетрадиционная архитектура](https://nuancesprog.ru/p/10090/) [RU]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyVqyez7Z6zV"
   },
   "source": [
    "### <span class=\"girk\">Выводы:</span>  \n",
    " 1. Простая смена функции активации с ```relu``` на ```tanh``` + снижение ```Dropout``` в 2 раза позволила увеличить ```accuracy``` на тестовой выборке с 0,5 до 0,55\n",
    " 2. Уменьшение размера партии c 128 до 64 (batch) уменьшает точность\n",
    " 3. Замена функции активации в последнем слое активации с ```softmax``` на иную будет снижать точность. \n",
    " 4. Помимо конфигурирования слоев необходимо тюнить Dropout под каждую конфигурацию: уменьшение Convolution в первом слое с (3, 3) на (2, 2) и (1, 1) вместе с увеличением Dropout-ов с 0,06 до 0,1 привело к росту точности модели до 0,62."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NsKhUR8fywAm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "13_lesson_4_my_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
