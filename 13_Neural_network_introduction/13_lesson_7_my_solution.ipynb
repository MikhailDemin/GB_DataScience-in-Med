{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWcUWSWpt0Rl"
   },
   "source": [
    "# Урок 4. Сверточные нейронные сети\n",
    "# Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7FBavh7yj77"
   },
   "source": [
    "### <span class=\"burk\">Задание 1.</span>\n",
    "**Сделайте краткий обзор любой архитектуры для object detection.**\n",
    "\n",
    "Проведите анализ: \n",
    " - Чем отличается выбранная вами архитектура нейронной сети от других?\n",
    " - В чём плюсы и минусы данной архитектуры?\n",
    " - Какие могут возникнуть трудности при применении этой архитектуры на практике?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SpineNet** — это backbone нейросетевая архитектура для задачи распознавания объекта. Разработкой модели занимались исследователи из Google Research. Модель обходит state-of-the-art подходы на задаче распознавания объектов на данных COCO. При этом SpineNet производит на 60% меньше вычислений и обходит ResNet-FPN на 6% по AP. Предложенную архитектуру также используют для классификации. SpineNet обходит state-of-the-art на 6% в точности на датасете iNaturalist.\n",
    "\n",
    " * Обычно backbone характеризует сеть с уменьшающимся масштабом в архитектуре “энкодер-декодер”, т.е. энкодер. \n",
    " * Поскольку задача энкодера состоит в вычислении представлений признаков на основе вводных данных, backbone с уменьшающимся масштабом не сможет удерживать пространственную информацию. \n",
    " * По мере углубления слоёв признаки будут становиться всё более абстрактными и менее локализованными, тем самым усложняя извлечение декодером точных необходимых признаков. \n",
    "\n",
    "С целью преодоления сложности получения и извлечения многомасштабных признаков для локализации была представлена модель с пермутируемыми масштабами и межмасштабными связями, предлагающая следующие улучшения:\n",
    "\n",
    "1. Масштабы карт признаков в этой архитектуре получили возможность увеличения или уменьшения в любой момент времени посредством пермутации блоков, что противоположно прежнему шаблону, подразумевавшему только уменьшение. Это позволило сохранять пространственную информацию. \n",
    "2. Связям карт признаков разрешено пересекать масштабы признаков для выполнения слияния признаков из разных масштабов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Summary:_**  \n",
    "\n",
    "__Чем SpineNet отличается от предыдущих backbone-сетей?__  \n",
    "В то время как для обнаружения присутствия признака может потребоваться высокое разрешение, для определения его локализации такая же точность не требуется.  \n",
    "\n",
    "**SpineNet учится на разномасштабных изображениях за счет смешения слоев**\n",
    "\n",
    "**_Плюсы архитектуры:_**\n",
    "\n",
    "1. Использование SpineNet позволяет добиться хорошей точности при меньших затратах вычислительных ресурсов по сравнению с архитектурой ResNet\n",
    "2. При использовании SpineNet во время энкодинга теряется меньше информации с изображения\n",
    "3. Архитектура масштабируется: в [статье](https://arxiv.org/pdf/1912.05027.pdf) приводятся архитектуры SpineNet-49, SpineNet-96, SpineNet-143, SpineNet-190\n",
    "\n",
    "**_Минусы архитектуры:_**  \n",
    "1. SpineNet строится на основе архитектуры ResNet, следовательно все недостатки и ошибки ResNet присущи и SpineNet \n",
    "2. Размеры слоев подбирались с помощью нейронного поиска архитектур (NAS) что добавляет сложности при разработке модели\n",
    "\n",
    "\n",
    "**_Вероятные сложности при практической реализации:_** \n",
    "\n",
    "- В связи с использованием в SpineNet слоев переменных масштабов потребуется дополнительные затраты времени для создания пермутированных слоев которые являются переходными между слоями с разными размерами изображения и количеством признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ссылки\n",
    "\n",
    "1. Подробное объяснение архитектуры [SpineNet](https://www.youtube.com/watch?v=qFRfnIRMNlk) [EN]\n",
    "2. Статья [SpineNet: Learning Scale-Permuted Backbone for Recognition and Localization](https://arxiv.org/pdf/1912.05027.pdf) [EN]\n",
    "3. Разбор [SpineNet: нетрадиционная архитектура](https://nuancesprog.ru/p/10090/) [RU]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UY3IVQhZyj8E"
   },
   "source": [
    "### <span class=\"burk\">Задание 2$^*$.</span>\n",
    "**Ссылка на репозиторий с полным кодом для обучения ssd нейросети:\n",
    "https://github.com/sergeyveneckiy/ssd-tensorflow.** \n",
    "\n",
    "**Попробуйте улучшить точность её\n",
    "работы и напишите отчёт (что вы пробовали изменить в её параметрах и как это\n",
    "отражалось на процессе обучения нейронной сети)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPJbJUsrtOOl"
   },
   "source": [
    "**Для MNIST:**  \n",
    " - Необходимо понизить количество входящих каналов до 2 (черный и белый)\n",
    " - Увеличить количество слоёв\n",
    " - Увеличить количество эпох\n",
    " - Тюнинг Dropout-ов  \n",
    "\n",
    "**Для CIFAR100:**  \n",
    " - Увеличить количество выходных классов до 100\n",
    " - Возможно понадобится пересмотр архитектуры, так как в CIFAR100 классы объединены в суперклассы по 5. Таким образом сеть должна сначала отнести изображение к одному из 20 суперклассов, затем уже определять к какому из классов внутри суперкласса относится тестовое изображение.\n",
    " - Свертки и ядра возможно останутся такими же как в текущей модели, однако понадобится увеличение количества слоёв/эпох.\n",
    " - Тюнинг Dropout-ов\n",
    "\n",
    "**Для IMAGENET:**  \n",
    " - Для анализа сета скорее всего потребуется ансамбль нейросетей, т.к. датасет очень большой.\n",
    " - Следует использовать подход сеть-внутри-сети\n",
    " - Учитывая что классов большое количество следует ограничить выборку.\n",
    " - Количество выходных классов нужно увеличить, также увеличить свертки/пулинги\n",
    " - Также понадобится увеличение количества слоёв/эпох"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyVqyez7Z6zV"
   },
   "source": [
    "### <span class=\"girk\">Выводы:</span>  \n",
    " 1. Простая смена функции активации с ```relu``` на ```tanh``` + снижение ```Dropout``` в 2 раза позволила увеличить ```accuracy``` на тестовой выборке с 0,5 до 0,55\n",
    " 2. Уменьшение размера партии c 128 до 64 (batch) уменьшает точность\n",
    " 3. Замена функции активации в последнем слое активации с ```softmax``` на иную будет снижать точность. \n",
    " 4. Помимо конфигурирования слоев необходимо тюнить Dropout под каждую конфигурацию: уменьшение Convolution в первом слое с (3, 3) на (2, 2) и (1, 1) вместе с увеличением Dropout-ов с 0,06 до 0,1 привело к росту точности модели до 0,62."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NsKhUR8fywAm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "13_lesson_4_my_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
