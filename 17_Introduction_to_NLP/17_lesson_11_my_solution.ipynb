{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0Qjg6vuaHNt"
   },
   "source": [
    "# Урок 11. Модель Transformer-1\n",
    "## Домашнее задание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобраться с моделькой перевода (с механизмом внимания) как она устроена,\n",
    "запустить для перевода с русского на английский (при желании можно взять другие пары языков)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 32860,
     "status": "ok",
     "timestamp": 1677589829937,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "XFG0NDRu5mYQ",
    "outputId": "d5f24f72-016f-4222-9a16-3e125a8986b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting matplotlib==3.2.2\n",
      "  Downloading matplotlib-3.2.2-cp38-cp38-manylinux1_x86_64.whl (12.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.2.2) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.2.2) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.2.2) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.2.2) (1.22.4)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.2.2) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib==3.2.2) (1.15.0)\n",
      "Installing collected packages: matplotlib\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.5.3\n",
      "    Uninstalling matplotlib-3.5.3:\n",
      "      Successfully uninstalled matplotlib-3.5.3\n",
      "Successfully installed matplotlib-3.2.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "matplotlib",
         "mpl_toolkits"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install -q tfds-nightly\n",
    "\n",
    "# Pin matplotlib version to 3.2.2 since in the latest version\n",
    "# transformer.ipynb fails with the following error:\n",
    "# https://stackoverflow.com/questions/62953704/valueerror-the-number-of-fixedlocator-locations-5-usually-from-a-call-to-set\n",
    "!pip install matplotlib==3.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3242,
     "status": "ok",
     "timestamp": 1677589833169,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "JjJJyJTZYebt"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fd1NWMxjfsDd"
   },
   "source": [
    "## Setup input pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4_Qt8W1hJE_"
   },
   "source": [
    "Use [TFDS](https://www.tensorflow.org/datasets) to load the Ru-English translation dataset from the [TED Talks Open Translation Project](https://www.ted.com/participate/translate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168,
     "referenced_widgets": [
      "21a22c0cf1db4afe8b85c2a98e6b00ea",
      "e576cdba3d774476b38ebed2b61a58e6",
      "e81784049f2649598ecb25dbef3b1d9b",
      "cdcc6515657e4d24b0a19b2cf2a0bf4f",
      "ca3c765e63cd41daa1827166ed1cb6c5",
      "960a9f9023ec4180b943732f4b4ebf67",
      "f9097ae79f88464cbb00ddbb84ff7a7c",
      "d48da2b6fffd4ba2b9e6095f62048b9a",
      "ada68a0628784e8b9e8bea348ee8e9fa",
      "769fcd195be6497db071b66c51c04beb",
      "33e29c9596034eaeb9e30304d0771c5a",
      "f337addcdd864668a0287d5c98a8057b",
      "7ce640c71d1e4fd09e854a3ac2cb3e35",
      "8af46e271ba04628af052f047d06cf13",
      "402eefd4c38947c98bc1f9828415fef8",
      "198500121c8d4e548fa30fb27a61d66d",
      "fa8f84b22f0d4aab81fd83a2d383d9c7",
      "b96fcb1426be4d76b1c992c8327bb71a",
      "02cb3d383bcb4187b59e0abd3c13dc8c",
      "c97931f8652b415cb4894ecf42a80818",
      "4d977cae912f408e9c0910feefd5fb3d",
      "c23f5624ca4f4e258ebb2152724959ff",
      "b13217db84ea4ea08ecfd06162de7f34",
      "7f00f95f20c94794a83e64d86c990e8d",
      "6168334214c541e490c4ba5d938f7a4e",
      "8053bc0452664edda8b53c3b803c7136",
      "4537216e76c443bbb7a91533cd471d31",
      "330c5ddbe46a4e38bc2e805495092721",
      "0968600d30b24445880559d6c9e55b28",
      "ba510ab836d44957b63d6a1ceb08149d",
      "818a059008d04cb092c6c163649edebc",
      "cf7a853594d64daeb50129eb6e1fb3a7",
      "4b3d994eb2f84a61942a5fbb0c1aba6a",
      "b83a3c1cbec84df7b80ab123a7f1faf1",
      "bf7f083e184f47ddb7bee9b270a50e26",
      "1c37032e90414083ad622ee7a0f67c05",
      "072bb88f18154b2fae3d0d1a67d7dbf9",
      "49bca3ba670146f2944f0059d4a5996e",
      "94beada069b94d8baa1d8c5b321f5edb",
      "807c368799124d4aa81cc6e489861059",
      "ac7eb7b615994d108aa6a18917686575",
      "66a8456b82424baca6c7dadaa49c3fde",
      "5a283e3a6add46b3a19188080c3e3ab8",
      "0069794296c54a0680417ff91692d115",
      "aab35f63459c4545b632a37611a246cb",
      "8327b27a9ed746b1b1e54037dc60e30f",
      "10122b47d646469f9442f8618caca701",
      "1647854dc0dd4188aac4ff8166f0054e",
      "e0b3ceebe6e149b9a4d745a88c2c8138",
      "638e97f3846946e186c04f9c1095e3c2",
      "864f18f033f641f2983f55f9906e039b",
      "9b1e1a7b7d2644beac8d12317b3c6cf1",
      "ea5f172293234d9186007242bd1255ff",
      "2f4a88886f324e7ca8a6bb9614eff7aa",
      "2861d02bb55a438c9cd2027524a6a021",
      "6492c10f01ca403b9a87b7905e4ae7a8",
      "725b8ee7d6394aaf8876cd5d3eee5740",
      "41a0b54f4e404d568a36d122a072650f",
      "27b34af6e2964f8db01fc7c701acfbad",
      "7f7fff9736a14c3c9ca53baa792dbbcd",
      "c936b834321e4432a2511d0a88b32070",
      "b0178c8ffb934c1e9ea9bb808720fa29",
      "af253ca7030b46438bf0e4b4b9c31332",
      "e6261cf928d740ec90e1e4f03802a3cd",
      "eaa755782de2433a876a898616058680",
      "2454cba57e8f4069b0b93e85d4128cb6",
      "c898ecbd94cc4f2bb4ad7d0441a2dd4f",
      "ce30224b3e1d4405a7221d51e286fccb",
      "4b4ac4baf39a4e179b00e0ffb2003491",
      "d282fa4be526420089d7e40e1720954f",
      "aff8f76bb80b4037805914bcddb903a2",
      "67cfbc8ab04d4205865409b05fb9c9df",
      "c99fdcf7799d45af847eee0b5565304a",
      "cf8db9d4ca9e41aaa61bc6a3d634f607",
      "baf9018a95d34c4c93823b2440f4d5d7",
      "4e332f8efc944611b10922101faa5912",
      "a1b88cc9e6ca48c5a997ba53acaba2b9",
      "574fa67d600244219b76d6330ba03294",
      "1ca03450ffdf48199297e446ed12087f",
      "400d07b3cf754a369e73e51d7da0aede",
      "389902c6621c4903a2fc9cc28a9462d0",
      "10de753360fa4f33bad5e0e0236b8840",
      "e7e0a3c4299447dfaf89c020deed6ccf",
      "73960e406dc24772b0ea3ba64b86bd24",
      "f86f6a5af4114b639972feca51a596dc",
      "547ec8c1c6324a718b332472acf8d80c",
      "7afad1c9c72347ec9046e0918373d395",
      "8325d355b1914d159fd5a98c2278c1b3",
      "8cf3457cc9714ec79adb02b610225199",
      "66db343ecf5f4ceea10268dffa5b66c4",
      "2aed024b3eb74c269dbfeb49290e56e7",
      "60bd47c105bb4e559d195d28de04bc8f",
      "53d4209261ad4e70af7ba03419820055",
      "51f993bd0919435a82ccbccaab4313d1",
      "d2bdd5457f82497cb8bef321a792a0b3",
      "84c26e7728364848854d6f386e86b7b4",
      "d1bff15c3c6a45fab96db3f29775f576",
      "edc2628465824b6da1a2d30533ec2b21",
      "9a256edddbcd402690c9aab72ea08f77",
      "ba970f4409ca42d39f3ab4be715f2324",
      "d5ebb5979a1e4aebbbdd41c17f1ca5ec",
      "caab20b977a74d9584334c406117853b",
      "0bd984b8b5214dae8ee91dc057593385",
      "12b6d2fb2bc642579b034fb35caa2f97",
      "9a9d098f0d7e4881b19b91e7ae8efe63",
      "1cf4b0c6ef49418caf1b9de0dfba4e71",
      "8e233332962e4ba88ae5dbb9cab7c57e",
      "2f2f7364c8384e8db8c771d451e3c506",
      "8cb0a7163a7b4ce8b30fd32f27509b7e",
      "e1af616dfbf44288803f43a591cbf31d"
     ]
    },
    "executionInfo": {
     "elapsed": 52054,
     "status": "ok",
     "timestamp": 1677589885219,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "8q9t4FmN96eN",
    "outputId": "8a69c9a0-07a0-4689-f756-3811c2e9e6f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/ted_hrlr_translate/ru_to_en/1.0.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a22c0cf1db4afe8b85c2a98e6b00ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f337addcdd864668a0287d5c98a8057b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13217db84ea4ea08ecfd06162de7f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83a3c1cbec84df7b80ab123a7f1faf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab35f63459c4545b632a37611a246cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6492c10f01ca403b9a87b7905e4ae7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /root/tensorflow_datasets/ted_hrlr_translate/ru_to_en/1.0.0.incompleteU089BI/ted_hrlr_translate-trai…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c898ecbd94cc4f2bb4ad7d0441a2dd4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574fa67d600244219b76d6330ba03294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /root/tensorflow_datasets/ted_hrlr_translate/ru_to_en/1.0.0.incompleteU089BI/ted_hrlr_translate-vali…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf3457cc9714ec79adb02b610225199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba970f4409ca42d39f3ab4be715f2324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /root/tensorflow_datasets/ted_hrlr_translate/ru_to_en/1.0.0.incompleteU089BI/ted_hrlr_translate-test…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ted_hrlr_translate downloaded and prepared to /root/tensorflow_datasets/ted_hrlr_translate/ru_to_en/1.0.0. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/ru_to_en', with_info=True,\n",
    "                               as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCEKotqosGfq"
   },
   "source": [
    "Создайте собственный токенизатор подслов из training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 578487,
     "status": "ok",
     "timestamp": 1677590463702,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "KVBg5Q8tBk5z"
   },
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for ru, en in train_examples), target_vocab_size=2**13)\n",
    "\n",
    "tokenizer_ru = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (ru.numpy() for ru, en in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1677590463702,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "4DYWukNFkGQN",
    "outputId": "40c891ef-cbb6-47ef-83f1-a05b7d439069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [8073, 1034, 8104, 5774, 13, 3531, 8035]\n",
      "The original string: Transformer is awesome.\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Transformer is awesome.'\n",
    "\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9KJWJjrsZ4Y"
   },
   "source": [
    "Токенизатор кодирует строку, разбивая ее на подслова, если слово отсутствует в его словаре.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1677590463702,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "bf2ntBxjkqK6",
    "outputId": "55432fea-d974-4ad9-d8c3-0190f2c52578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8073 ----> T\n",
      "1034 ----> ran\n",
      "8104 ----> s\n",
      "5774 ----> former \n",
      "13 ----> is \n",
      "3531 ----> awesome\n",
      "8035 ----> .\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1677590463703,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "bcRp7VcQ5m6g"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGi4PoVakxdc"
   },
   "source": [
    "Добавьте начальный и конечный токены к входу и цели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1677590463703,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "UZwnPr4R055s"
   },
   "outputs": [],
   "source": [
    "# two tokenizers (tokenizer_ru and tokenizer_en) are used to encode two languages (lang1 and lang2). \n",
    "# The encode method is then called on each language, which adds the beginning and end of sequence tokens \n",
    "# (tokenizer_ru.vocabsize and tokenizer_en.vocabsize+1) to the encoded text. Finally, the encoded text for both \n",
    "# languages is returned as a tuple.\n",
    "\n",
    "def encode(lang1, lang2):\n",
    "  lang1 = [tokenizer_ru.vocab_size] + tokenizer_ru.encode(\n",
    "      lang1.numpy()) + [tokenizer_ru.vocab_size+1]\n",
    "\n",
    "  lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "      lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "  \n",
    "  return lang1, lang2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tx1sFbR-9fRs"
   },
   "source": [
    "Вы хотите использовать Dataset.map чтобы применить эту функцию к каждому элементу набора данных. Dataset.map работает в графическом режиме.\n",
    "\n",
    "Тензоры графов не имеют значения.\n",
    "В графическом режиме вы можете использовать только операции и функции TensorFlow.\n",
    "Таким образом, вы не можете напрямую .map эту функцию: вам нужно обернуть ее в tf.py_function . tf.py_function будет передавать обычные тензоры (со значением и .numpy() для доступа к нему) в .numpy() функцию python.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1677590463703,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "Mah1cS-P70Iz"
   },
   "outputs": [],
   "source": [
    "def tf_encode(ru, en):\n",
    "\n",
    "# tf.pyfunction method is used to call a custom function (encode) with two arguments (ru and en). \n",
    "# The two arguments are then mapped to two data types (tf.int64, tf.int64) which will be returned as a tuple containing two Tensors.\n",
    "  result_ru, result_en = tf.py_function(encode, [ru, en], [tf.int64, tf.int64])\n",
    "\n",
    "#set_shape method is used to set the shape of each Tensor to [None], which means that it will be able to accept variable-length inputs.\n",
    "  result_ru.set_shape([None]) \n",
    "  result_en.set_shape([None])\n",
    "\n",
    "  return result_ru, result_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1677590463704,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "2QEgbjntk6Yf"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1677590463704,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "myo7GJnKcVe9"
   },
   "outputs": [],
   "source": [
    "# filter out examples that have a length greater than the specified maxlength. \n",
    "# This is done by checking the length of both x and y using the tf.size method and then using the tf.logicaland method to return\n",
    "#  a boolean value indicating if both lengths are less than the specified max_length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1677590463704,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "c081xPGv1CPI"
   },
   "outputs": [],
   "source": [
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "  return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1677590463704,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "9mk9AZdZ5bcS"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_examples.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "# cache the dataset to memory to get a speedup while reading from it.\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE) # create batches of data in which the examples are padded with zeros to match the maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1677590464306,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "_fXvfYVfQr2n",
    "outputId": "4fb28794-054f-4725-f39f-55c56ed35f9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 38), dtype=int64, numpy=\n",
       " array([[8179,   57,   86, ...,    0,    0,    0],\n",
       "        [8179,    3,   38, ...,    0,    0,    0],\n",
       "        [8179,   57,  135, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8179,    3,    7, ...,    0,    0,    0],\n",
       "        [8179,  138,  250, ...,    0,    0,    0],\n",
       "        [8179,   19,    7, ...,    0,    0,    0]])>,\n",
       " <tf.Tensor: shape=(64, 40), dtype=int64, numpy=\n",
       " array([[8245,   90,  101, ...,    0,    0,    0],\n",
       "        [8245,   70,   25, ...,    0,    0,    0],\n",
       "        [8245,   90,  153, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8245,    4,   18, ...,    0,    0,    0],\n",
       "        [8245,   19,   59, ...,    0,    0,    0],\n",
       "        [8245,   24,   18, ...,    0,    0,    0]])>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch, en_batch = next(iter(val_dataset))\n",
    "pt_batch, en_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBQuibYA4n0n"
   },
   "source": [
    "## Positional encoding\n",
    "\n",
    "Поскольку эта модель не содержит повторений или сверток, добавляется позиционное кодирование, чтобы дать модели некоторую информацию об относительном положении слов в предложении.\n",
    "\n",
    "Вектор позиционного кодирования добавляется к вектору внедрения. Вложения представляют собой токен в d-мерном пространстве, где токены с одинаковым значением будут ближе друг к другу. Но вложения не кодируют относительное положение слов в предложении. Таким образом, после добавления позиционной кодировки слова будут ближе друг к другу на основе сходства их значения и их положения в предложении в d-мерном пространстве.\n",
    "\n",
    "Формула для расчета позиционного кодирования выглядит следующим образом:\n",
    "\n",
    "\n",
    "\n",
    "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
    "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677590464307,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "WhIOZjMNKujn"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  print(pos * angle_rates)\n",
    "  return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1677590464310,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "1Rz82wEs5biZ"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis], # стобец\n",
    "                          np.arange(d_model)[np.newaxis, :], # строка\n",
    "                          d_model)\n",
    "  \n",
    "  # apply sin to even indices in the array; 2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1677590464311,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "1kLCla68EloE",
    "outputId": "6a7494f3-19a2-41f3-e379-33ad65296ec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 1.00000000e+00 9.64661620e-01 ... 1.07460783e-04\n",
      "  1.03663293e-04 1.03663293e-04]\n",
      " [2.00000000e+00 2.00000000e+00 1.92932324e+00 ... 2.14921566e-04\n",
      "  2.07326586e-04 2.07326586e-04]\n",
      " ...\n",
      " [4.70000000e+01 4.70000000e+01 4.53390961e+01 ... 5.05065679e-03\n",
      "  4.87217476e-03 4.87217476e-03]\n",
      " [4.80000000e+01 4.80000000e+01 4.63037578e+01 ... 5.15811758e-03\n",
      "  4.97583806e-03 4.97583806e-03]\n",
      " [4.90000000e+01 4.90000000e+01 4.72684194e+01 ... 5.26557836e-03\n",
      "  5.07950135e-03 5.07950135e-03]]\n",
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Получаем 50 строк по 512 значений\n",
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_b4ou4TYqUN"
   },
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s42Uydjkv0hF"
   },
   "source": [
    "Замаскируйте все маркеры площадок в пакете последовательности. Это гарантирует, что модель не обрабатывает отступы как входные данные. Маска указывает, где присутствует значение пэда 0 : она выводит 1 в этих местах и 0 противном случае."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1677590464312,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "U2i8-e1s8ti9"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32) # 1 if element is null, otherwise - 0\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1677590464313,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "A7BYeBCNvi7n",
    "outputId": "30146641-42f8-4c26-c28a-40d294be73cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0hzukDBgVom"
   },
   "source": [
    "Маска упреждающего просмотра используется для маскировки будущих токенов в последовательности. Другими словами, маска указывает, какие записи не следует использовать.\n",
    "\n",
    "Это означает, что для предсказания третьего слова будут использоваться только первое и второе слово. Аналогично для предсказания четвертого слова будут использоваться только первое, второе и третье слово и так далее.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1677590464313,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "dVxS8OPI9uI0"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0) # Copy a tensor setting everything outside a central band in each innermost matrix to zero.\n",
    "  return mask  # (seq_len, seq_len) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1677590464314,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "yxKGuXxaBeeE",
    "outputId": "5ea76597-66ed-4324-c98c-59402a8d18d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.05678511 0.45999086 0.9655584 ]], shape=(1, 3), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "print(x)\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xluDl5cXYy4y"
   },
   "source": [
    "## Scaled dot product attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsxEE_-Wa1gF"
   },
   "source": [
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/scaled_attention.png\" width=\"500\" alt=\"scaled_dot_product_attention\">\n",
    "\n",
    "Функция внимания, используемая преобразователем, принимает три входа: Q (запрос), K (ключ), V (значение). Уравнение, используемое для расчета весов внимания:\n",
    "\n",
    "\n",
    "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$\n",
    "\n",
    "Внимание скалярного произведения масштабируется с коэффициентом квадратного корня из глубины. Это сделано потому, что для больших значений глубины скалярное произведение увеличивается по величине, подталкивая функцию softmax, где у него есть небольшие градиенты, что приводит к очень жесткому softmax.\n",
    "\n",
    "Например, предположим, что Q и K имеют среднее значение 0 и дисперсию 1. Их матричное умножение будет иметь среднее значение 0 и дисперсию dk . Следовательно, для масштабирования используется квадратный корень из dk (а не какое-либо другое число), потому что матрица Q и K должна иметь среднее значение 0 и дисперсию 1, и вы получите более мягкий softmax.\n",
    "\n",
    "Маска умножается на -1e9 (близко к отрицательной бесконечности). Это сделано потому, что маска суммируется с умножением масштабированной матрицы Q и K и применяется непосредственно перед softmax. Цель состоит в том, чтобы обнулить эти ячейки, и большие отрицательные входные данные для softmax близки к нулю на выходе.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677590464314,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "LazzUq3bJ5SH"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FiqETnhCkoXh"
   },
   "source": [
    "Поскольку нормализация softmax выполняется для K, его значения определяют степень важности, придаваемой Q.\n",
    "\n",
    "Выходные данные представляют собой умножение весов внимания и вектора V (значения). Это гарантирует, что слова, на которых вы хотите сосредоточиться, останутся как есть, а нерелевантные слова будут удалены.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677590464314,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "n90YjClyInFy"
   },
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "  temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "  print ('Attention weights are:')\n",
    "  print (temp_attn)\n",
    "  print ('Output is:')\n",
    "  print (temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2818,
     "status": "ok",
     "timestamp": 1677590467120,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "yAzUAf2DPlNt",
    "outputId": "2028de24-2f78-4bfd-f668-6a18b09335af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1677590467120,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "zg6k-fGhgXra",
    "outputId": "a8be470b-1efa-4ff5-df2d-725972ea0b08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns with a repeated key (third and fourth), \n",
    "# so all associated values get averaged.\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677590467120,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "UAq3YOzUgXhb",
    "outputId": "bf6abb2d-1d4f-474b-d0f9-899f4e1c2c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns equally with the first and second key, \n",
    "# so their values get averaged.\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOz-4_XIhaTP"
   },
   "source": [
    "Pass all the queries together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1677590467121,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "6dlU8Tm-hYrF",
    "outputId": "788e9fee-8fff-4498-9606-2f62db0a012b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.   0.   0.5  0.5 ]\n",
      " [0.   1.   0.   0.  ]\n",
      " [0.25 0.25 0.25 0.25]], shape=(3, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[550.     5.5 ]\n",
      " [ 10.     0.  ]\n",
      " [277.75   2.75]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 10]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmzGPEy64qmA"
   },
   "source": [
    "## Multi-head attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fz5BMC8Kaoqo"
   },
   "source": [
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/multi_head_attention.png\" width=\"500\" alt=\"multi-head attention\">\n",
    "\n",
    "\n",
    "Многоголовое внимание состоит из четырех частей:\n",
    "\n",
    "* Слои линейные и разбиваются на головы.\n",
    "* Повышенное внимание к скалярному продукту\n",
    "* Конкатенация голов.\n",
    "* Финальный линейный слой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPmbr6F1C-v_"
   },
   "source": [
    "Каждый блок внимания с несколькими головами получает три входа; Q (запрос), K (ключ), V (значение). Они проходят через линейные (плотные) слои и разбиваются на несколько головок.\n",
    "\n",
    "scaled_dot_product_attention определенный выше, применяется к каждой голове (транслируется для эффективности). На этапе внимания необходимо использовать соответствующую маску. Затем вывод внимания для каждой головы объединяется (с использованием tf.transpose и tf.reshape ) и пропускается через последний слой Dense .\n",
    "\n",
    "Вместо одной единственной головы внимания Q, K и V разделены на несколько голов, потому что это позволяет модели совместно обращать внимание на информацию в разных положениях из разных пространств представления. После разделения каждая голова имеет уменьшенную размерность, поэтому общая стоимость вычислений такая же, как и внимание одной головы с полной размерностью.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1677590467121,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "BSV3PPKsYecw"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    assert d_model % self.num_heads == 0\n",
    "    \n",
    "    self.depth = d_model // self.num_heads\n",
    "    \n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    # If one component of shape is the special value -1, the size of that dimension is computed so that \n",
    "    # the total size remains constant. In particular, a shape of [-1] flattens into 1-D. \n",
    "    # At most one component of shape can be -1.\n",
    "    \n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "    \n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "    \n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D8FJue5lDyZ"
   },
   "source": [
    "Создайте слой MultiHeadAttention чтобы попробовать. В каждом месте в последовательности y MultiHeadAttention запускает все 8 головок внимания по всем другим местам в последовательности, возвращая новый вектор той же длины в каждом месте.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1677590467122,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "Hu94p-_-2_BX",
    "outputId": "75a54988-6e93-4070-c569-ec3db8badd38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выходные размерности:  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 3, 10]), TensorShape([2, 2, 3, 3]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=10, num_heads=2)\n",
    "y = tf.random.uniform((2, 3, 10))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "print('Выходные размерности:  \\n')\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdDqGayx67vv"
   },
   "source": [
    "## Point wise feed forward network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBqzJXGfHK3X"
   },
   "source": [
    "Сеть с точечной прямой связью состоит из двух полностью связанных слоев с активацией ReLU между ними.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677590467122,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "ET7xLt0yCT6Z"
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 644,
     "status": "ok",
     "timestamp": 1677590467760,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "mytb1lPyOHLB",
    "outputId": "0241321a-284a-44eb-bba2-ed2b99b6e400"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e7hKcxn6-zd"
   },
   "source": [
    "## Encoder and decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yScbC0MUH8dS"
   },
   "source": [
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfYJG-Kvgwy2"
   },
   "source": [
    "Модель трансформера следует той же общей схеме, что и стандартная последовательность действий с моделью внимания .\n",
    "\n",
    "Входное предложение проходит через N уровней кодировщика, которые генерируют выходные данные для каждого слова / токена в последовательности.\n",
    "Декодер отслеживает вывод кодировщика и свой собственный ввод (самовнимание), чтобы предсказать следующее слово.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFv-FNYUmvpn"
   },
   "source": [
    "### Encoder layer\n",
    "\n",
    "Каждый уровень кодировщика состоит из подслоев:\n",
    "\n",
    "Многоголовое внимание (с дополнительной маской)\n",
    "Точечные сети прямого распространения.\n",
    "Каждый из этих подуровней имеет остаточную связь вокруг себя, за которой следует нормализация уровня. Остаточные соединения помогают избежать проблемы исчезающего градиента в глубоких сетях.\n",
    "\n",
    "Результатом каждого подслоя является LayerNorm(x + Sublayer(x)) . Нормализация выполняется по d_model (последняя). В трансформаторе N слоев кодировщика.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1677590467761,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "ncyS-Ms3i2x_"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1677590467761,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "AzZRXdO0mI48",
    "outputId": "a5a580df-773e-4c88-a3c1-295dbe293af1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LO_48Owmx_o"
   },
   "source": [
    "### Decoder layer\n",
    "\n",
    "Каждый слой декодера состоит из подслоев:\n",
    "\n",
    "Замаскированное внимание с несколькими головами (с опережающей маской и дополнительной маской)\n",
    "Многоголовое внимание (с дополнительной маской). V (значение) и K (ключ) получают выходной сигнал энкодера в качестве входных данных. Q (запрос) получает выходные данные от подуровня замаскированного многоголового внимания.\n",
    "Точечные сети прямого распространения\n",
    "Каждый из этих подуровней имеет остаточную связь вокруг себя, за которой следует нормализация уровня. Результатом каждого подслоя является LayerNorm(x + Sublayer(x)) . Нормализация выполняется по d_model (последняя).\n",
    "\n",
    "В трансформаторе N слоев декодера.\n",
    "\n",
    "Поскольку Q принимает выходные данные от первого блока внимания декодера, а K принимает выходные данные кодировщика, веса внимания представляют важность, придаваемую входу декодера на основе выходных данных кодера. Другими словами, декодер предсказывает следующее слово, глядя на выходные данные кодировщика и самостоятельно присматриваясь к своим собственным выходным данным. См. Демонстрацию выше в разделе «Внимание к скалярному произведению».\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1677590467762,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "9SoX0-vd1hue"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "    \n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1677590467762,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "Ne2Bqx8k71l0",
    "outputId": "660bd728-def9-401b-da8e-c46937fcb6b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SE1H51Ajm0q1"
   },
   "source": [
    "### Encoder\n",
    "\n",
    "The `Encoder` consists of:\n",
    "1.   Input Embedding\n",
    "2.   Positional Encoding\n",
    "3.   N encoder layers\n",
    "\n",
    "The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1677590467763,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "jpEox7gJ8FCI"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                            self.d_model)\n",
    "    \n",
    "    \n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "  \n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1] #40\n",
    "    \n",
    "    # adding embedding and position encoding.\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 519,
     "status": "ok",
     "timestamp": 1677590468273,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "8QG9nueFQKXx",
    "outputId": "84fa26b2-a266-4465-d215-0dfbcc22fa9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.            0.            0.         ...    0.\n",
      "     0.            0.        ]\n",
      " [   1.            1.            0.96466162 ...    0.00010746\n",
      "     0.00010366    0.00010366]\n",
      " [   2.            2.            1.92932324 ...    0.00021492\n",
      "     0.00020733    0.00020733]\n",
      " ...\n",
      " [9997.         9997.         9643.72221425 ...    1.07428545\n",
      "     1.03632194    1.03632194]\n",
      " [9998.         9998.         9644.68687587 ...    1.07439291\n",
      "     1.0364256     1.0364256 ]\n",
      " [9999.         9999.         9645.65153749 ...    1.07450037\n",
      "     1.03652927    1.03652927]]\n",
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-uO6ls8m2O5"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtT7PKzrXkNr"
   },
   "source": [
    " The `Decoder` consists of:\n",
    "1.   Output Embedding\n",
    "2.   Positional Encoding\n",
    "3.   N decoder layers\n",
    "\n",
    "The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1677590468273,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "d5_d5-PLQXwY"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "    \n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "    \n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "      \n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1677590468274,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "a1jXoAMRZyvu",
    "outputId": "a606bee2-ee29-4942-d6a9-89bf82d657fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.            0.            0.         ...    0.\n",
      "     0.            0.        ]\n",
      " [   1.            1.            0.96466162 ...    0.00010746\n",
      "     0.00010366    0.00010366]\n",
      " [   2.            2.            1.92932324 ...    0.00021492\n",
      "     0.00020733    0.00020733]\n",
      " ...\n",
      " [4997.         4997.         4820.4141147  ...    0.53698153\n",
      "     0.51800547    0.51800547]\n",
      " [4998.         4998.         4821.37877632 ...    0.53708899\n",
      "     0.51810914    0.51810914]\n",
      " [4999.         4999.         4822.34343794 ...    0.53719645\n",
      "     0.5182128     0.5182128 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input, \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False,\n",
    "                              look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y54xnJnuYgJ7"
   },
   "source": [
    "## Create the Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uERO1y54cOKq"
   },
   "source": [
    "Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677590468274,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "PED3bIpOYkBu"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "  def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "    \n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 696,
     "status": "ok",
     "timestamp": 1677590468965,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "tJ4fbQcIkHW1",
    "outputId": "2cbd939a-b892-46ac-e866-30e52ea05ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.            0.            0.         ...    0.\n",
      "     0.            0.        ]\n",
      " [   1.            1.            0.96466162 ...    0.00010746\n",
      "     0.00010366    0.00010366]\n",
      " [   2.            2.            1.92932324 ...    0.00021492\n",
      "     0.00020733    0.00020733]\n",
      " ...\n",
      " [9997.         9997.         9643.72221425 ...    1.07428545\n",
      "     1.03632194    1.03632194]\n",
      " [9998.         9998.         9644.68687587 ...    1.07439291\n",
      "     1.0364256     1.0364256 ]\n",
      " [9999.         9999.         9645.65153749 ...    1.07450037\n",
      "     1.03652927    1.03652927]]\n",
      "[[   0.            0.            0.         ...    0.\n",
      "     0.            0.        ]\n",
      " [   1.            1.            0.96466162 ...    0.00010746\n",
      "     0.00010366    0.00010366]\n",
      " [   2.            2.            1.92932324 ...    0.00021492\n",
      "     0.00020733    0.00020733]\n",
      " ...\n",
      " [5997.         5997.         5785.07573461 ...    0.64444231\n",
      "     0.62166877    0.62166877]\n",
      " [5998.         5998.         5786.04039623 ...    0.64454978\n",
      "     0.62177243    0.62177243]\n",
      " [5999.         5999.         5787.00505785 ...    0.64465724\n",
      "     0.62187609    0.62187609]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 36, 8000])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000, \n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsINyf1VEQLC"
   },
   "source": [
    "## Set hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVjWCxFNcgbt"
   },
   "source": [
    "To keep this example small and relatively fast, the values for *num_layers, d_model, and dff* have been reduced. \n",
    "\n",
    "The values used in the base model of transformer were; *num_layers=6*, *d_model = 512*, *dff = 2048*. See the [paper](https://arxiv.org/abs/1706.03762) for all the other versions of the transformer.\n",
    "\n",
    "Note: By changing the values below, you can get the model that achieved state of the art on many tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677590468965,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "lnJn5SLA2ahP"
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_ru.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYEGhEOtzn5W"
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOmWW--yP3zx"
   },
   "source": [
    "Use the Adam optimizer with a custom learning rate scheduler according to the formula in the [paper](https://arxiv.org/abs/1706.03762).\n",
    "\n",
    "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677590468966,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "iYQdOO1axwEI"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, np.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkvtTdKawj4p"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677590468966,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "7r4scdulztRx"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Omzm9c9wyRJM"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1677590468966,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "f33ZCgvHpPdG",
    "outputId": "0a70de01-10f9-4bca-a5dd-0919035dab90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgkDE7hzo8r5"
   },
   "source": [
    "## Loss and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxGJtoDuYIHL"
   },
   "source": [
    "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1677590468966,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "MlhsJMm0TW_B"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1677590468967,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "67oqVHiT0Eiu"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "  \n",
    "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "  \n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1677590468967,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "phlyxMnm-Tpx"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeHumfr7zmMa"
   },
   "source": [
    "## Training and checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1026,
     "status": "ok",
     "timestamp": 1677590469985,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "UiysUa--4tOU",
    "outputId": "bbd45aa2-0b64-4d01-abe3-8186cc154436"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.            0.            0.         ...    0.\n",
      "     0.            0.        ]\n",
      " [   1.            1.            0.86596432 ...    0.00013335\n",
      "     0.00011548    0.00011548]\n",
      " [   2.            2.            1.73192865 ...    0.0002667\n",
      "     0.00023096    0.00023096]\n",
      " ...\n",
      " [8178.         8178.         7081.85623644 ...    1.09055383\n",
      "     0.94438071    0.94438071]\n",
      " [8179.         8179.         7082.72220076 ...    1.09068718\n",
      "     0.94449619    0.94449619]\n",
      " [8180.         8180.         7083.58816509 ...    1.09082053\n",
      "     0.94461166    0.94461166]]\n",
      "[[   0.            0.            0.         ...    0.\n",
      "     0.            0.        ]\n",
      " [   1.            1.            0.86596432 ...    0.00013335\n",
      "     0.00011548    0.00011548]\n",
      " [   2.            2.            1.73192865 ...    0.0002667\n",
      "     0.00023096    0.00023096]\n",
      " ...\n",
      " [8244.         8244.         7139.00988178 ...    1.09935507\n",
      "     0.95200227    0.95200227]\n",
      " [8245.         8245.         7139.8758461  ...    1.09948842\n",
      "     0.95211775    0.95211775]\n",
      " [8246.         8246.         7140.74181043 ...    1.09962177\n",
      "     0.95223322    0.95223322]]\n"
     ]
    }
   ],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677590469985,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "ZOJUSB1T8GjM"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "  # Encoder padding mask\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 2nd attention block in the decoder.\n",
    "  # This padding mask is used to mask the encoder outputs.\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 1st attention block in the decoder.\n",
    "  # It is used to pad and mask future tokens in the input received by \n",
    "  # the decoder.\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fzuf06YZp66w"
   },
   "source": [
    "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677590469986,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "hNhuYfllndLZ"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Di_Yaa1gf9r"
   },
   "source": [
    "Цель делится на tar_inp и tar_real. tar_inp передается декодеру в качестве входных данных. tar_real - это тот же самый ввод, сдвинутый на 1: в каждом месте tar_input tar_real содержит следующий токен, который должен быть предсказан.\n",
    "\n",
    "Например, sentence = \"SOS Лев в джунглях спит EOS\"\n",
    "\n",
    "tar_inp = \"SOS tar_inp лев в джунглях\"\n",
    "\n",
    "tar_real = \"Лев в джунглях спит EOS\"\n",
    "\n",
    "Преобразователь - это авторегрессивная модель: он делает прогнозы по частям и использует свои выходные данные, чтобы решить, что делать дальше.\n",
    "\n",
    "Во время обучения в этом примере используется принуждение учителя (как в учебнике по созданию текста ). Принуждение учителя передает истинный результат следующему временному шагу независимо от того, что модель предсказывает на текущем временном шаге.\n",
    "\n",
    "Поскольку преобразователь предсказывает каждое слово, самовнимание позволяет ему смотреть на предыдущие слова во входной последовательности, чтобы лучше предсказать следующее слово.\n",
    "\n",
    "Чтобы модель не просматривала ожидаемый результат, в модели используется маска просмотра вперед.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677590469986,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "LKpoA6q1sJFj"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677590469986,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "iJwmp9OE29oj"
   },
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "  \n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "  train_loss(loss)\n",
    "  train_accuracy(accuracy_function(tar_real, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qM2PDWGDJ_8V"
   },
   "source": [
    "Ru is used as the input language and English is the target language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5244630,
     "status": "ok",
     "timestamp": 1677595714611,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "bbvmaKNiznHZ",
    "outputId": "931134f8-ea61-4d05-e8be-1fec354ec269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 9.0270 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 8.9683 Accuracy 0.0071\n",
      "Epoch 1 Batch 100 Loss 8.8804 Accuracy 0.0294\n",
      "Epoch 1 Batch 150 Loss 8.7808 Accuracy 0.0375\n",
      "Epoch 1 Batch 200 Loss 8.6539 Accuracy 0.0416\n",
      "Epoch 1 Batch 250 Loss 8.5014 Accuracy 0.0441\n",
      "Epoch 1 Batch 300 Loss 8.3261 Accuracy 0.0467\n",
      "Epoch 1 Batch 350 Loss 8.1401 Accuracy 0.0542\n",
      "Epoch 1 Batch 400 Loss 7.9567 Accuracy 0.0624\n",
      "Epoch 1 Batch 450 Loss 7.7903 Accuracy 0.0694\n",
      "Epoch 1 Batch 500 Loss 7.6417 Accuracy 0.0766\n",
      "Epoch 1 Batch 550 Loss 7.5056 Accuracy 0.0842\n",
      "Epoch 1 Batch 600 Loss 7.3788 Accuracy 0.0916\n",
      "Epoch 1 Batch 650 Loss 7.2567 Accuracy 0.0990\n",
      "Epoch 1 Batch 700 Loss 7.1394 Accuracy 0.1064\n",
      "Epoch 1 Batch 750 Loss 7.0294 Accuracy 0.1135\n",
      "Epoch 1 Batch 800 Loss 6.9251 Accuracy 0.1202\n",
      "Epoch 1 Batch 850 Loss 6.8291 Accuracy 0.1267\n",
      "Epoch 1 Batch 900 Loss 6.7370 Accuracy 0.1329\n",
      "Epoch 1 Batch 950 Loss 6.6508 Accuracy 0.1389\n",
      "Epoch 1 Batch 1000 Loss 6.5717 Accuracy 0.1445\n",
      "Epoch 1 Batch 1050 Loss 6.4984 Accuracy 0.1499\n",
      "Epoch 1 Batch 1100 Loss 6.4291 Accuracy 0.1550\n",
      "Epoch 1 Batch 1150 Loss 6.3637 Accuracy 0.1599\n",
      "Epoch 1 Batch 1200 Loss 6.3011 Accuracy 0.1647\n",
      "Epoch 1 Batch 1250 Loss 6.2442 Accuracy 0.1691\n",
      "Epoch 1 Batch 1300 Loss 6.1898 Accuracy 0.1731\n",
      "Epoch 1 Batch 1350 Loss 6.1379 Accuracy 0.1771\n",
      "Epoch 1 Batch 1400 Loss 6.0892 Accuracy 0.1808\n",
      "Epoch 1 Batch 1450 Loss 6.0426 Accuracy 0.1844\n",
      "Epoch 1 Batch 1500 Loss 5.9971 Accuracy 0.1878\n",
      "Epoch 1 Batch 1550 Loss 5.9543 Accuracy 0.1911\n",
      "Epoch 1 Batch 1600 Loss 5.9140 Accuracy 0.1943\n",
      "Epoch 1 Batch 1650 Loss 5.8749 Accuracy 0.1973\n",
      "Epoch 1 Batch 1700 Loss 5.8381 Accuracy 0.2002\n",
      "Epoch 1 Batch 1750 Loss 5.8019 Accuracy 0.2031\n",
      "Epoch 1 Batch 1800 Loss 5.7673 Accuracy 0.2057\n",
      "Epoch 1 Batch 1850 Loss 5.7346 Accuracy 0.2083\n",
      "Epoch 1 Batch 1900 Loss 5.7029 Accuracy 0.2108\n",
      "Epoch 1 Batch 1950 Loss 5.6726 Accuracy 0.2131\n",
      "Epoch 1 Batch 2000 Loss 5.6434 Accuracy 0.2154\n",
      "Epoch 1 Batch 2050 Loss 5.6151 Accuracy 0.2176\n",
      "Epoch 1 Batch 2100 Loss 5.5876 Accuracy 0.2197\n",
      "Epoch 1 Batch 2150 Loss 5.5611 Accuracy 0.2218\n",
      "Epoch 1 Batch 2200 Loss 5.5350 Accuracy 0.2239\n",
      "Epoch 1 Batch 2250 Loss 5.5098 Accuracy 0.2259\n",
      "Epoch 1 Batch 2300 Loss 5.4851 Accuracy 0.2278\n",
      "Epoch 1 Batch 2350 Loss 5.4610 Accuracy 0.2297\n",
      "Epoch 1 Batch 2400 Loss 5.4386 Accuracy 0.2314\n",
      "Epoch 1 Batch 2450 Loss 5.4163 Accuracy 0.2332\n",
      "Epoch 1 Batch 2500 Loss 5.3949 Accuracy 0.2349\n",
      "Epoch 1 Batch 2550 Loss 5.3735 Accuracy 0.2366\n",
      "Epoch 1 Batch 2600 Loss 5.3529 Accuracy 0.2381\n",
      "Epoch 1 Loss 5.3431 Accuracy 0.2389\n",
      "Time taken for 1 epoch: 459.5653419494629 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 4.3040 Accuracy 0.3121\n",
      "Epoch 2 Batch 50 Loss 4.2572 Accuracy 0.3245\n",
      "Epoch 2 Batch 100 Loss 4.2546 Accuracy 0.3249\n",
      "Epoch 2 Batch 150 Loss 4.2314 Accuracy 0.3280\n",
      "Epoch 2 Batch 200 Loss 4.2286 Accuracy 0.3284\n",
      "Epoch 2 Batch 250 Loss 4.2227 Accuracy 0.3285\n",
      "Epoch 2 Batch 300 Loss 4.2127 Accuracy 0.3299\n",
      "Epoch 2 Batch 350 Loss 4.2020 Accuracy 0.3310\n",
      "Epoch 2 Batch 400 Loss 4.1966 Accuracy 0.3311\n",
      "Epoch 2 Batch 450 Loss 4.1887 Accuracy 0.3318\n",
      "Epoch 2 Batch 500 Loss 4.1787 Accuracy 0.3329\n",
      "Epoch 2 Batch 550 Loss 4.1691 Accuracy 0.3340\n",
      "Epoch 2 Batch 600 Loss 4.1606 Accuracy 0.3346\n",
      "Epoch 2 Batch 650 Loss 4.1521 Accuracy 0.3354\n",
      "Epoch 2 Batch 700 Loss 4.1453 Accuracy 0.3361\n",
      "Epoch 2 Batch 750 Loss 4.1364 Accuracy 0.3370\n",
      "Epoch 2 Batch 800 Loss 4.1287 Accuracy 0.3378\n",
      "Epoch 2 Batch 850 Loss 4.1188 Accuracy 0.3387\n",
      "Epoch 2 Batch 900 Loss 4.1101 Accuracy 0.3396\n",
      "Epoch 2 Batch 950 Loss 4.1014 Accuracy 0.3404\n",
      "Epoch 2 Batch 1000 Loss 4.0925 Accuracy 0.3413\n",
      "Epoch 2 Batch 1050 Loss 4.0849 Accuracy 0.3422\n",
      "Epoch 2 Batch 1100 Loss 4.0773 Accuracy 0.3430\n",
      "Epoch 2 Batch 1150 Loss 4.0696 Accuracy 0.3438\n",
      "Epoch 2 Batch 1200 Loss 4.0613 Accuracy 0.3447\n",
      "Epoch 2 Batch 1250 Loss 4.0533 Accuracy 0.3455\n",
      "Epoch 2 Batch 1300 Loss 4.0465 Accuracy 0.3462\n",
      "Epoch 2 Batch 1350 Loss 4.0388 Accuracy 0.3470\n",
      "Epoch 2 Batch 1400 Loss 4.0315 Accuracy 0.3478\n",
      "Epoch 2 Batch 1450 Loss 4.0231 Accuracy 0.3487\n",
      "Epoch 2 Batch 1500 Loss 4.0149 Accuracy 0.3497\n",
      "Epoch 2 Batch 1550 Loss 4.0075 Accuracy 0.3505\n",
      "Epoch 2 Batch 1600 Loss 3.9988 Accuracy 0.3514\n",
      "Epoch 2 Batch 1650 Loss 3.9918 Accuracy 0.3522\n",
      "Epoch 2 Batch 1700 Loss 3.9840 Accuracy 0.3531\n",
      "Epoch 2 Batch 1750 Loss 3.9766 Accuracy 0.3539\n",
      "Epoch 2 Batch 1800 Loss 3.9697 Accuracy 0.3546\n",
      "Epoch 2 Batch 1850 Loss 3.9612 Accuracy 0.3555\n",
      "Epoch 2 Batch 1900 Loss 3.9532 Accuracy 0.3564\n",
      "Epoch 2 Batch 1950 Loss 3.9463 Accuracy 0.3571\n",
      "Epoch 2 Batch 2000 Loss 3.9395 Accuracy 0.3578\n",
      "Epoch 2 Batch 2050 Loss 3.9318 Accuracy 0.3587\n",
      "Epoch 2 Batch 2100 Loss 3.9240 Accuracy 0.3595\n",
      "Epoch 2 Batch 2150 Loss 3.9166 Accuracy 0.3603\n",
      "Epoch 2 Batch 2200 Loss 3.9088 Accuracy 0.3612\n",
      "Epoch 2 Batch 2250 Loss 3.9015 Accuracy 0.3620\n",
      "Epoch 2 Batch 2300 Loss 3.8936 Accuracy 0.3628\n",
      "Epoch 2 Batch 2350 Loss 3.8856 Accuracy 0.3637\n",
      "Epoch 2 Batch 2400 Loss 3.8785 Accuracy 0.3645\n",
      "Epoch 2 Batch 2450 Loss 3.8709 Accuracy 0.3653\n",
      "Epoch 2 Batch 2500 Loss 3.8636 Accuracy 0.3661\n",
      "Epoch 2 Batch 2550 Loss 3.8565 Accuracy 0.3668\n",
      "Epoch 2 Batch 2600 Loss 3.8496 Accuracy 0.3675\n",
      "Epoch 2 Loss 3.8464 Accuracy 0.3678\n",
      "Time taken for 1 epoch: 168.79296350479126 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 3.4976 Accuracy 0.4137\n",
      "Epoch 3 Batch 50 Loss 3.4484 Accuracy 0.4115\n",
      "Epoch 3 Batch 100 Loss 3.4298 Accuracy 0.4131\n",
      "Epoch 3 Batch 150 Loss 3.4242 Accuracy 0.4133\n",
      "Epoch 3 Batch 200 Loss 3.4107 Accuracy 0.4145\n",
      "Epoch 3 Batch 250 Loss 3.4083 Accuracy 0.4147\n",
      "Epoch 3 Batch 300 Loss 3.4092 Accuracy 0.4145\n",
      "Epoch 3 Batch 350 Loss 3.4042 Accuracy 0.4152\n",
      "Epoch 3 Batch 400 Loss 3.4020 Accuracy 0.4154\n",
      "Epoch 3 Batch 450 Loss 3.3972 Accuracy 0.4159\n",
      "Epoch 3 Batch 500 Loss 3.3909 Accuracy 0.4165\n",
      "Epoch 3 Batch 550 Loss 3.3835 Accuracy 0.4175\n",
      "Epoch 3 Batch 600 Loss 3.3772 Accuracy 0.4181\n",
      "Epoch 3 Batch 650 Loss 3.3715 Accuracy 0.4188\n",
      "Epoch 3 Batch 700 Loss 3.3656 Accuracy 0.4194\n",
      "Epoch 3 Batch 750 Loss 3.3610 Accuracy 0.4199\n",
      "Epoch 3 Batch 800 Loss 3.3558 Accuracy 0.4205\n",
      "Epoch 3 Batch 850 Loss 3.3511 Accuracy 0.4209\n",
      "Epoch 3 Batch 900 Loss 3.3443 Accuracy 0.4217\n",
      "Epoch 3 Batch 950 Loss 3.3387 Accuracy 0.4222\n",
      "Epoch 3 Batch 1000 Loss 3.3343 Accuracy 0.4226\n",
      "Epoch 3 Batch 1050 Loss 3.3290 Accuracy 0.4233\n",
      "Epoch 3 Batch 1100 Loss 3.3243 Accuracy 0.4237\n",
      "Epoch 3 Batch 1150 Loss 3.3184 Accuracy 0.4244\n",
      "Epoch 3 Batch 1200 Loss 3.3134 Accuracy 0.4251\n",
      "Epoch 3 Batch 1250 Loss 3.3093 Accuracy 0.4256\n",
      "Epoch 3 Batch 1300 Loss 3.3051 Accuracy 0.4260\n",
      "Epoch 3 Batch 1350 Loss 3.2993 Accuracy 0.4268\n",
      "Epoch 3 Batch 1400 Loss 3.2946 Accuracy 0.4273\n",
      "Epoch 3 Batch 1450 Loss 3.2892 Accuracy 0.4278\n",
      "Epoch 3 Batch 1500 Loss 3.2851 Accuracy 0.4283\n",
      "Epoch 3 Batch 1550 Loss 3.2794 Accuracy 0.4290\n",
      "Epoch 3 Batch 1600 Loss 3.2738 Accuracy 0.4296\n",
      "Epoch 3 Batch 1650 Loss 3.2696 Accuracy 0.4301\n",
      "Epoch 3 Batch 1700 Loss 3.2654 Accuracy 0.4306\n",
      "Epoch 3 Batch 1750 Loss 3.2610 Accuracy 0.4311\n",
      "Epoch 3 Batch 1800 Loss 3.2569 Accuracy 0.4315\n",
      "Epoch 3 Batch 1850 Loss 3.2531 Accuracy 0.4320\n",
      "Epoch 3 Batch 1900 Loss 3.2487 Accuracy 0.4325\n",
      "Epoch 3 Batch 1950 Loss 3.2441 Accuracy 0.4330\n",
      "Epoch 3 Batch 2000 Loss 3.2399 Accuracy 0.4334\n",
      "Epoch 3 Batch 2050 Loss 3.2355 Accuracy 0.4340\n",
      "Epoch 3 Batch 2100 Loss 3.2316 Accuracy 0.4345\n",
      "Epoch 3 Batch 2150 Loss 3.2280 Accuracy 0.4348\n",
      "Epoch 3 Batch 2200 Loss 3.2240 Accuracy 0.4353\n",
      "Epoch 3 Batch 2250 Loss 3.2203 Accuracy 0.4357\n",
      "Epoch 3 Batch 2300 Loss 3.2157 Accuracy 0.4362\n",
      "Epoch 3 Batch 2350 Loss 3.2117 Accuracy 0.4366\n",
      "Epoch 3 Batch 2400 Loss 3.2074 Accuracy 0.4371\n",
      "Epoch 3 Batch 2450 Loss 3.2036 Accuracy 0.4375\n",
      "Epoch 3 Batch 2500 Loss 3.1995 Accuracy 0.4380\n",
      "Epoch 3 Batch 2550 Loss 3.1957 Accuracy 0.4384\n",
      "Epoch 3 Batch 2600 Loss 3.1916 Accuracy 0.4389\n",
      "Epoch 3 Loss 3.1898 Accuracy 0.4391\n",
      "Time taken for 1 epoch: 168.00084686279297 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 2.9400 Accuracy 0.4812\n",
      "Epoch 4 Batch 50 Loss 2.9496 Accuracy 0.4634\n",
      "Epoch 4 Batch 100 Loss 2.9593 Accuracy 0.4632\n",
      "Epoch 4 Batch 150 Loss 2.9623 Accuracy 0.4631\n",
      "Epoch 4 Batch 200 Loss 2.9570 Accuracy 0.4638\n",
      "Epoch 4 Batch 250 Loss 2.9467 Accuracy 0.4656\n",
      "Epoch 4 Batch 300 Loss 2.9450 Accuracy 0.4658\n",
      "Epoch 4 Batch 350 Loss 2.9390 Accuracy 0.4666\n",
      "Epoch 4 Batch 400 Loss 2.9405 Accuracy 0.4666\n",
      "Epoch 4 Batch 450 Loss 2.9374 Accuracy 0.4670\n",
      "Epoch 4 Batch 500 Loss 2.9346 Accuracy 0.4675\n",
      "Epoch 4 Batch 550 Loss 2.9332 Accuracy 0.4677\n",
      "Epoch 4 Batch 600 Loss 2.9308 Accuracy 0.4683\n",
      "Epoch 4 Batch 650 Loss 2.9261 Accuracy 0.4687\n",
      "Epoch 4 Batch 700 Loss 2.9227 Accuracy 0.4693\n",
      "Epoch 4 Batch 750 Loss 2.9193 Accuracy 0.4696\n",
      "Epoch 4 Batch 800 Loss 2.9169 Accuracy 0.4701\n",
      "Epoch 4 Batch 850 Loss 2.9142 Accuracy 0.4704\n",
      "Epoch 4 Batch 900 Loss 2.9111 Accuracy 0.4708\n",
      "Epoch 4 Batch 950 Loss 2.9082 Accuracy 0.4712\n",
      "Epoch 4 Batch 1000 Loss 2.9071 Accuracy 0.4712\n",
      "Epoch 4 Batch 1050 Loss 2.9043 Accuracy 0.4716\n",
      "Epoch 4 Batch 1100 Loss 2.9009 Accuracy 0.4719\n",
      "Epoch 4 Batch 1150 Loss 2.8995 Accuracy 0.4722\n",
      "Epoch 4 Batch 1200 Loss 2.8973 Accuracy 0.4724\n",
      "Epoch 4 Batch 1250 Loss 2.8958 Accuracy 0.4725\n",
      "Epoch 4 Batch 1300 Loss 2.8923 Accuracy 0.4729\n",
      "Epoch 4 Batch 1350 Loss 2.8896 Accuracy 0.4732\n",
      "Epoch 4 Batch 1400 Loss 2.8872 Accuracy 0.4736\n",
      "Epoch 4 Batch 1450 Loss 2.8845 Accuracy 0.4739\n",
      "Epoch 4 Batch 1500 Loss 2.8821 Accuracy 0.4742\n",
      "Epoch 4 Batch 1550 Loss 2.8796 Accuracy 0.4746\n",
      "Epoch 4 Batch 1600 Loss 2.8771 Accuracy 0.4749\n",
      "Epoch 4 Batch 1650 Loss 2.8746 Accuracy 0.4752\n",
      "Epoch 4 Batch 1700 Loss 2.8722 Accuracy 0.4755\n",
      "Epoch 4 Batch 1750 Loss 2.8702 Accuracy 0.4756\n",
      "Epoch 4 Batch 1800 Loss 2.8685 Accuracy 0.4758\n",
      "Epoch 4 Batch 1850 Loss 2.8664 Accuracy 0.4760\n",
      "Epoch 4 Batch 1900 Loss 2.8643 Accuracy 0.4763\n",
      "Epoch 4 Batch 1950 Loss 2.8620 Accuracy 0.4766\n",
      "Epoch 4 Batch 2000 Loss 2.8604 Accuracy 0.4769\n",
      "Epoch 4 Batch 2050 Loss 2.8579 Accuracy 0.4772\n",
      "Epoch 4 Batch 2100 Loss 2.8555 Accuracy 0.4775\n",
      "Epoch 4 Batch 2150 Loss 2.8533 Accuracy 0.4778\n",
      "Epoch 4 Batch 2200 Loss 2.8513 Accuracy 0.4780\n",
      "Epoch 4 Batch 2250 Loss 2.8491 Accuracy 0.4783\n",
      "Epoch 4 Batch 2300 Loss 2.8471 Accuracy 0.4785\n",
      "Epoch 4 Batch 2350 Loss 2.8448 Accuracy 0.4787\n",
      "Epoch 4 Batch 2400 Loss 2.8430 Accuracy 0.4789\n",
      "Epoch 4 Batch 2450 Loss 2.8412 Accuracy 0.4791\n",
      "Epoch 4 Batch 2500 Loss 2.8389 Accuracy 0.4793\n",
      "Epoch 4 Batch 2550 Loss 2.8368 Accuracy 0.4796\n",
      "Epoch 4 Batch 2600 Loss 2.8347 Accuracy 0.4798\n",
      "Epoch 4 Loss 2.8337 Accuracy 0.4800\n",
      "Time taken for 1 epoch: 166.4137783050537 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 2.7361 Accuracy 0.4794\n",
      "Epoch 5 Batch 50 Loss 2.7026 Accuracy 0.4932\n",
      "Epoch 5 Batch 100 Loss 2.6988 Accuracy 0.4946\n",
      "Epoch 5 Batch 150 Loss 2.6996 Accuracy 0.4950\n",
      "Epoch 5 Batch 200 Loss 2.7022 Accuracy 0.4953\n",
      "Epoch 5 Batch 250 Loss 2.6992 Accuracy 0.4958\n",
      "Epoch 5 Batch 300 Loss 2.6946 Accuracy 0.4961\n",
      "Epoch 5 Batch 350 Loss 2.6904 Accuracy 0.4965\n",
      "Epoch 5 Batch 400 Loss 2.6867 Accuracy 0.4973\n",
      "Epoch 5 Batch 450 Loss 2.6850 Accuracy 0.4975\n",
      "Epoch 5 Batch 500 Loss 2.6860 Accuracy 0.4975\n",
      "Epoch 5 Batch 550 Loss 2.6842 Accuracy 0.4977\n",
      "Epoch 5 Batch 600 Loss 2.6847 Accuracy 0.4976\n",
      "Epoch 5 Batch 650 Loss 2.6844 Accuracy 0.4977\n",
      "Epoch 5 Batch 700 Loss 2.6831 Accuracy 0.4979\n",
      "Epoch 5 Batch 750 Loss 2.6811 Accuracy 0.4982\n",
      "Epoch 5 Batch 800 Loss 2.6796 Accuracy 0.4985\n",
      "Epoch 5 Batch 850 Loss 2.6780 Accuracy 0.4987\n",
      "Epoch 5 Batch 900 Loss 2.6780 Accuracy 0.4986\n",
      "Epoch 5 Batch 950 Loss 2.6768 Accuracy 0.4988\n",
      "Epoch 5 Batch 1000 Loss 2.6751 Accuracy 0.4990\n",
      "Epoch 5 Batch 1050 Loss 2.6737 Accuracy 0.4991\n",
      "Epoch 5 Batch 1100 Loss 2.6705 Accuracy 0.4996\n",
      "Epoch 5 Batch 1150 Loss 2.6697 Accuracy 0.4997\n",
      "Epoch 5 Batch 1200 Loss 2.6693 Accuracy 0.4998\n",
      "Epoch 5 Batch 1250 Loss 2.6680 Accuracy 0.5001\n",
      "Epoch 5 Batch 1300 Loss 2.6658 Accuracy 0.5004\n",
      "Epoch 5 Batch 1350 Loss 2.6641 Accuracy 0.5005\n",
      "Epoch 5 Batch 1400 Loss 2.6631 Accuracy 0.5007\n",
      "Epoch 5 Batch 1450 Loss 2.6625 Accuracy 0.5008\n",
      "Epoch 5 Batch 1500 Loss 2.6614 Accuracy 0.5009\n",
      "Epoch 5 Batch 1550 Loss 2.6601 Accuracy 0.5011\n",
      "Epoch 5 Batch 1600 Loss 2.6599 Accuracy 0.5010\n",
      "Epoch 5 Batch 1650 Loss 2.6583 Accuracy 0.5013\n",
      "Epoch 5 Batch 1700 Loss 2.6566 Accuracy 0.5014\n",
      "Epoch 5 Batch 1750 Loss 2.6552 Accuracy 0.5016\n",
      "Epoch 5 Batch 1800 Loss 2.6538 Accuracy 0.5017\n",
      "Epoch 5 Batch 1850 Loss 2.6520 Accuracy 0.5020\n",
      "Epoch 5 Batch 1900 Loss 2.6511 Accuracy 0.5021\n",
      "Epoch 5 Batch 1950 Loss 2.6495 Accuracy 0.5022\n",
      "Epoch 5 Batch 2000 Loss 2.6483 Accuracy 0.5024\n",
      "Epoch 5 Batch 2050 Loss 2.6472 Accuracy 0.5025\n",
      "Epoch 5 Batch 2100 Loss 2.6463 Accuracy 0.5026\n",
      "Epoch 5 Batch 2150 Loss 2.6454 Accuracy 0.5027\n",
      "Epoch 5 Batch 2200 Loss 2.6438 Accuracy 0.5029\n",
      "Epoch 5 Batch 2250 Loss 2.6436 Accuracy 0.5029\n",
      "Epoch 5 Batch 2300 Loss 2.6428 Accuracy 0.5030\n",
      "Epoch 5 Batch 2350 Loss 2.6412 Accuracy 0.5032\n",
      "Epoch 5 Batch 2400 Loss 2.6403 Accuracy 0.5032\n",
      "Epoch 5 Batch 2450 Loss 2.6384 Accuracy 0.5034\n",
      "Epoch 5 Batch 2500 Loss 2.6377 Accuracy 0.5036\n",
      "Epoch 5 Batch 2550 Loss 2.6368 Accuracy 0.5037\n",
      "Epoch 5 Batch 2600 Loss 2.6356 Accuracy 0.5038\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-1\n",
      "Epoch 5 Loss 2.6351 Accuracy 0.5038\n",
      "Time taken for 1 epoch: 165.43188905715942 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 2.4198 Accuracy 0.5409\n",
      "Epoch 6 Batch 50 Loss 2.5444 Accuracy 0.5153\n",
      "Epoch 6 Batch 100 Loss 2.5447 Accuracy 0.5135\n",
      "Epoch 6 Batch 150 Loss 2.5395 Accuracy 0.5138\n",
      "Epoch 6 Batch 200 Loss 2.5340 Accuracy 0.5145\n",
      "Epoch 6 Batch 250 Loss 2.5346 Accuracy 0.5146\n",
      "Epoch 6 Batch 300 Loss 2.5374 Accuracy 0.5146\n",
      "Epoch 6 Batch 350 Loss 2.5377 Accuracy 0.5143\n",
      "Epoch 6 Batch 400 Loss 2.5418 Accuracy 0.5141\n",
      "Epoch 6 Batch 450 Loss 2.5410 Accuracy 0.5144\n",
      "Epoch 6 Batch 500 Loss 2.5404 Accuracy 0.5145\n",
      "Epoch 6 Batch 550 Loss 2.5378 Accuracy 0.5150\n",
      "Epoch 6 Batch 600 Loss 2.5371 Accuracy 0.5153\n",
      "Epoch 6 Batch 650 Loss 2.5351 Accuracy 0.5157\n",
      "Epoch 6 Batch 700 Loss 2.5358 Accuracy 0.5156\n",
      "Epoch 6 Batch 750 Loss 2.5358 Accuracy 0.5157\n",
      "Epoch 6 Batch 800 Loss 2.5356 Accuracy 0.5155\n",
      "Epoch 6 Batch 850 Loss 2.5353 Accuracy 0.5156\n",
      "Epoch 6 Batch 900 Loss 2.5353 Accuracy 0.5155\n",
      "Epoch 6 Batch 950 Loss 2.5336 Accuracy 0.5158\n",
      "Epoch 6 Batch 1000 Loss 2.5326 Accuracy 0.5160\n",
      "Epoch 6 Batch 1050 Loss 2.5309 Accuracy 0.5162\n",
      "Epoch 6 Batch 1100 Loss 2.5321 Accuracy 0.5161\n",
      "Epoch 6 Batch 1150 Loss 2.5305 Accuracy 0.5164\n",
      "Epoch 6 Batch 1200 Loss 2.5286 Accuracy 0.5166\n",
      "Epoch 6 Batch 1250 Loss 2.5282 Accuracy 0.5166\n",
      "Epoch 6 Batch 1300 Loss 2.5271 Accuracy 0.5168\n",
      "Epoch 6 Batch 1350 Loss 2.5262 Accuracy 0.5169\n",
      "Epoch 6 Batch 1400 Loss 2.5249 Accuracy 0.5171\n",
      "Epoch 6 Batch 1450 Loss 2.5234 Accuracy 0.5173\n",
      "Epoch 6 Batch 1500 Loss 2.5232 Accuracy 0.5174\n",
      "Epoch 6 Batch 1550 Loss 2.5229 Accuracy 0.5174\n",
      "Epoch 6 Batch 1600 Loss 2.5220 Accuracy 0.5175\n",
      "Epoch 6 Batch 1650 Loss 2.5210 Accuracy 0.5177\n",
      "Epoch 6 Batch 1700 Loss 2.5207 Accuracy 0.5178\n",
      "Epoch 6 Batch 1750 Loss 2.5196 Accuracy 0.5179\n",
      "Epoch 6 Batch 1800 Loss 2.5191 Accuracy 0.5180\n",
      "Epoch 6 Batch 1850 Loss 2.5183 Accuracy 0.5181\n",
      "Epoch 6 Batch 1900 Loss 2.5175 Accuracy 0.5182\n",
      "Epoch 6 Batch 1950 Loss 2.5162 Accuracy 0.5184\n",
      "Epoch 6 Batch 2000 Loss 2.5159 Accuracy 0.5185\n",
      "Epoch 6 Batch 2050 Loss 2.5149 Accuracy 0.5186\n",
      "Epoch 6 Batch 2100 Loss 2.5142 Accuracy 0.5187\n",
      "Epoch 6 Batch 2150 Loss 2.5136 Accuracy 0.5188\n",
      "Epoch 6 Batch 2200 Loss 2.5133 Accuracy 0.5188\n",
      "Epoch 6 Batch 2250 Loss 2.5122 Accuracy 0.5190\n",
      "Epoch 6 Batch 2300 Loss 2.5115 Accuracy 0.5191\n",
      "Epoch 6 Batch 2350 Loss 2.5107 Accuracy 0.5192\n",
      "Epoch 6 Batch 2400 Loss 2.5100 Accuracy 0.5192\n",
      "Epoch 6 Batch 2450 Loss 2.5091 Accuracy 0.5193\n",
      "Epoch 6 Batch 2500 Loss 2.5087 Accuracy 0.5194\n",
      "Epoch 6 Batch 2550 Loss 2.5082 Accuracy 0.5194\n",
      "Epoch 6 Batch 2600 Loss 2.5079 Accuracy 0.5195\n",
      "Epoch 6 Loss 2.5073 Accuracy 0.5195\n",
      "Time taken for 1 epoch: 165.34186220169067 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 2.4194 Accuracy 0.5334\n",
      "Epoch 7 Batch 50 Loss 2.4346 Accuracy 0.5298\n",
      "Epoch 7 Batch 100 Loss 2.4300 Accuracy 0.5285\n",
      "Epoch 7 Batch 150 Loss 2.4285 Accuracy 0.5293\n",
      "Epoch 7 Batch 200 Loss 2.4370 Accuracy 0.5276\n",
      "Epoch 7 Batch 250 Loss 2.4400 Accuracy 0.5277\n",
      "Epoch 7 Batch 300 Loss 2.4407 Accuracy 0.5276\n",
      "Epoch 7 Batch 350 Loss 2.4408 Accuracy 0.5276\n",
      "Epoch 7 Batch 400 Loss 2.4397 Accuracy 0.5276\n",
      "Epoch 7 Batch 450 Loss 2.4377 Accuracy 0.5277\n",
      "Epoch 7 Batch 500 Loss 2.4361 Accuracy 0.5280\n",
      "Epoch 7 Batch 550 Loss 2.4357 Accuracy 0.5280\n",
      "Epoch 7 Batch 600 Loss 2.4362 Accuracy 0.5279\n",
      "Epoch 7 Batch 650 Loss 2.4359 Accuracy 0.5279\n",
      "Epoch 7 Batch 700 Loss 2.4355 Accuracy 0.5279\n",
      "Epoch 7 Batch 750 Loss 2.4363 Accuracy 0.5278\n",
      "Epoch 7 Batch 800 Loss 2.4354 Accuracy 0.5280\n",
      "Epoch 7 Batch 850 Loss 2.4346 Accuracy 0.5281\n",
      "Epoch 7 Batch 900 Loss 2.4355 Accuracy 0.5281\n",
      "Epoch 7 Batch 950 Loss 2.4344 Accuracy 0.5282\n",
      "Epoch 7 Batch 1000 Loss 2.4334 Accuracy 0.5284\n",
      "Epoch 7 Batch 1050 Loss 2.4330 Accuracy 0.5286\n",
      "Epoch 7 Batch 1100 Loss 2.4309 Accuracy 0.5288\n",
      "Epoch 7 Batch 1150 Loss 2.4310 Accuracy 0.5288\n",
      "Epoch 7 Batch 1200 Loss 2.4304 Accuracy 0.5290\n",
      "Epoch 7 Batch 1250 Loss 2.4292 Accuracy 0.5292\n",
      "Epoch 7 Batch 1300 Loss 2.4284 Accuracy 0.5295\n",
      "Epoch 7 Batch 1350 Loss 2.4272 Accuracy 0.5297\n",
      "Epoch 7 Batch 1400 Loss 2.4264 Accuracy 0.5298\n",
      "Epoch 7 Batch 1450 Loss 2.4261 Accuracy 0.5299\n",
      "Epoch 7 Batch 1500 Loss 2.4255 Accuracy 0.5300\n",
      "Epoch 7 Batch 1550 Loss 2.4253 Accuracy 0.5299\n",
      "Epoch 7 Batch 1600 Loss 2.4249 Accuracy 0.5300\n",
      "Epoch 7 Batch 1650 Loss 2.4243 Accuracy 0.5301\n",
      "Epoch 7 Batch 1700 Loss 2.4234 Accuracy 0.5302\n",
      "Epoch 7 Batch 1750 Loss 2.4229 Accuracy 0.5303\n",
      "Epoch 7 Batch 1800 Loss 2.4226 Accuracy 0.5303\n",
      "Epoch 7 Batch 1850 Loss 2.4221 Accuracy 0.5304\n",
      "Epoch 7 Batch 1900 Loss 2.4218 Accuracy 0.5304\n",
      "Epoch 7 Batch 1950 Loss 2.4211 Accuracy 0.5305\n",
      "Epoch 7 Batch 2000 Loss 2.4208 Accuracy 0.5306\n",
      "Epoch 7 Batch 2050 Loss 2.4198 Accuracy 0.5307\n",
      "Epoch 7 Batch 2100 Loss 2.4200 Accuracy 0.5306\n",
      "Epoch 7 Batch 2150 Loss 2.4196 Accuracy 0.5307\n",
      "Epoch 7 Batch 2200 Loss 2.4182 Accuracy 0.5309\n",
      "Epoch 7 Batch 2250 Loss 2.4179 Accuracy 0.5309\n",
      "Epoch 7 Batch 2300 Loss 2.4175 Accuracy 0.5310\n",
      "Epoch 7 Batch 2350 Loss 2.4170 Accuracy 0.5310\n",
      "Epoch 7 Batch 2400 Loss 2.4166 Accuracy 0.5311\n",
      "Epoch 7 Batch 2450 Loss 2.4160 Accuracy 0.5312\n",
      "Epoch 7 Batch 2500 Loss 2.4156 Accuracy 0.5312\n",
      "Epoch 7 Batch 2550 Loss 2.4156 Accuracy 0.5312\n",
      "Epoch 7 Batch 2600 Loss 2.4148 Accuracy 0.5313\n",
      "Epoch 7 Loss 2.4146 Accuracy 0.5313\n",
      "Time taken for 1 epoch: 165.4800043106079 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 2.4522 Accuracy 0.5243\n",
      "Epoch 8 Batch 50 Loss 2.3658 Accuracy 0.5365\n",
      "Epoch 8 Batch 100 Loss 2.3682 Accuracy 0.5376\n",
      "Epoch 8 Batch 150 Loss 2.3661 Accuracy 0.5370\n",
      "Epoch 8 Batch 200 Loss 2.3593 Accuracy 0.5381\n",
      "Epoch 8 Batch 250 Loss 2.3633 Accuracy 0.5373\n",
      "Epoch 8 Batch 300 Loss 2.3614 Accuracy 0.5378\n",
      "Epoch 8 Batch 350 Loss 2.3589 Accuracy 0.5380\n",
      "Epoch 8 Batch 400 Loss 2.3583 Accuracy 0.5380\n",
      "Epoch 8 Batch 450 Loss 2.3601 Accuracy 0.5377\n",
      "Epoch 8 Batch 500 Loss 2.3612 Accuracy 0.5377\n",
      "Epoch 8 Batch 550 Loss 2.3599 Accuracy 0.5380\n",
      "Epoch 8 Batch 600 Loss 2.3597 Accuracy 0.5382\n",
      "Epoch 8 Batch 650 Loss 2.3578 Accuracy 0.5384\n",
      "Epoch 8 Batch 700 Loss 2.3585 Accuracy 0.5382\n",
      "Epoch 8 Batch 750 Loss 2.3583 Accuracy 0.5382\n",
      "Epoch 8 Batch 800 Loss 2.3580 Accuracy 0.5382\n",
      "Epoch 8 Batch 850 Loss 2.3581 Accuracy 0.5381\n",
      "Epoch 8 Batch 900 Loss 2.3576 Accuracy 0.5382\n",
      "Epoch 8 Batch 950 Loss 2.3586 Accuracy 0.5383\n",
      "Epoch 8 Batch 1000 Loss 2.3578 Accuracy 0.5384\n",
      "Epoch 8 Batch 1050 Loss 2.3584 Accuracy 0.5384\n",
      "Epoch 8 Batch 1100 Loss 2.3568 Accuracy 0.5385\n",
      "Epoch 8 Batch 1150 Loss 2.3566 Accuracy 0.5387\n",
      "Epoch 8 Batch 1200 Loss 2.3560 Accuracy 0.5388\n",
      "Epoch 8 Batch 1250 Loss 2.3557 Accuracy 0.5389\n",
      "Epoch 8 Batch 1300 Loss 2.3544 Accuracy 0.5391\n",
      "Epoch 8 Batch 1350 Loss 2.3544 Accuracy 0.5391\n",
      "Epoch 8 Batch 1400 Loss 2.3537 Accuracy 0.5392\n",
      "Epoch 8 Batch 1450 Loss 2.3527 Accuracy 0.5393\n",
      "Epoch 8 Batch 1500 Loss 2.3520 Accuracy 0.5394\n",
      "Epoch 8 Batch 1550 Loss 2.3519 Accuracy 0.5394\n",
      "Epoch 8 Batch 1600 Loss 2.3510 Accuracy 0.5395\n",
      "Epoch 8 Batch 1650 Loss 2.3504 Accuracy 0.5396\n",
      "Epoch 8 Batch 1700 Loss 2.3503 Accuracy 0.5396\n",
      "Epoch 8 Batch 1750 Loss 2.3496 Accuracy 0.5397\n",
      "Epoch 8 Batch 1800 Loss 2.3491 Accuracy 0.5398\n",
      "Epoch 8 Batch 1850 Loss 2.3487 Accuracy 0.5398\n",
      "Epoch 8 Batch 1900 Loss 2.3484 Accuracy 0.5399\n",
      "Epoch 8 Batch 1950 Loss 2.3476 Accuracy 0.5399\n",
      "Epoch 8 Batch 2000 Loss 2.3479 Accuracy 0.5399\n",
      "Epoch 8 Batch 2050 Loss 2.3470 Accuracy 0.5400\n",
      "Epoch 8 Batch 2100 Loss 2.3466 Accuracy 0.5401\n",
      "Epoch 8 Batch 2150 Loss 2.3461 Accuracy 0.5401\n",
      "Epoch 8 Batch 2200 Loss 2.3465 Accuracy 0.5400\n",
      "Epoch 8 Batch 2250 Loss 2.3461 Accuracy 0.5401\n",
      "Epoch 8 Batch 2300 Loss 2.3455 Accuracy 0.5402\n",
      "Epoch 8 Batch 2350 Loss 2.3454 Accuracy 0.5403\n",
      "Epoch 8 Batch 2400 Loss 2.3448 Accuracy 0.5404\n",
      "Epoch 8 Batch 2450 Loss 2.3446 Accuracy 0.5404\n",
      "Epoch 8 Batch 2500 Loss 2.3442 Accuracy 0.5405\n",
      "Epoch 8 Batch 2550 Loss 2.3440 Accuracy 0.5405\n",
      "Epoch 8 Batch 2600 Loss 2.3440 Accuracy 0.5405\n",
      "Epoch 8 Loss 2.3442 Accuracy 0.5405\n",
      "Time taken for 1 epoch: 165.57883667945862 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 2.3871 Accuracy 0.5265\n",
      "Epoch 9 Batch 50 Loss 2.3270 Accuracy 0.5441\n",
      "Epoch 9 Batch 100 Loss 2.2951 Accuracy 0.5482\n",
      "Epoch 9 Batch 150 Loss 2.2945 Accuracy 0.5481\n",
      "Epoch 9 Batch 200 Loss 2.2990 Accuracy 0.5469\n",
      "Epoch 9 Batch 250 Loss 2.3018 Accuracy 0.5465\n",
      "Epoch 9 Batch 300 Loss 2.2989 Accuracy 0.5467\n",
      "Epoch 9 Batch 350 Loss 2.3035 Accuracy 0.5458\n",
      "Epoch 9 Batch 400 Loss 2.3036 Accuracy 0.5454\n",
      "Epoch 9 Batch 450 Loss 2.3014 Accuracy 0.5460\n",
      "Epoch 9 Batch 500 Loss 2.3017 Accuracy 0.5458\n",
      "Epoch 9 Batch 550 Loss 2.2999 Accuracy 0.5459\n",
      "Epoch 9 Batch 600 Loss 2.2995 Accuracy 0.5461\n",
      "Epoch 9 Batch 650 Loss 2.2994 Accuracy 0.5461\n",
      "Epoch 9 Batch 700 Loss 2.2990 Accuracy 0.5462\n",
      "Epoch 9 Batch 750 Loss 2.2986 Accuracy 0.5464\n",
      "Epoch 9 Batch 800 Loss 2.2975 Accuracy 0.5465\n",
      "Epoch 9 Batch 850 Loss 2.2966 Accuracy 0.5467\n",
      "Epoch 9 Batch 900 Loss 2.2966 Accuracy 0.5466\n",
      "Epoch 9 Batch 950 Loss 2.2969 Accuracy 0.5465\n",
      "Epoch 9 Batch 1000 Loss 2.2979 Accuracy 0.5463\n",
      "Epoch 9 Batch 1050 Loss 2.2975 Accuracy 0.5464\n",
      "Epoch 9 Batch 1100 Loss 2.2969 Accuracy 0.5466\n",
      "Epoch 9 Batch 1150 Loss 2.2964 Accuracy 0.5466\n",
      "Epoch 9 Batch 1200 Loss 2.2952 Accuracy 0.5469\n",
      "Epoch 9 Batch 1250 Loss 2.2959 Accuracy 0.5469\n",
      "Epoch 9 Batch 1300 Loss 2.2954 Accuracy 0.5469\n",
      "Epoch 9 Batch 1350 Loss 2.2953 Accuracy 0.5469\n",
      "Epoch 9 Batch 1400 Loss 2.2945 Accuracy 0.5470\n",
      "Epoch 9 Batch 1450 Loss 2.2939 Accuracy 0.5471\n",
      "Epoch 9 Batch 1500 Loss 2.2928 Accuracy 0.5473\n",
      "Epoch 9 Batch 1550 Loss 2.2927 Accuracy 0.5473\n",
      "Epoch 9 Batch 1600 Loss 2.2925 Accuracy 0.5473\n",
      "Epoch 9 Batch 1650 Loss 2.2929 Accuracy 0.5473\n",
      "Epoch 9 Batch 1700 Loss 2.2926 Accuracy 0.5473\n",
      "Epoch 9 Batch 1750 Loss 2.2920 Accuracy 0.5474\n",
      "Epoch 9 Batch 1800 Loss 2.2915 Accuracy 0.5475\n",
      "Epoch 9 Batch 1850 Loss 2.2915 Accuracy 0.5475\n",
      "Epoch 9 Batch 1900 Loss 2.2920 Accuracy 0.5474\n",
      "Epoch 9 Batch 1950 Loss 2.2916 Accuracy 0.5474\n",
      "Epoch 9 Batch 2000 Loss 2.2911 Accuracy 0.5475\n",
      "Epoch 9 Batch 2050 Loss 2.2908 Accuracy 0.5475\n",
      "Epoch 9 Batch 2100 Loss 2.2898 Accuracy 0.5477\n",
      "Epoch 9 Batch 2150 Loss 2.2902 Accuracy 0.5476\n",
      "Epoch 9 Batch 2200 Loss 2.2897 Accuracy 0.5477\n",
      "Epoch 9 Batch 2250 Loss 2.2899 Accuracy 0.5477\n",
      "Epoch 9 Batch 2300 Loss 2.2895 Accuracy 0.5477\n",
      "Epoch 9 Batch 2350 Loss 2.2890 Accuracy 0.5478\n",
      "Epoch 9 Batch 2400 Loss 2.2895 Accuracy 0.5477\n",
      "Epoch 9 Batch 2450 Loss 2.2894 Accuracy 0.5477\n",
      "Epoch 9 Batch 2500 Loss 2.2889 Accuracy 0.5477\n",
      "Epoch 9 Batch 2550 Loss 2.2888 Accuracy 0.5477\n",
      "Epoch 9 Batch 2600 Loss 2.2884 Accuracy 0.5478\n",
      "Epoch 9 Loss 2.2882 Accuracy 0.5478\n",
      "Time taken for 1 epoch: 169.6482617855072 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 2.1396 Accuracy 0.5731\n",
      "Epoch 10 Batch 50 Loss 2.2315 Accuracy 0.5565\n",
      "Epoch 10 Batch 100 Loss 2.2268 Accuracy 0.5572\n",
      "Epoch 10 Batch 150 Loss 2.2320 Accuracy 0.5563\n",
      "Epoch 10 Batch 200 Loss 2.2391 Accuracy 0.5549\n",
      "Epoch 10 Batch 250 Loss 2.2369 Accuracy 0.5551\n",
      "Epoch 10 Batch 300 Loss 2.2390 Accuracy 0.5548\n",
      "Epoch 10 Batch 350 Loss 2.2390 Accuracy 0.5549\n",
      "Epoch 10 Batch 400 Loss 2.2402 Accuracy 0.5546\n",
      "Epoch 10 Batch 450 Loss 2.2430 Accuracy 0.5540\n",
      "Epoch 10 Batch 500 Loss 2.2431 Accuracy 0.5538\n",
      "Epoch 10 Batch 550 Loss 2.2441 Accuracy 0.5537\n",
      "Epoch 10 Batch 600 Loss 2.2438 Accuracy 0.5536\n",
      "Epoch 10 Batch 650 Loss 2.2434 Accuracy 0.5537\n",
      "Epoch 10 Batch 700 Loss 2.2431 Accuracy 0.5536\n",
      "Epoch 10 Batch 750 Loss 2.2460 Accuracy 0.5530\n",
      "Epoch 10 Batch 800 Loss 2.2465 Accuracy 0.5531\n",
      "Epoch 10 Batch 850 Loss 2.2444 Accuracy 0.5534\n",
      "Epoch 10 Batch 900 Loss 2.2451 Accuracy 0.5533\n",
      "Epoch 10 Batch 950 Loss 2.2453 Accuracy 0.5534\n",
      "Epoch 10 Batch 1000 Loss 2.2456 Accuracy 0.5533\n",
      "Epoch 10 Batch 1050 Loss 2.2459 Accuracy 0.5533\n",
      "Epoch 10 Batch 1100 Loss 2.2455 Accuracy 0.5534\n",
      "Epoch 10 Batch 1150 Loss 2.2472 Accuracy 0.5532\n",
      "Epoch 10 Batch 1200 Loss 2.2465 Accuracy 0.5534\n",
      "Epoch 10 Batch 1250 Loss 2.2467 Accuracy 0.5533\n",
      "Epoch 10 Batch 1300 Loss 2.2462 Accuracy 0.5534\n",
      "Epoch 10 Batch 1350 Loss 2.2461 Accuracy 0.5534\n",
      "Epoch 10 Batch 1400 Loss 2.2448 Accuracy 0.5536\n",
      "Epoch 10 Batch 1450 Loss 2.2449 Accuracy 0.5537\n",
      "Epoch 10 Batch 1500 Loss 2.2448 Accuracy 0.5537\n",
      "Epoch 10 Batch 1550 Loss 2.2446 Accuracy 0.5538\n",
      "Epoch 10 Batch 1600 Loss 2.2450 Accuracy 0.5538\n",
      "Epoch 10 Batch 1650 Loss 2.2448 Accuracy 0.5538\n",
      "Epoch 10 Batch 1700 Loss 2.2436 Accuracy 0.5539\n",
      "Epoch 10 Batch 1750 Loss 2.2436 Accuracy 0.5539\n",
      "Epoch 10 Batch 1800 Loss 2.2432 Accuracy 0.5539\n",
      "Epoch 10 Batch 1850 Loss 2.2433 Accuracy 0.5539\n",
      "Epoch 10 Batch 1900 Loss 2.2428 Accuracy 0.5540\n",
      "Epoch 10 Batch 1950 Loss 2.2426 Accuracy 0.5541\n",
      "Epoch 10 Batch 2000 Loss 2.2422 Accuracy 0.5542\n",
      "Epoch 10 Batch 2050 Loss 2.2420 Accuracy 0.5542\n",
      "Epoch 10 Batch 2100 Loss 2.2419 Accuracy 0.5543\n",
      "Epoch 10 Batch 2150 Loss 2.2417 Accuracy 0.5544\n",
      "Epoch 10 Batch 2200 Loss 2.2415 Accuracy 0.5544\n",
      "Epoch 10 Batch 2250 Loss 2.2418 Accuracy 0.5543\n",
      "Epoch 10 Batch 2300 Loss 2.2415 Accuracy 0.5544\n",
      "Epoch 10 Batch 2350 Loss 2.2414 Accuracy 0.5544\n",
      "Epoch 10 Batch 2400 Loss 2.2414 Accuracy 0.5544\n",
      "Epoch 10 Batch 2450 Loss 2.2406 Accuracy 0.5545\n",
      "Epoch 10 Batch 2500 Loss 2.2413 Accuracy 0.5544\n",
      "Epoch 10 Batch 2550 Loss 2.2409 Accuracy 0.5544\n",
      "Epoch 10 Batch 2600 Loss 2.2412 Accuracy 0.5543\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-2\n",
      "Epoch 10 Loss 2.2410 Accuracy 0.5544\n",
      "Time taken for 1 epoch: 171.90347385406494 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 2.0598 Accuracy 0.5897\n",
      "Epoch 11 Batch 50 Loss 2.1957 Accuracy 0.5597\n",
      "Epoch 11 Batch 100 Loss 2.2009 Accuracy 0.5590\n",
      "Epoch 11 Batch 150 Loss 2.2025 Accuracy 0.5587\n",
      "Epoch 11 Batch 200 Loss 2.2032 Accuracy 0.5584\n",
      "Epoch 11 Batch 250 Loss 2.2015 Accuracy 0.5592\n",
      "Epoch 11 Batch 300 Loss 2.2003 Accuracy 0.5596\n",
      "Epoch 11 Batch 350 Loss 2.2018 Accuracy 0.5596\n",
      "Epoch 11 Batch 400 Loss 2.2048 Accuracy 0.5592\n",
      "Epoch 11 Batch 450 Loss 2.2071 Accuracy 0.5588\n",
      "Epoch 11 Batch 500 Loss 2.2064 Accuracy 0.5591\n",
      "Epoch 11 Batch 550 Loss 2.2049 Accuracy 0.5592\n",
      "Epoch 11 Batch 600 Loss 2.2043 Accuracy 0.5593\n",
      "Epoch 11 Batch 650 Loss 2.2027 Accuracy 0.5594\n",
      "Epoch 11 Batch 700 Loss 2.2052 Accuracy 0.5591\n",
      "Epoch 11 Batch 750 Loss 2.2045 Accuracy 0.5592\n",
      "Epoch 11 Batch 800 Loss 2.2051 Accuracy 0.5592\n",
      "Epoch 11 Batch 850 Loss 2.2061 Accuracy 0.5590\n",
      "Epoch 11 Batch 900 Loss 2.2057 Accuracy 0.5591\n",
      "Epoch 11 Batch 950 Loss 2.2059 Accuracy 0.5590\n",
      "Epoch 11 Batch 1000 Loss 2.2069 Accuracy 0.5589\n",
      "Epoch 11 Batch 1050 Loss 2.2079 Accuracy 0.5586\n",
      "Epoch 11 Batch 1100 Loss 2.2067 Accuracy 0.5589\n",
      "Epoch 11 Batch 1150 Loss 2.2058 Accuracy 0.5590\n",
      "Epoch 11 Batch 1200 Loss 2.2061 Accuracy 0.5591\n",
      "Epoch 11 Batch 1250 Loss 2.2056 Accuracy 0.5592\n",
      "Epoch 11 Batch 1300 Loss 2.2050 Accuracy 0.5593\n",
      "Epoch 11 Batch 1350 Loss 2.2045 Accuracy 0.5594\n",
      "Epoch 11 Batch 1400 Loss 2.2046 Accuracy 0.5594\n",
      "Epoch 11 Batch 1450 Loss 2.2035 Accuracy 0.5596\n",
      "Epoch 11 Batch 1500 Loss 2.2045 Accuracy 0.5594\n",
      "Epoch 11 Batch 1550 Loss 2.2045 Accuracy 0.5595\n",
      "Epoch 11 Batch 1600 Loss 2.2053 Accuracy 0.5594\n",
      "Epoch 11 Batch 1650 Loss 2.2046 Accuracy 0.5595\n",
      "Epoch 11 Batch 1700 Loss 2.2042 Accuracy 0.5596\n",
      "Epoch 11 Batch 1750 Loss 2.2039 Accuracy 0.5596\n",
      "Epoch 11 Batch 1800 Loss 2.2039 Accuracy 0.5595\n",
      "Epoch 11 Batch 1850 Loss 2.2037 Accuracy 0.5596\n",
      "Epoch 11 Batch 1900 Loss 2.2040 Accuracy 0.5595\n",
      "Epoch 11 Batch 1950 Loss 2.2038 Accuracy 0.5595\n",
      "Epoch 11 Batch 2000 Loss 2.2035 Accuracy 0.5595\n",
      "Epoch 11 Batch 2050 Loss 2.2034 Accuracy 0.5595\n",
      "Epoch 11 Batch 2100 Loss 2.2030 Accuracy 0.5596\n",
      "Epoch 11 Batch 2150 Loss 2.2028 Accuracy 0.5596\n",
      "Epoch 11 Batch 2200 Loss 2.2027 Accuracy 0.5596\n",
      "Epoch 11 Batch 2250 Loss 2.2026 Accuracy 0.5597\n",
      "Epoch 11 Batch 2300 Loss 2.2024 Accuracy 0.5597\n",
      "Epoch 11 Batch 2350 Loss 2.2022 Accuracy 0.5597\n",
      "Epoch 11 Batch 2400 Loss 2.2024 Accuracy 0.5597\n",
      "Epoch 11 Batch 2450 Loss 2.2018 Accuracy 0.5597\n",
      "Epoch 11 Batch 2500 Loss 2.2022 Accuracy 0.5596\n",
      "Epoch 11 Batch 2550 Loss 2.2019 Accuracy 0.5597\n",
      "Epoch 11 Batch 2600 Loss 2.2021 Accuracy 0.5596\n",
      "Epoch 11 Loss 2.2018 Accuracy 0.5597\n",
      "Time taken for 1 epoch: 166.30353379249573 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 2.3126 Accuracy 0.5405\n",
      "Epoch 12 Batch 50 Loss 2.1474 Accuracy 0.5681\n",
      "Epoch 12 Batch 100 Loss 2.1676 Accuracy 0.5638\n",
      "Epoch 12 Batch 150 Loss 2.1699 Accuracy 0.5637\n",
      "Epoch 12 Batch 200 Loss 2.1713 Accuracy 0.5630\n",
      "Epoch 12 Batch 250 Loss 2.1705 Accuracy 0.5634\n",
      "Epoch 12 Batch 300 Loss 2.1732 Accuracy 0.5632\n",
      "Epoch 12 Batch 350 Loss 2.1753 Accuracy 0.5631\n",
      "Epoch 12 Batch 400 Loss 2.1759 Accuracy 0.5630\n",
      "Epoch 12 Batch 450 Loss 2.1755 Accuracy 0.5629\n",
      "Epoch 12 Batch 500 Loss 2.1748 Accuracy 0.5628\n",
      "Epoch 12 Batch 550 Loss 2.1738 Accuracy 0.5630\n",
      "Epoch 12 Batch 600 Loss 2.1748 Accuracy 0.5629\n",
      "Epoch 12 Batch 650 Loss 2.1750 Accuracy 0.5632\n",
      "Epoch 12 Batch 700 Loss 2.1747 Accuracy 0.5632\n",
      "Epoch 12 Batch 750 Loss 2.1733 Accuracy 0.5632\n",
      "Epoch 12 Batch 800 Loss 2.1726 Accuracy 0.5634\n",
      "Epoch 12 Batch 850 Loss 2.1720 Accuracy 0.5633\n",
      "Epoch 12 Batch 900 Loss 2.1725 Accuracy 0.5633\n",
      "Epoch 12 Batch 950 Loss 2.1725 Accuracy 0.5634\n",
      "Epoch 12 Batch 1000 Loss 2.1738 Accuracy 0.5632\n",
      "Epoch 12 Batch 1050 Loss 2.1736 Accuracy 0.5632\n",
      "Epoch 12 Batch 1100 Loss 2.1726 Accuracy 0.5634\n",
      "Epoch 12 Batch 1150 Loss 2.1720 Accuracy 0.5636\n",
      "Epoch 12 Batch 1200 Loss 2.1708 Accuracy 0.5636\n",
      "Epoch 12 Batch 1250 Loss 2.1705 Accuracy 0.5636\n",
      "Epoch 12 Batch 1300 Loss 2.1710 Accuracy 0.5636\n",
      "Epoch 12 Batch 1350 Loss 2.1708 Accuracy 0.5637\n",
      "Epoch 12 Batch 1400 Loss 2.1715 Accuracy 0.5636\n",
      "Epoch 12 Batch 1450 Loss 2.1710 Accuracy 0.5637\n",
      "Epoch 12 Batch 1500 Loss 2.1708 Accuracy 0.5638\n",
      "Epoch 12 Batch 1550 Loss 2.1707 Accuracy 0.5638\n",
      "Epoch 12 Batch 1600 Loss 2.1709 Accuracy 0.5637\n",
      "Epoch 12 Batch 1650 Loss 2.1712 Accuracy 0.5637\n",
      "Epoch 12 Batch 1700 Loss 2.1713 Accuracy 0.5636\n",
      "Epoch 12 Batch 1750 Loss 2.1713 Accuracy 0.5636\n",
      "Epoch 12 Batch 1800 Loss 2.1713 Accuracy 0.5637\n",
      "Epoch 12 Batch 1850 Loss 2.1713 Accuracy 0.5637\n",
      "Epoch 12 Batch 1900 Loss 2.1708 Accuracy 0.5637\n",
      "Epoch 12 Batch 1950 Loss 2.1703 Accuracy 0.5637\n",
      "Epoch 12 Batch 2000 Loss 2.1694 Accuracy 0.5639\n",
      "Epoch 12 Batch 2050 Loss 2.1695 Accuracy 0.5639\n",
      "Epoch 12 Batch 2100 Loss 2.1692 Accuracy 0.5639\n",
      "Epoch 12 Batch 2150 Loss 2.1697 Accuracy 0.5638\n",
      "Epoch 12 Batch 2200 Loss 2.1699 Accuracy 0.5639\n",
      "Epoch 12 Batch 2250 Loss 2.1699 Accuracy 0.5639\n",
      "Epoch 12 Batch 2300 Loss 2.1696 Accuracy 0.5639\n",
      "Epoch 12 Batch 2350 Loss 2.1690 Accuracy 0.5641\n",
      "Epoch 12 Batch 2400 Loss 2.1687 Accuracy 0.5640\n",
      "Epoch 12 Batch 2450 Loss 2.1694 Accuracy 0.5639\n",
      "Epoch 12 Batch 2500 Loss 2.1696 Accuracy 0.5639\n",
      "Epoch 12 Batch 2550 Loss 2.1692 Accuracy 0.5639\n",
      "Epoch 12 Batch 2600 Loss 2.1689 Accuracy 0.5640\n",
      "Epoch 12 Loss 2.1687 Accuracy 0.5640\n",
      "Time taken for 1 epoch: 166.13710403442383 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 2.1359 Accuracy 0.5720\n",
      "Epoch 13 Batch 50 Loss 2.1365 Accuracy 0.5694\n",
      "Epoch 13 Batch 100 Loss 2.1480 Accuracy 0.5671\n",
      "Epoch 13 Batch 150 Loss 2.1444 Accuracy 0.5674\n",
      "Epoch 13 Batch 200 Loss 2.1428 Accuracy 0.5674\n",
      "Epoch 13 Batch 250 Loss 2.1458 Accuracy 0.5667\n",
      "Epoch 13 Batch 300 Loss 2.1451 Accuracy 0.5671\n",
      "Epoch 13 Batch 350 Loss 2.1438 Accuracy 0.5677\n",
      "Epoch 13 Batch 400 Loss 2.1444 Accuracy 0.5676\n",
      "Epoch 13 Batch 450 Loss 2.1436 Accuracy 0.5676\n",
      "Epoch 13 Batch 500 Loss 2.1426 Accuracy 0.5679\n",
      "Epoch 13 Batch 550 Loss 2.1431 Accuracy 0.5677\n",
      "Epoch 13 Batch 600 Loss 2.1419 Accuracy 0.5679\n",
      "Epoch 13 Batch 650 Loss 2.1420 Accuracy 0.5678\n",
      "Epoch 13 Batch 700 Loss 2.1419 Accuracy 0.5678\n",
      "Epoch 13 Batch 750 Loss 2.1407 Accuracy 0.5680\n",
      "Epoch 13 Batch 800 Loss 2.1407 Accuracy 0.5680\n",
      "Epoch 13 Batch 850 Loss 2.1401 Accuracy 0.5681\n",
      "Epoch 13 Batch 900 Loss 2.1420 Accuracy 0.5679\n",
      "Epoch 13 Batch 950 Loss 2.1429 Accuracy 0.5679\n",
      "Epoch 13 Batch 1000 Loss 2.1432 Accuracy 0.5679\n",
      "Epoch 13 Batch 1050 Loss 2.1428 Accuracy 0.5680\n",
      "Epoch 13 Batch 1100 Loss 2.1418 Accuracy 0.5681\n",
      "Epoch 13 Batch 1150 Loss 2.1418 Accuracy 0.5681\n",
      "Epoch 13 Batch 1200 Loss 2.1421 Accuracy 0.5682\n",
      "Epoch 13 Batch 1250 Loss 2.1411 Accuracy 0.5683\n",
      "Epoch 13 Batch 1300 Loss 2.1412 Accuracy 0.5683\n",
      "Epoch 13 Batch 1350 Loss 2.1415 Accuracy 0.5682\n",
      "Epoch 13 Batch 1400 Loss 2.1410 Accuracy 0.5682\n",
      "Epoch 13 Batch 1450 Loss 2.1407 Accuracy 0.5682\n",
      "Epoch 13 Batch 1500 Loss 2.1404 Accuracy 0.5683\n",
      "Epoch 13 Batch 1550 Loss 2.1398 Accuracy 0.5684\n",
      "Epoch 13 Batch 1600 Loss 2.1390 Accuracy 0.5685\n",
      "Epoch 13 Batch 1650 Loss 2.1394 Accuracy 0.5684\n",
      "Epoch 13 Batch 1700 Loss 2.1395 Accuracy 0.5684\n",
      "Epoch 13 Batch 1750 Loss 2.1394 Accuracy 0.5685\n",
      "Epoch 13 Batch 1800 Loss 2.1390 Accuracy 0.5685\n",
      "Epoch 13 Batch 1850 Loss 2.1393 Accuracy 0.5685\n",
      "Epoch 13 Batch 1900 Loss 2.1389 Accuracy 0.5686\n",
      "Epoch 13 Batch 1950 Loss 2.1389 Accuracy 0.5685\n",
      "Epoch 13 Batch 2000 Loss 2.1390 Accuracy 0.5685\n",
      "Epoch 13 Batch 2050 Loss 2.1393 Accuracy 0.5684\n",
      "Epoch 13 Batch 2100 Loss 2.1392 Accuracy 0.5684\n",
      "Epoch 13 Batch 2150 Loss 2.1386 Accuracy 0.5685\n",
      "Epoch 13 Batch 2200 Loss 2.1384 Accuracy 0.5685\n",
      "Epoch 13 Batch 2250 Loss 2.1384 Accuracy 0.5685\n",
      "Epoch 13 Batch 2300 Loss 2.1378 Accuracy 0.5686\n",
      "Epoch 13 Batch 2350 Loss 2.1379 Accuracy 0.5686\n",
      "Epoch 13 Batch 2400 Loss 2.1376 Accuracy 0.5686\n",
      "Epoch 13 Batch 2450 Loss 2.1376 Accuracy 0.5686\n",
      "Epoch 13 Batch 2500 Loss 2.1377 Accuracy 0.5686\n",
      "Epoch 13 Batch 2550 Loss 2.1377 Accuracy 0.5686\n",
      "Epoch 13 Batch 2600 Loss 2.1379 Accuracy 0.5685\n",
      "Epoch 13 Loss 2.1382 Accuracy 0.5685\n",
      "Time taken for 1 epoch: 164.89954328536987 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 2.0218 Accuracy 0.5896\n",
      "Epoch 14 Batch 50 Loss 2.1050 Accuracy 0.5719\n",
      "Epoch 14 Batch 100 Loss 2.1014 Accuracy 0.5721\n",
      "Epoch 14 Batch 150 Loss 2.1089 Accuracy 0.5709\n",
      "Epoch 14 Batch 200 Loss 2.1065 Accuracy 0.5709\n",
      "Epoch 14 Batch 250 Loss 2.1082 Accuracy 0.5710\n",
      "Epoch 14 Batch 300 Loss 2.1109 Accuracy 0.5709\n",
      "Epoch 14 Batch 350 Loss 2.1143 Accuracy 0.5705\n",
      "Epoch 14 Batch 400 Loss 2.1160 Accuracy 0.5705\n",
      "Epoch 14 Batch 450 Loss 2.1176 Accuracy 0.5705\n",
      "Epoch 14 Batch 500 Loss 2.1166 Accuracy 0.5707\n",
      "Epoch 14 Batch 550 Loss 2.1153 Accuracy 0.5712\n",
      "Epoch 14 Batch 600 Loss 2.1166 Accuracy 0.5710\n",
      "Epoch 14 Batch 650 Loss 2.1156 Accuracy 0.5711\n",
      "Epoch 14 Batch 700 Loss 2.1146 Accuracy 0.5710\n",
      "Epoch 14 Batch 750 Loss 2.1133 Accuracy 0.5712\n",
      "Epoch 14 Batch 800 Loss 2.1148 Accuracy 0.5709\n",
      "Epoch 14 Batch 850 Loss 2.1146 Accuracy 0.5709\n",
      "Epoch 14 Batch 900 Loss 2.1151 Accuracy 0.5709\n",
      "Epoch 14 Batch 950 Loss 2.1159 Accuracy 0.5709\n",
      "Epoch 14 Batch 1000 Loss 2.1159 Accuracy 0.5711\n",
      "Epoch 14 Batch 1050 Loss 2.1155 Accuracy 0.5712\n",
      "Epoch 14 Batch 1100 Loss 2.1150 Accuracy 0.5713\n",
      "Epoch 14 Batch 1150 Loss 2.1152 Accuracy 0.5712\n",
      "Epoch 14 Batch 1200 Loss 2.1148 Accuracy 0.5713\n",
      "Epoch 14 Batch 1250 Loss 2.1146 Accuracy 0.5713\n",
      "Epoch 14 Batch 1300 Loss 2.1145 Accuracy 0.5714\n",
      "Epoch 14 Batch 1350 Loss 2.1132 Accuracy 0.5716\n",
      "Epoch 14 Batch 1400 Loss 2.1137 Accuracy 0.5716\n",
      "Epoch 14 Batch 1450 Loss 2.1134 Accuracy 0.5717\n",
      "Epoch 14 Batch 1500 Loss 2.1139 Accuracy 0.5716\n",
      "Epoch 14 Batch 1550 Loss 2.1132 Accuracy 0.5718\n",
      "Epoch 14 Batch 1600 Loss 2.1137 Accuracy 0.5718\n",
      "Epoch 14 Batch 1650 Loss 2.1131 Accuracy 0.5719\n",
      "Epoch 14 Batch 1700 Loss 2.1129 Accuracy 0.5719\n",
      "Epoch 14 Batch 1750 Loss 2.1134 Accuracy 0.5718\n",
      "Epoch 14 Batch 1800 Loss 2.1132 Accuracy 0.5718\n",
      "Epoch 14 Batch 1850 Loss 2.1132 Accuracy 0.5718\n",
      "Epoch 14 Batch 1900 Loss 2.1138 Accuracy 0.5717\n",
      "Epoch 14 Batch 1950 Loss 2.1135 Accuracy 0.5717\n",
      "Epoch 14 Batch 2000 Loss 2.1133 Accuracy 0.5717\n",
      "Epoch 14 Batch 2050 Loss 2.1127 Accuracy 0.5718\n",
      "Epoch 14 Batch 2100 Loss 2.1128 Accuracy 0.5718\n",
      "Epoch 14 Batch 2150 Loss 2.1125 Accuracy 0.5719\n",
      "Epoch 14 Batch 2200 Loss 2.1123 Accuracy 0.5719\n",
      "Epoch 14 Batch 2250 Loss 2.1123 Accuracy 0.5719\n",
      "Epoch 14 Batch 2300 Loss 2.1125 Accuracy 0.5719\n",
      "Epoch 14 Batch 2350 Loss 2.1123 Accuracy 0.5719\n",
      "Epoch 14 Batch 2400 Loss 2.1121 Accuracy 0.5719\n",
      "Epoch 14 Batch 2450 Loss 2.1120 Accuracy 0.5719\n",
      "Epoch 14 Batch 2500 Loss 2.1124 Accuracy 0.5718\n",
      "Epoch 14 Batch 2550 Loss 2.1125 Accuracy 0.5718\n",
      "Epoch 14 Batch 2600 Loss 2.1130 Accuracy 0.5718\n",
      "Epoch 14 Loss 2.1135 Accuracy 0.5717\n",
      "Time taken for 1 epoch: 163.67085695266724 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 2.0638 Accuracy 0.5883\n",
      "Epoch 15 Batch 50 Loss 2.0967 Accuracy 0.5746\n",
      "Epoch 15 Batch 100 Loss 2.0905 Accuracy 0.5750\n",
      "Epoch 15 Batch 150 Loss 2.0865 Accuracy 0.5746\n",
      "Epoch 15 Batch 200 Loss 2.0890 Accuracy 0.5742\n",
      "Epoch 15 Batch 250 Loss 2.0904 Accuracy 0.5740\n",
      "Epoch 15 Batch 300 Loss 2.0907 Accuracy 0.5740\n",
      "Epoch 15 Batch 350 Loss 2.0927 Accuracy 0.5737\n",
      "Epoch 15 Batch 400 Loss 2.0950 Accuracy 0.5731\n",
      "Epoch 15 Batch 450 Loss 2.0932 Accuracy 0.5735\n",
      "Epoch 15 Batch 500 Loss 2.0925 Accuracy 0.5735\n",
      "Epoch 15 Batch 550 Loss 2.0944 Accuracy 0.5736\n",
      "Epoch 15 Batch 600 Loss 2.0931 Accuracy 0.5738\n",
      "Epoch 15 Batch 650 Loss 2.0918 Accuracy 0.5742\n",
      "Epoch 15 Batch 700 Loss 2.0913 Accuracy 0.5741\n",
      "Epoch 15 Batch 750 Loss 2.0911 Accuracy 0.5742\n",
      "Epoch 15 Batch 800 Loss 2.0921 Accuracy 0.5740\n",
      "Epoch 15 Batch 850 Loss 2.0919 Accuracy 0.5740\n",
      "Epoch 15 Batch 900 Loss 2.0923 Accuracy 0.5741\n",
      "Epoch 15 Batch 950 Loss 2.0917 Accuracy 0.5743\n",
      "Epoch 15 Batch 1000 Loss 2.0904 Accuracy 0.5745\n",
      "Epoch 15 Batch 1050 Loss 2.0916 Accuracy 0.5743\n",
      "Epoch 15 Batch 1100 Loss 2.0908 Accuracy 0.5745\n",
      "Epoch 15 Batch 1150 Loss 2.0911 Accuracy 0.5744\n",
      "Epoch 15 Batch 1200 Loss 2.0916 Accuracy 0.5743\n",
      "Epoch 15 Batch 1250 Loss 2.0917 Accuracy 0.5744\n",
      "Epoch 15 Batch 1300 Loss 2.0915 Accuracy 0.5745\n",
      "Epoch 15 Batch 1350 Loss 2.0906 Accuracy 0.5747\n",
      "Epoch 15 Batch 1400 Loss 2.0906 Accuracy 0.5746\n",
      "Epoch 15 Batch 1450 Loss 2.0910 Accuracy 0.5747\n",
      "Epoch 15 Batch 1500 Loss 2.0904 Accuracy 0.5748\n",
      "Epoch 15 Batch 1550 Loss 2.0910 Accuracy 0.5747\n",
      "Epoch 15 Batch 1600 Loss 2.0910 Accuracy 0.5747\n",
      "Epoch 15 Batch 1650 Loss 2.0911 Accuracy 0.5747\n",
      "Epoch 15 Batch 1700 Loss 2.0911 Accuracy 0.5748\n",
      "Epoch 15 Batch 1750 Loss 2.0914 Accuracy 0.5747\n",
      "Epoch 15 Batch 1800 Loss 2.0917 Accuracy 0.5746\n",
      "Epoch 15 Batch 1850 Loss 2.0918 Accuracy 0.5746\n",
      "Epoch 15 Batch 1900 Loss 2.0913 Accuracy 0.5748\n",
      "Epoch 15 Batch 1950 Loss 2.0903 Accuracy 0.5749\n",
      "Epoch 15 Batch 2000 Loss 2.0901 Accuracy 0.5750\n",
      "Epoch 15 Batch 2050 Loss 2.0905 Accuracy 0.5749\n",
      "Epoch 15 Batch 2100 Loss 2.0911 Accuracy 0.5748\n",
      "Epoch 15 Batch 2150 Loss 2.0907 Accuracy 0.5749\n",
      "Epoch 15 Batch 2200 Loss 2.0904 Accuracy 0.5750\n",
      "Epoch 15 Batch 2250 Loss 2.0905 Accuracy 0.5749\n",
      "Epoch 15 Batch 2300 Loss 2.0909 Accuracy 0.5749\n",
      "Epoch 15 Batch 2350 Loss 2.0905 Accuracy 0.5750\n",
      "Epoch 15 Batch 2400 Loss 2.0902 Accuracy 0.5750\n",
      "Epoch 15 Batch 2450 Loss 2.0902 Accuracy 0.5750\n",
      "Epoch 15 Batch 2500 Loss 2.0903 Accuracy 0.5750\n",
      "Epoch 15 Batch 2550 Loss 2.0899 Accuracy 0.5750\n",
      "Epoch 15 Batch 2600 Loss 2.0903 Accuracy 0.5750\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-3\n",
      "Epoch 15 Loss 2.0904 Accuracy 0.5750\n",
      "Time taken for 1 epoch: 165.37509489059448 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 1.9667 Accuracy 0.5899\n",
      "Epoch 16 Batch 50 Loss 2.0519 Accuracy 0.5804\n",
      "Epoch 16 Batch 100 Loss 2.0526 Accuracy 0.5800\n",
      "Epoch 16 Batch 150 Loss 2.0556 Accuracy 0.5798\n",
      "Epoch 16 Batch 200 Loss 2.0544 Accuracy 0.5798\n",
      "Epoch 16 Batch 250 Loss 2.0629 Accuracy 0.5787\n",
      "Epoch 16 Batch 300 Loss 2.0599 Accuracy 0.5789\n",
      "Epoch 16 Batch 350 Loss 2.0621 Accuracy 0.5784\n",
      "Epoch 16 Batch 400 Loss 2.0630 Accuracy 0.5784\n",
      "Epoch 16 Batch 450 Loss 2.0625 Accuracy 0.5783\n",
      "Epoch 16 Batch 500 Loss 2.0648 Accuracy 0.5780\n",
      "Epoch 16 Batch 550 Loss 2.0649 Accuracy 0.5781\n",
      "Epoch 16 Batch 600 Loss 2.0663 Accuracy 0.5779\n",
      "Epoch 16 Batch 650 Loss 2.0656 Accuracy 0.5781\n",
      "Epoch 16 Batch 700 Loss 2.0652 Accuracy 0.5782\n",
      "Epoch 16 Batch 750 Loss 2.0668 Accuracy 0.5779\n",
      "Epoch 16 Batch 800 Loss 2.0680 Accuracy 0.5777\n",
      "Epoch 16 Batch 850 Loss 2.0681 Accuracy 0.5777\n",
      "Epoch 16 Batch 900 Loss 2.0675 Accuracy 0.5778\n",
      "Epoch 16 Batch 950 Loss 2.0703 Accuracy 0.5774\n",
      "Epoch 16 Batch 1000 Loss 2.0702 Accuracy 0.5775\n",
      "Epoch 16 Batch 1050 Loss 2.0704 Accuracy 0.5775\n",
      "Epoch 16 Batch 1100 Loss 2.0708 Accuracy 0.5775\n",
      "Epoch 16 Batch 1150 Loss 2.0710 Accuracy 0.5776\n",
      "Epoch 16 Batch 1200 Loss 2.0714 Accuracy 0.5775\n",
      "Epoch 16 Batch 1250 Loss 2.0709 Accuracy 0.5776\n",
      "Epoch 16 Batch 1300 Loss 2.0709 Accuracy 0.5776\n",
      "Epoch 16 Batch 1350 Loss 2.0707 Accuracy 0.5778\n",
      "Epoch 16 Batch 1400 Loss 2.0706 Accuracy 0.5778\n",
      "Epoch 16 Batch 1450 Loss 2.0701 Accuracy 0.5779\n",
      "Epoch 16 Batch 1500 Loss 2.0707 Accuracy 0.5777\n",
      "Epoch 16 Batch 1550 Loss 2.0703 Accuracy 0.5778\n",
      "Epoch 16 Batch 1600 Loss 2.0708 Accuracy 0.5777\n",
      "Epoch 16 Batch 1650 Loss 2.0706 Accuracy 0.5777\n",
      "Epoch 16 Batch 1700 Loss 2.0707 Accuracy 0.5777\n",
      "Epoch 16 Batch 1750 Loss 2.0702 Accuracy 0.5778\n",
      "Epoch 16 Batch 1800 Loss 2.0703 Accuracy 0.5778\n",
      "Epoch 16 Batch 1850 Loss 2.0703 Accuracy 0.5778\n",
      "Epoch 16 Batch 1900 Loss 2.0708 Accuracy 0.5777\n",
      "Epoch 16 Batch 1950 Loss 2.0708 Accuracy 0.5777\n",
      "Epoch 16 Batch 2000 Loss 2.0708 Accuracy 0.5778\n",
      "Epoch 16 Batch 2050 Loss 2.0705 Accuracy 0.5778\n",
      "Epoch 16 Batch 2100 Loss 2.0703 Accuracy 0.5778\n",
      "Epoch 16 Batch 2150 Loss 2.0700 Accuracy 0.5779\n",
      "Epoch 16 Batch 2200 Loss 2.0694 Accuracy 0.5779\n",
      "Epoch 16 Batch 2250 Loss 2.0699 Accuracy 0.5779\n",
      "Epoch 16 Batch 2300 Loss 2.0694 Accuracy 0.5780\n",
      "Epoch 16 Batch 2350 Loss 2.0690 Accuracy 0.5780\n",
      "Epoch 16 Batch 2400 Loss 2.0690 Accuracy 0.5780\n",
      "Epoch 16 Batch 2450 Loss 2.0687 Accuracy 0.5781\n",
      "Epoch 16 Batch 2500 Loss 2.0689 Accuracy 0.5781\n",
      "Epoch 16 Batch 2550 Loss 2.0691 Accuracy 0.5780\n",
      "Epoch 16 Batch 2600 Loss 2.0692 Accuracy 0.5780\n",
      "Epoch 16 Loss 2.0692 Accuracy 0.5780\n",
      "Time taken for 1 epoch: 163.3128788471222 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 1.9938 Accuracy 0.5831\n",
      "Epoch 17 Batch 50 Loss 2.0596 Accuracy 0.5769\n",
      "Epoch 17 Batch 100 Loss 2.0568 Accuracy 0.5783\n",
      "Epoch 17 Batch 150 Loss 2.0546 Accuracy 0.5790\n",
      "Epoch 17 Batch 200 Loss 2.0479 Accuracy 0.5807\n",
      "Epoch 17 Batch 250 Loss 2.0470 Accuracy 0.5810\n",
      "Epoch 17 Batch 300 Loss 2.0456 Accuracy 0.5814\n",
      "Epoch 17 Batch 350 Loss 2.0428 Accuracy 0.5821\n",
      "Epoch 17 Batch 400 Loss 2.0452 Accuracy 0.5816\n",
      "Epoch 17 Batch 450 Loss 2.0446 Accuracy 0.5817\n",
      "Epoch 17 Batch 500 Loss 2.0450 Accuracy 0.5816\n",
      "Epoch 17 Batch 550 Loss 2.0468 Accuracy 0.5815\n",
      "Epoch 17 Batch 600 Loss 2.0481 Accuracy 0.5812\n",
      "Epoch 17 Batch 650 Loss 2.0498 Accuracy 0.5811\n",
      "Epoch 17 Batch 700 Loss 2.0497 Accuracy 0.5808\n",
      "Epoch 17 Batch 750 Loss 2.0503 Accuracy 0.5806\n",
      "Epoch 17 Batch 800 Loss 2.0511 Accuracy 0.5806\n",
      "Epoch 17 Batch 850 Loss 2.0516 Accuracy 0.5806\n",
      "Epoch 17 Batch 900 Loss 2.0516 Accuracy 0.5806\n",
      "Epoch 17 Batch 950 Loss 2.0520 Accuracy 0.5806\n",
      "Epoch 17 Batch 1000 Loss 2.0528 Accuracy 0.5804\n",
      "Epoch 17 Batch 1050 Loss 2.0518 Accuracy 0.5805\n",
      "Epoch 17 Batch 1100 Loss 2.0517 Accuracy 0.5806\n",
      "Epoch 17 Batch 1150 Loss 2.0522 Accuracy 0.5804\n",
      "Epoch 17 Batch 1200 Loss 2.0512 Accuracy 0.5806\n",
      "Epoch 17 Batch 1250 Loss 2.0506 Accuracy 0.5807\n",
      "Epoch 17 Batch 1300 Loss 2.0506 Accuracy 0.5807\n",
      "Epoch 17 Batch 1350 Loss 2.0511 Accuracy 0.5807\n",
      "Epoch 17 Batch 1400 Loss 2.0503 Accuracy 0.5809\n",
      "Epoch 17 Batch 1450 Loss 2.0505 Accuracy 0.5809\n",
      "Epoch 17 Batch 1500 Loss 2.0508 Accuracy 0.5809\n",
      "Epoch 17 Batch 1550 Loss 2.0510 Accuracy 0.5809\n",
      "Epoch 17 Batch 1600 Loss 2.0514 Accuracy 0.5808\n",
      "Epoch 17 Batch 1650 Loss 2.0506 Accuracy 0.5809\n",
      "Epoch 17 Batch 1700 Loss 2.0508 Accuracy 0.5808\n",
      "Epoch 17 Batch 1750 Loss 2.0501 Accuracy 0.5809\n",
      "Epoch 17 Batch 1800 Loss 2.0500 Accuracy 0.5809\n",
      "Epoch 17 Batch 1850 Loss 2.0503 Accuracy 0.5809\n",
      "Epoch 17 Batch 1900 Loss 2.0503 Accuracy 0.5808\n",
      "Epoch 17 Batch 1950 Loss 2.0506 Accuracy 0.5808\n",
      "Epoch 17 Batch 2000 Loss 2.0508 Accuracy 0.5808\n",
      "Epoch 17 Batch 2050 Loss 2.0504 Accuracy 0.5808\n",
      "Epoch 17 Batch 2100 Loss 2.0506 Accuracy 0.5808\n",
      "Epoch 17 Batch 2150 Loss 2.0511 Accuracy 0.5808\n",
      "Epoch 17 Batch 2200 Loss 2.0510 Accuracy 0.5808\n",
      "Epoch 17 Batch 2250 Loss 2.0508 Accuracy 0.5808\n",
      "Epoch 17 Batch 2300 Loss 2.0508 Accuracy 0.5809\n",
      "Epoch 17 Batch 2350 Loss 2.0506 Accuracy 0.5809\n",
      "Epoch 17 Batch 2400 Loss 2.0503 Accuracy 0.5810\n",
      "Epoch 17 Batch 2450 Loss 2.0504 Accuracy 0.5810\n",
      "Epoch 17 Batch 2500 Loss 2.0502 Accuracy 0.5809\n",
      "Epoch 17 Batch 2550 Loss 2.0504 Accuracy 0.5809\n",
      "Epoch 17 Batch 2600 Loss 2.0507 Accuracy 0.5809\n",
      "Epoch 17 Loss 2.0507 Accuracy 0.5808\n",
      "Time taken for 1 epoch: 162.86502647399902 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 2.1115 Accuracy 0.5662\n",
      "Epoch 18 Batch 50 Loss 2.0424 Accuracy 0.5821\n",
      "Epoch 18 Batch 100 Loss 2.0261 Accuracy 0.5850\n",
      "Epoch 18 Batch 150 Loss 2.0312 Accuracy 0.5836\n",
      "Epoch 18 Batch 200 Loss 2.0340 Accuracy 0.5833\n",
      "Epoch 18 Batch 250 Loss 2.0291 Accuracy 0.5841\n",
      "Epoch 18 Batch 300 Loss 2.0290 Accuracy 0.5840\n",
      "Epoch 18 Batch 350 Loss 2.0303 Accuracy 0.5835\n",
      "Epoch 18 Batch 400 Loss 2.0327 Accuracy 0.5829\n",
      "Epoch 18 Batch 450 Loss 2.0345 Accuracy 0.5826\n",
      "Epoch 18 Batch 500 Loss 2.0361 Accuracy 0.5824\n",
      "Epoch 18 Batch 550 Loss 2.0365 Accuracy 0.5825\n",
      "Epoch 18 Batch 600 Loss 2.0366 Accuracy 0.5825\n",
      "Epoch 18 Batch 650 Loss 2.0362 Accuracy 0.5824\n",
      "Epoch 18 Batch 700 Loss 2.0346 Accuracy 0.5829\n",
      "Epoch 18 Batch 750 Loss 2.0349 Accuracy 0.5828\n",
      "Epoch 18 Batch 800 Loss 2.0341 Accuracy 0.5830\n",
      "Epoch 18 Batch 850 Loss 2.0328 Accuracy 0.5832\n",
      "Epoch 18 Batch 900 Loss 2.0337 Accuracy 0.5830\n",
      "Epoch 18 Batch 950 Loss 2.0333 Accuracy 0.5832\n",
      "Epoch 18 Batch 1000 Loss 2.0328 Accuracy 0.5834\n",
      "Epoch 18 Batch 1050 Loss 2.0335 Accuracy 0.5832\n",
      "Epoch 18 Batch 1100 Loss 2.0342 Accuracy 0.5831\n",
      "Epoch 18 Batch 1150 Loss 2.0340 Accuracy 0.5831\n",
      "Epoch 18 Batch 1200 Loss 2.0337 Accuracy 0.5832\n",
      "Epoch 18 Batch 1250 Loss 2.0338 Accuracy 0.5832\n",
      "Epoch 18 Batch 1300 Loss 2.0334 Accuracy 0.5832\n",
      "Epoch 18 Batch 1350 Loss 2.0333 Accuracy 0.5833\n",
      "Epoch 18 Batch 1400 Loss 2.0327 Accuracy 0.5835\n",
      "Epoch 18 Batch 1450 Loss 2.0326 Accuracy 0.5834\n",
      "Epoch 18 Batch 1500 Loss 2.0322 Accuracy 0.5835\n",
      "Epoch 18 Batch 1550 Loss 2.0320 Accuracy 0.5835\n",
      "Epoch 18 Batch 1600 Loss 2.0320 Accuracy 0.5835\n",
      "Epoch 18 Batch 1650 Loss 2.0324 Accuracy 0.5835\n",
      "Epoch 18 Batch 1700 Loss 2.0333 Accuracy 0.5834\n",
      "Epoch 18 Batch 1750 Loss 2.0323 Accuracy 0.5835\n",
      "Epoch 18 Batch 1800 Loss 2.0319 Accuracy 0.5835\n",
      "Epoch 18 Batch 1850 Loss 2.0318 Accuracy 0.5835\n",
      "Epoch 18 Batch 1900 Loss 2.0321 Accuracy 0.5834\n",
      "Epoch 18 Batch 1950 Loss 2.0322 Accuracy 0.5834\n",
      "Epoch 18 Batch 2000 Loss 2.0327 Accuracy 0.5833\n",
      "Epoch 18 Batch 2050 Loss 2.0332 Accuracy 0.5833\n",
      "Epoch 18 Batch 2100 Loss 2.0340 Accuracy 0.5832\n",
      "Epoch 18 Batch 2150 Loss 2.0340 Accuracy 0.5832\n",
      "Epoch 18 Batch 2200 Loss 2.0341 Accuracy 0.5832\n",
      "Epoch 18 Batch 2250 Loss 2.0337 Accuracy 0.5832\n",
      "Epoch 18 Batch 2300 Loss 2.0339 Accuracy 0.5832\n",
      "Epoch 18 Batch 2350 Loss 2.0342 Accuracy 0.5832\n",
      "Epoch 18 Batch 2400 Loss 2.0340 Accuracy 0.5832\n",
      "Epoch 18 Batch 2450 Loss 2.0343 Accuracy 0.5832\n",
      "Epoch 18 Batch 2500 Loss 2.0345 Accuracy 0.5831\n",
      "Epoch 18 Batch 2550 Loss 2.0343 Accuracy 0.5831\n",
      "Epoch 18 Batch 2600 Loss 2.0343 Accuracy 0.5831\n",
      "Epoch 18 Loss 2.0344 Accuracy 0.5831\n",
      "Time taken for 1 epoch: 162.19879007339478 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 1.9584 Accuracy 0.5990\n",
      "Epoch 19 Batch 50 Loss 2.0225 Accuracy 0.5851\n",
      "Epoch 19 Batch 100 Loss 2.0112 Accuracy 0.5862\n",
      "Epoch 19 Batch 150 Loss 2.0192 Accuracy 0.5857\n",
      "Epoch 19 Batch 200 Loss 2.0202 Accuracy 0.5854\n",
      "Epoch 19 Batch 250 Loss 2.0169 Accuracy 0.5860\n",
      "Epoch 19 Batch 300 Loss 2.0165 Accuracy 0.5859\n",
      "Epoch 19 Batch 350 Loss 2.0139 Accuracy 0.5863\n",
      "Epoch 19 Batch 400 Loss 2.0172 Accuracy 0.5856\n",
      "Epoch 19 Batch 450 Loss 2.0151 Accuracy 0.5859\n",
      "Epoch 19 Batch 500 Loss 2.0153 Accuracy 0.5857\n",
      "Epoch 19 Batch 550 Loss 2.0158 Accuracy 0.5856\n",
      "Epoch 19 Batch 600 Loss 2.0164 Accuracy 0.5856\n",
      "Epoch 19 Batch 650 Loss 2.0169 Accuracy 0.5855\n",
      "Epoch 19 Batch 700 Loss 2.0180 Accuracy 0.5852\n",
      "Epoch 19 Batch 750 Loss 2.0165 Accuracy 0.5853\n",
      "Epoch 19 Batch 800 Loss 2.0158 Accuracy 0.5856\n",
      "Epoch 19 Batch 850 Loss 2.0168 Accuracy 0.5855\n",
      "Epoch 19 Batch 900 Loss 2.0159 Accuracy 0.5858\n",
      "Epoch 19 Batch 950 Loss 2.0160 Accuracy 0.5859\n",
      "Epoch 19 Batch 1000 Loss 2.0158 Accuracy 0.5858\n",
      "Epoch 19 Batch 1050 Loss 2.0164 Accuracy 0.5858\n",
      "Epoch 19 Batch 1100 Loss 2.0173 Accuracy 0.5856\n",
      "Epoch 19 Batch 1150 Loss 2.0173 Accuracy 0.5856\n",
      "Epoch 19 Batch 1200 Loss 2.0173 Accuracy 0.5856\n",
      "Epoch 19 Batch 1250 Loss 2.0166 Accuracy 0.5857\n",
      "Epoch 19 Batch 1300 Loss 2.0166 Accuracy 0.5856\n",
      "Epoch 19 Batch 1350 Loss 2.0164 Accuracy 0.5856\n",
      "Epoch 19 Batch 1400 Loss 2.0171 Accuracy 0.5856\n",
      "Epoch 19 Batch 1450 Loss 2.0171 Accuracy 0.5856\n",
      "Epoch 19 Batch 1500 Loss 2.0177 Accuracy 0.5856\n",
      "Epoch 19 Batch 1550 Loss 2.0176 Accuracy 0.5856\n",
      "Epoch 19 Batch 1600 Loss 2.0178 Accuracy 0.5855\n",
      "Epoch 19 Batch 1650 Loss 2.0180 Accuracy 0.5856\n",
      "Epoch 19 Batch 1700 Loss 2.0176 Accuracy 0.5857\n",
      "Epoch 19 Batch 1750 Loss 2.0180 Accuracy 0.5856\n",
      "Epoch 19 Batch 1800 Loss 2.0181 Accuracy 0.5856\n",
      "Epoch 19 Batch 1850 Loss 2.0178 Accuracy 0.5856\n",
      "Epoch 19 Batch 1900 Loss 2.0177 Accuracy 0.5856\n",
      "Epoch 19 Batch 1950 Loss 2.0177 Accuracy 0.5856\n",
      "Epoch 19 Batch 2000 Loss 2.0176 Accuracy 0.5857\n",
      "Epoch 19 Batch 2050 Loss 2.0174 Accuracy 0.5857\n",
      "Epoch 19 Batch 2100 Loss 2.0179 Accuracy 0.5856\n",
      "Epoch 19 Batch 2150 Loss 2.0178 Accuracy 0.5856\n",
      "Epoch 19 Batch 2200 Loss 2.0180 Accuracy 0.5856\n",
      "Epoch 19 Batch 2250 Loss 2.0180 Accuracy 0.5856\n",
      "Epoch 19 Batch 2300 Loss 2.0180 Accuracy 0.5855\n",
      "Epoch 19 Batch 2350 Loss 2.0180 Accuracy 0.5856\n",
      "Epoch 19 Batch 2400 Loss 2.0177 Accuracy 0.5856\n",
      "Epoch 19 Batch 2450 Loss 2.0177 Accuracy 0.5856\n",
      "Epoch 19 Batch 2500 Loss 2.0180 Accuracy 0.5855\n",
      "Epoch 19 Batch 2550 Loss 2.0181 Accuracy 0.5855\n",
      "Epoch 19 Batch 2600 Loss 2.0179 Accuracy 0.5856\n",
      "Epoch 19 Loss 2.0180 Accuracy 0.5855\n",
      "Time taken for 1 epoch: 162.7699112892151 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 1.8930 Accuracy 0.5964\n",
      "Epoch 20 Batch 50 Loss 2.0031 Accuracy 0.5866\n",
      "Epoch 20 Batch 100 Loss 2.0008 Accuracy 0.5876\n",
      "Epoch 20 Batch 150 Loss 1.9913 Accuracy 0.5889\n",
      "Epoch 20 Batch 200 Loss 1.9924 Accuracy 0.5887\n",
      "Epoch 20 Batch 250 Loss 1.9938 Accuracy 0.5886\n",
      "Epoch 20 Batch 300 Loss 1.9964 Accuracy 0.5881\n",
      "Epoch 20 Batch 350 Loss 1.9966 Accuracy 0.5880\n",
      "Epoch 20 Batch 400 Loss 1.9972 Accuracy 0.5880\n",
      "Epoch 20 Batch 450 Loss 1.9966 Accuracy 0.5881\n",
      "Epoch 20 Batch 500 Loss 1.9993 Accuracy 0.5876\n",
      "Epoch 20 Batch 550 Loss 1.9973 Accuracy 0.5880\n",
      "Epoch 20 Batch 600 Loss 1.9980 Accuracy 0.5880\n",
      "Epoch 20 Batch 650 Loss 2.0006 Accuracy 0.5877\n",
      "Epoch 20 Batch 700 Loss 2.0023 Accuracy 0.5876\n",
      "Epoch 20 Batch 750 Loss 2.0024 Accuracy 0.5876\n",
      "Epoch 20 Batch 800 Loss 2.0018 Accuracy 0.5878\n",
      "Epoch 20 Batch 850 Loss 2.0012 Accuracy 0.5878\n",
      "Epoch 20 Batch 900 Loss 2.0006 Accuracy 0.5879\n",
      "Epoch 20 Batch 950 Loss 2.0012 Accuracy 0.5878\n",
      "Epoch 20 Batch 1000 Loss 2.0006 Accuracy 0.5879\n",
      "Epoch 20 Batch 1050 Loss 2.0008 Accuracy 0.5879\n",
      "Epoch 20 Batch 1100 Loss 2.0005 Accuracy 0.5879\n",
      "Epoch 20 Batch 1150 Loss 2.0018 Accuracy 0.5876\n",
      "Epoch 20 Batch 1200 Loss 2.0016 Accuracy 0.5876\n",
      "Epoch 20 Batch 1250 Loss 2.0020 Accuracy 0.5877\n",
      "Epoch 20 Batch 1300 Loss 2.0020 Accuracy 0.5877\n",
      "Epoch 20 Batch 1350 Loss 2.0020 Accuracy 0.5879\n",
      "Epoch 20 Batch 1400 Loss 2.0024 Accuracy 0.5879\n",
      "Epoch 20 Batch 1450 Loss 2.0020 Accuracy 0.5880\n",
      "Epoch 20 Batch 1500 Loss 2.0016 Accuracy 0.5880\n",
      "Epoch 20 Batch 1550 Loss 2.0011 Accuracy 0.5880\n",
      "Epoch 20 Batch 1600 Loss 2.0025 Accuracy 0.5878\n",
      "Epoch 20 Batch 1650 Loss 2.0030 Accuracy 0.5877\n",
      "Epoch 20 Batch 1700 Loss 2.0024 Accuracy 0.5878\n",
      "Epoch 20 Batch 1750 Loss 2.0020 Accuracy 0.5878\n",
      "Epoch 20 Batch 1800 Loss 2.0023 Accuracy 0.5878\n",
      "Epoch 20 Batch 1850 Loss 2.0018 Accuracy 0.5878\n",
      "Epoch 20 Batch 1900 Loss 2.0019 Accuracy 0.5878\n",
      "Epoch 20 Batch 1950 Loss 2.0020 Accuracy 0.5878\n",
      "Epoch 20 Batch 2000 Loss 2.0024 Accuracy 0.5877\n",
      "Epoch 20 Batch 2050 Loss 2.0030 Accuracy 0.5877\n",
      "Epoch 20 Batch 2100 Loss 2.0030 Accuracy 0.5877\n",
      "Epoch 20 Batch 2150 Loss 2.0032 Accuracy 0.5877\n",
      "Epoch 20 Batch 2200 Loss 2.0038 Accuracy 0.5875\n",
      "Epoch 20 Batch 2250 Loss 2.0037 Accuracy 0.5875\n",
      "Epoch 20 Batch 2300 Loss 2.0038 Accuracy 0.5875\n",
      "Epoch 20 Batch 2350 Loss 2.0036 Accuracy 0.5875\n",
      "Epoch 20 Batch 2400 Loss 2.0037 Accuracy 0.5875\n",
      "Epoch 20 Batch 2450 Loss 2.0036 Accuracy 0.5875\n",
      "Epoch 20 Batch 2500 Loss 2.0034 Accuracy 0.5875\n",
      "Epoch 20 Batch 2550 Loss 2.0038 Accuracy 0.5875\n",
      "Epoch 20 Batch 2600 Loss 2.0039 Accuracy 0.5874\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-4\n",
      "Epoch 20 Loss 2.0041 Accuracy 0.5874\n",
      "Time taken for 1 epoch: 163.68037796020508 secs\n",
      "\n",
      "Epoch 21 Batch 0 Loss 2.1957 Accuracy 0.5658\n",
      "Epoch 21 Batch 50 Loss 2.0002 Accuracy 0.5883\n",
      "Epoch 21 Batch 100 Loss 2.0014 Accuracy 0.5883\n",
      "Epoch 21 Batch 150 Loss 1.9899 Accuracy 0.5894\n",
      "Epoch 21 Batch 200 Loss 1.9913 Accuracy 0.5892\n",
      "Epoch 21 Batch 250 Loss 1.9931 Accuracy 0.5890\n",
      "Epoch 21 Batch 300 Loss 1.9922 Accuracy 0.5890\n",
      "Epoch 21 Batch 350 Loss 1.9932 Accuracy 0.5885\n",
      "Epoch 21 Batch 400 Loss 1.9928 Accuracy 0.5888\n",
      "Epoch 21 Batch 450 Loss 1.9879 Accuracy 0.5897\n",
      "Epoch 21 Batch 500 Loss 1.9889 Accuracy 0.5895\n",
      "Epoch 21 Batch 550 Loss 1.9882 Accuracy 0.5898\n",
      "Epoch 21 Batch 600 Loss 1.9882 Accuracy 0.5896\n",
      "Epoch 21 Batch 650 Loss 1.9882 Accuracy 0.5894\n",
      "Epoch 21 Batch 700 Loss 1.9880 Accuracy 0.5895\n",
      "Epoch 21 Batch 750 Loss 1.9882 Accuracy 0.5896\n",
      "Epoch 21 Batch 800 Loss 1.9877 Accuracy 0.5896\n",
      "Epoch 21 Batch 850 Loss 1.9875 Accuracy 0.5896\n",
      "Epoch 21 Batch 900 Loss 1.9885 Accuracy 0.5894\n",
      "Epoch 21 Batch 950 Loss 1.9878 Accuracy 0.5896\n",
      "Epoch 21 Batch 1000 Loss 1.9886 Accuracy 0.5895\n",
      "Epoch 21 Batch 1050 Loss 1.9886 Accuracy 0.5895\n",
      "Epoch 21 Batch 1100 Loss 1.9884 Accuracy 0.5897\n",
      "Epoch 21 Batch 1150 Loss 1.9897 Accuracy 0.5894\n",
      "Epoch 21 Batch 1200 Loss 1.9894 Accuracy 0.5894\n",
      "Epoch 21 Batch 1250 Loss 1.9893 Accuracy 0.5895\n",
      "Epoch 21 Batch 1300 Loss 1.9895 Accuracy 0.5895\n",
      "Epoch 21 Batch 1350 Loss 1.9894 Accuracy 0.5896\n",
      "Epoch 21 Batch 1400 Loss 1.9893 Accuracy 0.5896\n",
      "Epoch 21 Batch 1450 Loss 1.9896 Accuracy 0.5896\n",
      "Epoch 21 Batch 1500 Loss 1.9894 Accuracy 0.5895\n",
      "Epoch 21 Batch 1550 Loss 1.9898 Accuracy 0.5896\n",
      "Epoch 21 Batch 1600 Loss 1.9897 Accuracy 0.5896\n",
      "Epoch 21 Batch 1650 Loss 1.9891 Accuracy 0.5897\n",
      "Epoch 21 Batch 1700 Loss 1.9887 Accuracy 0.5898\n",
      "Epoch 21 Batch 1750 Loss 1.9884 Accuracy 0.5898\n",
      "Epoch 21 Batch 1800 Loss 1.9881 Accuracy 0.5898\n",
      "Epoch 21 Batch 1850 Loss 1.9888 Accuracy 0.5897\n",
      "Epoch 21 Batch 1900 Loss 1.9886 Accuracy 0.5897\n",
      "Epoch 21 Batch 1950 Loss 1.9887 Accuracy 0.5897\n",
      "Epoch 21 Batch 2000 Loss 1.9890 Accuracy 0.5897\n",
      "Epoch 21 Batch 2050 Loss 1.9886 Accuracy 0.5898\n",
      "Epoch 21 Batch 2100 Loss 1.9887 Accuracy 0.5897\n",
      "Epoch 21 Batch 2150 Loss 1.9893 Accuracy 0.5897\n",
      "Epoch 21 Batch 2200 Loss 1.9894 Accuracy 0.5896\n",
      "Epoch 21 Batch 2250 Loss 1.9898 Accuracy 0.5896\n",
      "Epoch 21 Batch 2300 Loss 1.9893 Accuracy 0.5897\n",
      "Epoch 21 Batch 2350 Loss 1.9893 Accuracy 0.5896\n",
      "Epoch 21 Batch 2400 Loss 1.9893 Accuracy 0.5897\n",
      "Epoch 21 Batch 2450 Loss 1.9892 Accuracy 0.5897\n",
      "Epoch 21 Batch 2500 Loss 1.9896 Accuracy 0.5896\n",
      "Epoch 21 Batch 2550 Loss 1.9896 Accuracy 0.5896\n",
      "Epoch 21 Batch 2600 Loss 1.9901 Accuracy 0.5895\n",
      "Epoch 21 Loss 1.9902 Accuracy 0.5895\n",
      "Time taken for 1 epoch: 162.84766578674316 secs\n",
      "\n",
      "Epoch 22 Batch 0 Loss 2.1483 Accuracy 0.5624\n",
      "Epoch 22 Batch 50 Loss 1.9876 Accuracy 0.5895\n",
      "Epoch 22 Batch 100 Loss 1.9823 Accuracy 0.5902\n",
      "Epoch 22 Batch 150 Loss 1.9755 Accuracy 0.5911\n",
      "Epoch 22 Batch 200 Loss 1.9698 Accuracy 0.5920\n",
      "Epoch 22 Batch 250 Loss 1.9708 Accuracy 0.5925\n",
      "Epoch 22 Batch 300 Loss 1.9748 Accuracy 0.5916\n",
      "Epoch 22 Batch 350 Loss 1.9727 Accuracy 0.5919\n",
      "Epoch 22 Batch 400 Loss 1.9738 Accuracy 0.5915\n",
      "Epoch 22 Batch 450 Loss 1.9741 Accuracy 0.5914\n",
      "Epoch 22 Batch 500 Loss 1.9738 Accuracy 0.5916\n",
      "Epoch 22 Batch 550 Loss 1.9740 Accuracy 0.5917\n",
      "Epoch 22 Batch 600 Loss 1.9733 Accuracy 0.5918\n",
      "Epoch 22 Batch 650 Loss 1.9754 Accuracy 0.5914\n",
      "Epoch 22 Batch 700 Loss 1.9757 Accuracy 0.5914\n",
      "Epoch 22 Batch 750 Loss 1.9761 Accuracy 0.5913\n",
      "Epoch 22 Batch 800 Loss 1.9776 Accuracy 0.5909\n",
      "Epoch 22 Batch 850 Loss 1.9764 Accuracy 0.5912\n",
      "Epoch 22 Batch 900 Loss 1.9782 Accuracy 0.5909\n",
      "Epoch 22 Batch 950 Loss 1.9782 Accuracy 0.5909\n",
      "Epoch 22 Batch 1000 Loss 1.9786 Accuracy 0.5909\n",
      "Epoch 22 Batch 1050 Loss 1.9788 Accuracy 0.5909\n",
      "Epoch 22 Batch 1100 Loss 1.9781 Accuracy 0.5910\n",
      "Epoch 22 Batch 1150 Loss 1.9778 Accuracy 0.5910\n",
      "Epoch 22 Batch 1200 Loss 1.9775 Accuracy 0.5912\n",
      "Epoch 22 Batch 1250 Loss 1.9772 Accuracy 0.5913\n",
      "Epoch 22 Batch 1300 Loss 1.9767 Accuracy 0.5914\n",
      "Epoch 22 Batch 1350 Loss 1.9759 Accuracy 0.5915\n",
      "Epoch 22 Batch 1400 Loss 1.9755 Accuracy 0.5916\n",
      "Epoch 22 Batch 1450 Loss 1.9751 Accuracy 0.5916\n",
      "Epoch 22 Batch 1500 Loss 1.9751 Accuracy 0.5917\n",
      "Epoch 22 Batch 1550 Loss 1.9757 Accuracy 0.5916\n",
      "Epoch 22 Batch 1600 Loss 1.9761 Accuracy 0.5916\n",
      "Epoch 22 Batch 1650 Loss 1.9761 Accuracy 0.5915\n",
      "Epoch 22 Batch 1700 Loss 1.9764 Accuracy 0.5915\n",
      "Epoch 22 Batch 1750 Loss 1.9761 Accuracy 0.5916\n",
      "Epoch 22 Batch 1800 Loss 1.9755 Accuracy 0.5917\n",
      "Epoch 22 Batch 1850 Loss 1.9759 Accuracy 0.5917\n",
      "Epoch 22 Batch 1900 Loss 1.9761 Accuracy 0.5916\n",
      "Epoch 22 Batch 1950 Loss 1.9760 Accuracy 0.5917\n",
      "Epoch 22 Batch 2000 Loss 1.9761 Accuracy 0.5917\n",
      "Epoch 22 Batch 2050 Loss 1.9766 Accuracy 0.5916\n",
      "Epoch 22 Batch 2100 Loss 1.9766 Accuracy 0.5916\n",
      "Epoch 22 Batch 2150 Loss 1.9766 Accuracy 0.5916\n",
      "Epoch 22 Batch 2200 Loss 1.9773 Accuracy 0.5915\n",
      "Epoch 22 Batch 2250 Loss 1.9777 Accuracy 0.5914\n",
      "Epoch 22 Batch 2300 Loss 1.9775 Accuracy 0.5914\n",
      "Epoch 22 Batch 2350 Loss 1.9772 Accuracy 0.5914\n",
      "Epoch 22 Batch 2400 Loss 1.9769 Accuracy 0.5914\n",
      "Epoch 22 Batch 2450 Loss 1.9773 Accuracy 0.5914\n",
      "Epoch 22 Batch 2500 Loss 1.9776 Accuracy 0.5913\n",
      "Epoch 22 Batch 2550 Loss 1.9781 Accuracy 0.5913\n",
      "Epoch 22 Batch 2600 Loss 1.9781 Accuracy 0.5913\n",
      "Epoch 22 Loss 1.9781 Accuracy 0.5914\n",
      "Time taken for 1 epoch: 163.8929934501648 secs\n",
      "\n",
      "Epoch 23 Batch 0 Loss 1.8451 Accuracy 0.6172\n",
      "Epoch 23 Batch 50 Loss 1.9585 Accuracy 0.5927\n",
      "Epoch 23 Batch 100 Loss 1.9405 Accuracy 0.5961\n",
      "Epoch 23 Batch 150 Loss 1.9547 Accuracy 0.5940\n",
      "Epoch 23 Batch 200 Loss 1.9537 Accuracy 0.5942\n",
      "Epoch 23 Batch 250 Loss 1.9580 Accuracy 0.5936\n",
      "Epoch 23 Batch 300 Loss 1.9634 Accuracy 0.5929\n",
      "Epoch 23 Batch 350 Loss 1.9649 Accuracy 0.5926\n",
      "Epoch 23 Batch 400 Loss 1.9646 Accuracy 0.5928\n",
      "Epoch 23 Batch 450 Loss 1.9651 Accuracy 0.5926\n",
      "Epoch 23 Batch 500 Loss 1.9640 Accuracy 0.5926\n",
      "Epoch 23 Batch 550 Loss 1.9638 Accuracy 0.5927\n",
      "Epoch 23 Batch 600 Loss 1.9656 Accuracy 0.5925\n",
      "Epoch 23 Batch 650 Loss 1.9666 Accuracy 0.5924\n",
      "Epoch 23 Batch 700 Loss 1.9664 Accuracy 0.5925\n",
      "Epoch 23 Batch 750 Loss 1.9665 Accuracy 0.5925\n",
      "Epoch 23 Batch 800 Loss 1.9655 Accuracy 0.5927\n",
      "Epoch 23 Batch 850 Loss 1.9643 Accuracy 0.5928\n",
      "Epoch 23 Batch 900 Loss 1.9648 Accuracy 0.5926\n",
      "Epoch 23 Batch 950 Loss 1.9652 Accuracy 0.5926\n",
      "Epoch 23 Batch 1000 Loss 1.9642 Accuracy 0.5927\n",
      "Epoch 23 Batch 1050 Loss 1.9645 Accuracy 0.5928\n",
      "Epoch 23 Batch 1100 Loss 1.9635 Accuracy 0.5929\n",
      "Epoch 23 Batch 1150 Loss 1.9653 Accuracy 0.5927\n",
      "Epoch 23 Batch 1200 Loss 1.9657 Accuracy 0.5927\n",
      "Epoch 23 Batch 1250 Loss 1.9653 Accuracy 0.5926\n",
      "Epoch 23 Batch 1300 Loss 1.9645 Accuracy 0.5928\n",
      "Epoch 23 Batch 1350 Loss 1.9660 Accuracy 0.5926\n",
      "Epoch 23 Batch 1400 Loss 1.9659 Accuracy 0.5925\n",
      "Epoch 23 Batch 1450 Loss 1.9657 Accuracy 0.5926\n",
      "Epoch 23 Batch 1500 Loss 1.9650 Accuracy 0.5927\n",
      "Epoch 23 Batch 1550 Loss 1.9654 Accuracy 0.5927\n",
      "Epoch 23 Batch 1600 Loss 1.9647 Accuracy 0.5928\n",
      "Epoch 23 Batch 1650 Loss 1.9641 Accuracy 0.5929\n",
      "Epoch 23 Batch 1700 Loss 1.9648 Accuracy 0.5928\n",
      "Epoch 23 Batch 1750 Loss 1.9646 Accuracy 0.5929\n",
      "Epoch 23 Batch 1800 Loss 1.9646 Accuracy 0.5929\n",
      "Epoch 23 Batch 1850 Loss 1.9649 Accuracy 0.5928\n",
      "Epoch 23 Batch 1900 Loss 1.9649 Accuracy 0.5928\n",
      "Epoch 23 Batch 1950 Loss 1.9651 Accuracy 0.5928\n",
      "Epoch 23 Batch 2000 Loss 1.9655 Accuracy 0.5928\n",
      "Epoch 23 Batch 2050 Loss 1.9654 Accuracy 0.5928\n",
      "Epoch 23 Batch 2100 Loss 1.9652 Accuracy 0.5929\n",
      "Epoch 23 Batch 2150 Loss 1.9654 Accuracy 0.5928\n",
      "Epoch 23 Batch 2200 Loss 1.9652 Accuracy 0.5928\n",
      "Epoch 23 Batch 2250 Loss 1.9656 Accuracy 0.5928\n",
      "Epoch 23 Batch 2300 Loss 1.9651 Accuracy 0.5929\n",
      "Epoch 23 Batch 2350 Loss 1.9656 Accuracy 0.5929\n",
      "Epoch 23 Batch 2400 Loss 1.9654 Accuracy 0.5930\n",
      "Epoch 23 Batch 2450 Loss 1.9652 Accuracy 0.5930\n",
      "Epoch 23 Batch 2500 Loss 1.9657 Accuracy 0.5929\n",
      "Epoch 23 Batch 2550 Loss 1.9652 Accuracy 0.5930\n",
      "Epoch 23 Batch 2600 Loss 1.9661 Accuracy 0.5928\n",
      "Epoch 23 Loss 1.9664 Accuracy 0.5928\n",
      "Time taken for 1 epoch: 164.8483021259308 secs\n",
      "\n",
      "Epoch 24 Batch 0 Loss 1.9421 Accuracy 0.6007\n",
      "Epoch 24 Batch 50 Loss 1.9324 Accuracy 0.5958\n",
      "Epoch 24 Batch 100 Loss 1.9411 Accuracy 0.5958\n",
      "Epoch 24 Batch 150 Loss 1.9419 Accuracy 0.5961\n",
      "Epoch 24 Batch 200 Loss 1.9467 Accuracy 0.5950\n",
      "Epoch 24 Batch 250 Loss 1.9522 Accuracy 0.5941\n",
      "Epoch 24 Batch 300 Loss 1.9505 Accuracy 0.5946\n",
      "Epoch 24 Batch 350 Loss 1.9494 Accuracy 0.5947\n",
      "Epoch 24 Batch 400 Loss 1.9498 Accuracy 0.5948\n",
      "Epoch 24 Batch 450 Loss 1.9501 Accuracy 0.5947\n",
      "Epoch 24 Batch 500 Loss 1.9493 Accuracy 0.5946\n",
      "Epoch 24 Batch 550 Loss 1.9501 Accuracy 0.5947\n",
      "Epoch 24 Batch 600 Loss 1.9503 Accuracy 0.5947\n",
      "Epoch 24 Batch 650 Loss 1.9519 Accuracy 0.5945\n",
      "Epoch 24 Batch 700 Loss 1.9522 Accuracy 0.5944\n",
      "Epoch 24 Batch 750 Loss 1.9520 Accuracy 0.5944\n",
      "Epoch 24 Batch 800 Loss 1.9521 Accuracy 0.5943\n",
      "Epoch 24 Batch 850 Loss 1.9526 Accuracy 0.5942\n",
      "Epoch 24 Batch 900 Loss 1.9528 Accuracy 0.5944\n",
      "Epoch 24 Batch 950 Loss 1.9530 Accuracy 0.5943\n",
      "Epoch 24 Batch 1000 Loss 1.9539 Accuracy 0.5942\n",
      "Epoch 24 Batch 1050 Loss 1.9535 Accuracy 0.5944\n",
      "Epoch 24 Batch 1100 Loss 1.9540 Accuracy 0.5943\n",
      "Epoch 24 Batch 1150 Loss 1.9541 Accuracy 0.5943\n",
      "Epoch 24 Batch 1200 Loss 1.9542 Accuracy 0.5943\n",
      "Epoch 24 Batch 1250 Loss 1.9534 Accuracy 0.5943\n",
      "Epoch 24 Batch 1300 Loss 1.9527 Accuracy 0.5945\n",
      "Epoch 24 Batch 1350 Loss 1.9539 Accuracy 0.5943\n",
      "Epoch 24 Batch 1400 Loss 1.9537 Accuracy 0.5944\n",
      "Epoch 24 Batch 1450 Loss 1.9537 Accuracy 0.5944\n",
      "Epoch 24 Batch 1500 Loss 1.9543 Accuracy 0.5943\n",
      "Epoch 24 Batch 1550 Loss 1.9541 Accuracy 0.5944\n",
      "Epoch 24 Batch 1600 Loss 1.9543 Accuracy 0.5944\n",
      "Epoch 24 Batch 1650 Loss 1.9539 Accuracy 0.5945\n",
      "Epoch 24 Batch 1700 Loss 1.9538 Accuracy 0.5945\n",
      "Epoch 24 Batch 1750 Loss 1.9545 Accuracy 0.5944\n",
      "Epoch 24 Batch 1800 Loss 1.9541 Accuracy 0.5945\n",
      "Epoch 24 Batch 1850 Loss 1.9538 Accuracy 0.5946\n",
      "Epoch 24 Batch 1900 Loss 1.9539 Accuracy 0.5945\n",
      "Epoch 24 Batch 1950 Loss 1.9539 Accuracy 0.5945\n",
      "Epoch 24 Batch 2000 Loss 1.9541 Accuracy 0.5945\n",
      "Epoch 24 Batch 2050 Loss 1.9544 Accuracy 0.5944\n",
      "Epoch 24 Batch 2100 Loss 1.9546 Accuracy 0.5944\n",
      "Epoch 24 Batch 2150 Loss 1.9545 Accuracy 0.5944\n",
      "Epoch 24 Batch 2200 Loss 1.9548 Accuracy 0.5944\n",
      "Epoch 24 Batch 2250 Loss 1.9548 Accuracy 0.5944\n",
      "Epoch 24 Batch 2300 Loss 1.9550 Accuracy 0.5944\n",
      "Epoch 24 Batch 2350 Loss 1.9552 Accuracy 0.5943\n",
      "Epoch 24 Batch 2400 Loss 1.9556 Accuracy 0.5943\n",
      "Epoch 24 Batch 2450 Loss 1.9558 Accuracy 0.5942\n",
      "Epoch 24 Batch 2500 Loss 1.9556 Accuracy 0.5943\n",
      "Epoch 24 Batch 2550 Loss 1.9552 Accuracy 0.5944\n",
      "Epoch 24 Batch 2600 Loss 1.9557 Accuracy 0.5943\n",
      "Epoch 24 Loss 1.9555 Accuracy 0.5944\n",
      "Time taken for 1 epoch: 165.33475613594055 secs\n",
      "\n",
      "Epoch 25 Batch 0 Loss 1.9340 Accuracy 0.5810\n",
      "Epoch 25 Batch 50 Loss 1.9144 Accuracy 0.6015\n",
      "Epoch 25 Batch 100 Loss 1.9199 Accuracy 0.5998\n",
      "Epoch 25 Batch 150 Loss 1.9321 Accuracy 0.5976\n",
      "Epoch 25 Batch 200 Loss 1.9389 Accuracy 0.5969\n",
      "Epoch 25 Batch 250 Loss 1.9414 Accuracy 0.5973\n",
      "Epoch 25 Batch 300 Loss 1.9424 Accuracy 0.5973\n",
      "Epoch 25 Batch 350 Loss 1.9407 Accuracy 0.5977\n",
      "Epoch 25 Batch 400 Loss 1.9407 Accuracy 0.5972\n",
      "Epoch 25 Batch 450 Loss 1.9385 Accuracy 0.5974\n",
      "Epoch 25 Batch 500 Loss 1.9419 Accuracy 0.5967\n",
      "Epoch 25 Batch 550 Loss 1.9425 Accuracy 0.5964\n",
      "Epoch 25 Batch 600 Loss 1.9437 Accuracy 0.5963\n",
      "Epoch 25 Batch 650 Loss 1.9432 Accuracy 0.5964\n",
      "Epoch 25 Batch 700 Loss 1.9413 Accuracy 0.5966\n",
      "Epoch 25 Batch 750 Loss 1.9415 Accuracy 0.5965\n",
      "Epoch 25 Batch 800 Loss 1.9426 Accuracy 0.5963\n",
      "Epoch 25 Batch 850 Loss 1.9423 Accuracy 0.5963\n",
      "Epoch 25 Batch 900 Loss 1.9427 Accuracy 0.5962\n",
      "Epoch 25 Batch 950 Loss 1.9432 Accuracy 0.5962\n",
      "Epoch 25 Batch 1000 Loss 1.9431 Accuracy 0.5962\n",
      "Epoch 25 Batch 1050 Loss 1.9424 Accuracy 0.5962\n",
      "Epoch 25 Batch 1100 Loss 1.9431 Accuracy 0.5962\n",
      "Epoch 25 Batch 1150 Loss 1.9431 Accuracy 0.5962\n",
      "Epoch 25 Batch 1200 Loss 1.9433 Accuracy 0.5962\n",
      "Epoch 25 Batch 1250 Loss 1.9444 Accuracy 0.5960\n",
      "Epoch 25 Batch 1300 Loss 1.9443 Accuracy 0.5960\n",
      "Epoch 25 Batch 1350 Loss 1.9441 Accuracy 0.5961\n",
      "Epoch 25 Batch 1400 Loss 1.9443 Accuracy 0.5961\n",
      "Epoch 25 Batch 1450 Loss 1.9440 Accuracy 0.5961\n",
      "Epoch 25 Batch 1500 Loss 1.9444 Accuracy 0.5960\n",
      "Epoch 25 Batch 1550 Loss 1.9438 Accuracy 0.5961\n",
      "Epoch 25 Batch 1600 Loss 1.9436 Accuracy 0.5962\n",
      "Epoch 25 Batch 1650 Loss 1.9439 Accuracy 0.5962\n",
      "Epoch 25 Batch 1700 Loss 1.9439 Accuracy 0.5962\n",
      "Epoch 25 Batch 1750 Loss 1.9448 Accuracy 0.5960\n",
      "Epoch 25 Batch 1800 Loss 1.9442 Accuracy 0.5960\n",
      "Epoch 25 Batch 1850 Loss 1.9437 Accuracy 0.5961\n",
      "Epoch 25 Batch 1900 Loss 1.9430 Accuracy 0.5962\n",
      "Epoch 25 Batch 1950 Loss 1.9431 Accuracy 0.5962\n",
      "Epoch 25 Batch 2000 Loss 1.9433 Accuracy 0.5962\n",
      "Epoch 25 Batch 2050 Loss 1.9437 Accuracy 0.5961\n",
      "Epoch 25 Batch 2100 Loss 1.9441 Accuracy 0.5960\n",
      "Epoch 25 Batch 2150 Loss 1.9449 Accuracy 0.5959\n",
      "Epoch 25 Batch 2200 Loss 1.9448 Accuracy 0.5960\n",
      "Epoch 25 Batch 2250 Loss 1.9446 Accuracy 0.5960\n",
      "Epoch 25 Batch 2300 Loss 1.9447 Accuracy 0.5961\n",
      "Epoch 25 Batch 2350 Loss 1.9447 Accuracy 0.5961\n",
      "Epoch 25 Batch 2400 Loss 1.9449 Accuracy 0.5960\n",
      "Epoch 25 Batch 2450 Loss 1.9451 Accuracy 0.5960\n",
      "Epoch 25 Batch 2500 Loss 1.9450 Accuracy 0.5960\n",
      "Epoch 25 Batch 2550 Loss 1.9453 Accuracy 0.5959\n",
      "Epoch 25 Batch 2600 Loss 1.9448 Accuracy 0.5959\n",
      "Saving checkpoint for epoch 25 at ./checkpoints/train/ckpt-5\n",
      "Epoch 25 Loss 1.9448 Accuracy 0.5960\n",
      "Time taken for 1 epoch: 164.2519886493683 secs\n",
      "\n",
      "Epoch 26 Batch 0 Loss 1.9633 Accuracy 0.5890\n",
      "Epoch 26 Batch 50 Loss 1.9205 Accuracy 0.5987\n",
      "Epoch 26 Batch 100 Loss 1.9262 Accuracy 0.5990\n",
      "Epoch 26 Batch 150 Loss 1.9316 Accuracy 0.5982\n",
      "Epoch 26 Batch 200 Loss 1.9251 Accuracy 0.5989\n",
      "Epoch 26 Batch 250 Loss 1.9265 Accuracy 0.5991\n",
      "Epoch 26 Batch 300 Loss 1.9295 Accuracy 0.5986\n",
      "Epoch 26 Batch 350 Loss 1.9303 Accuracy 0.5986\n",
      "Epoch 26 Batch 400 Loss 1.9327 Accuracy 0.5979\n",
      "Epoch 26 Batch 450 Loss 1.9329 Accuracy 0.5980\n",
      "Epoch 26 Batch 500 Loss 1.9350 Accuracy 0.5975\n",
      "Epoch 26 Batch 550 Loss 1.9353 Accuracy 0.5975\n",
      "Epoch 26 Batch 600 Loss 1.9337 Accuracy 0.5979\n",
      "Epoch 26 Batch 650 Loss 1.9345 Accuracy 0.5978\n",
      "Epoch 26 Batch 700 Loss 1.9350 Accuracy 0.5976\n",
      "Epoch 26 Batch 750 Loss 1.9356 Accuracy 0.5975\n",
      "Epoch 26 Batch 800 Loss 1.9351 Accuracy 0.5975\n",
      "Epoch 26 Batch 850 Loss 1.9336 Accuracy 0.5977\n",
      "Epoch 26 Batch 900 Loss 1.9343 Accuracy 0.5976\n",
      "Epoch 26 Batch 950 Loss 1.9344 Accuracy 0.5974\n",
      "Epoch 26 Batch 1000 Loss 1.9346 Accuracy 0.5975\n",
      "Epoch 26 Batch 1050 Loss 1.9348 Accuracy 0.5975\n",
      "Epoch 26 Batch 1100 Loss 1.9341 Accuracy 0.5977\n",
      "Epoch 26 Batch 1150 Loss 1.9334 Accuracy 0.5979\n",
      "Epoch 26 Batch 1200 Loss 1.9327 Accuracy 0.5981\n",
      "Epoch 26 Batch 1250 Loss 1.9325 Accuracy 0.5980\n",
      "Epoch 26 Batch 1300 Loss 1.9324 Accuracy 0.5981\n",
      "Epoch 26 Batch 1350 Loss 1.9327 Accuracy 0.5980\n",
      "Epoch 26 Batch 1400 Loss 1.9328 Accuracy 0.5980\n",
      "Epoch 26 Batch 1450 Loss 1.9330 Accuracy 0.5980\n",
      "Epoch 26 Batch 1500 Loss 1.9342 Accuracy 0.5978\n",
      "Epoch 26 Batch 1550 Loss 1.9349 Accuracy 0.5977\n",
      "Epoch 26 Batch 1600 Loss 1.9351 Accuracy 0.5977\n",
      "Epoch 26 Batch 1650 Loss 1.9355 Accuracy 0.5976\n",
      "Epoch 26 Batch 1700 Loss 1.9355 Accuracy 0.5976\n",
      "Epoch 26 Batch 1750 Loss 1.9352 Accuracy 0.5976\n",
      "Epoch 26 Batch 1800 Loss 1.9357 Accuracy 0.5976\n",
      "Epoch 26 Batch 1850 Loss 1.9354 Accuracy 0.5976\n",
      "Epoch 26 Batch 1900 Loss 1.9351 Accuracy 0.5977\n",
      "Epoch 26 Batch 1950 Loss 1.9351 Accuracy 0.5977\n",
      "Epoch 26 Batch 2000 Loss 1.9348 Accuracy 0.5977\n",
      "Epoch 26 Batch 2050 Loss 1.9344 Accuracy 0.5978\n",
      "Epoch 26 Batch 2100 Loss 1.9346 Accuracy 0.5978\n",
      "Epoch 26 Batch 2150 Loss 1.9351 Accuracy 0.5977\n",
      "Epoch 26 Batch 2200 Loss 1.9356 Accuracy 0.5976\n",
      "Epoch 26 Batch 2250 Loss 1.9356 Accuracy 0.5976\n",
      "Epoch 26 Batch 2300 Loss 1.9354 Accuracy 0.5977\n",
      "Epoch 26 Batch 2350 Loss 1.9356 Accuracy 0.5977\n",
      "Epoch 26 Batch 2400 Loss 1.9354 Accuracy 0.5977\n",
      "Epoch 26 Batch 2450 Loss 1.9353 Accuracy 0.5977\n",
      "Epoch 26 Batch 2500 Loss 1.9355 Accuracy 0.5977\n",
      "Epoch 26 Batch 2550 Loss 1.9358 Accuracy 0.5976\n",
      "Epoch 26 Batch 2600 Loss 1.9361 Accuracy 0.5976\n",
      "Epoch 26 Loss 1.9360 Accuracy 0.5976\n",
      "Time taken for 1 epoch: 163.45603275299072 secs\n",
      "\n",
      "Epoch 27 Batch 0 Loss 1.7228 Accuracy 0.6317\n",
      "Epoch 27 Batch 50 Loss 1.9147 Accuracy 0.6010\n",
      "Epoch 27 Batch 100 Loss 1.9190 Accuracy 0.6009\n",
      "Epoch 27 Batch 150 Loss 1.9177 Accuracy 0.6007\n",
      "Epoch 27 Batch 200 Loss 1.9177 Accuracy 0.6003\n",
      "Epoch 27 Batch 250 Loss 1.9154 Accuracy 0.6007\n",
      "Epoch 27 Batch 300 Loss 1.9167 Accuracy 0.6005\n",
      "Epoch 27 Batch 350 Loss 1.9154 Accuracy 0.6004\n",
      "Epoch 27 Batch 400 Loss 1.9177 Accuracy 0.5998\n",
      "Epoch 27 Batch 450 Loss 1.9181 Accuracy 0.5999\n",
      "Epoch 27 Batch 500 Loss 1.9210 Accuracy 0.5996\n",
      "Epoch 27 Batch 550 Loss 1.9231 Accuracy 0.5992\n",
      "Epoch 27 Batch 600 Loss 1.9227 Accuracy 0.5991\n",
      "Epoch 27 Batch 650 Loss 1.9226 Accuracy 0.5993\n",
      "Epoch 27 Batch 700 Loss 1.9234 Accuracy 0.5990\n",
      "Epoch 27 Batch 750 Loss 1.9243 Accuracy 0.5989\n",
      "Epoch 27 Batch 800 Loss 1.9244 Accuracy 0.5989\n",
      "Epoch 27 Batch 850 Loss 1.9232 Accuracy 0.5991\n",
      "Epoch 27 Batch 900 Loss 1.9241 Accuracy 0.5990\n",
      "Epoch 27 Batch 950 Loss 1.9240 Accuracy 0.5991\n",
      "Epoch 27 Batch 1000 Loss 1.9250 Accuracy 0.5990\n",
      "Epoch 27 Batch 1050 Loss 1.9258 Accuracy 0.5989\n",
      "Epoch 27 Batch 1100 Loss 1.9258 Accuracy 0.5989\n",
      "Epoch 27 Batch 1150 Loss 1.9256 Accuracy 0.5990\n",
      "Epoch 27 Batch 1200 Loss 1.9256 Accuracy 0.5991\n",
      "Epoch 27 Batch 1250 Loss 1.9255 Accuracy 0.5991\n",
      "Epoch 27 Batch 1300 Loss 1.9258 Accuracy 0.5991\n",
      "Epoch 27 Batch 1350 Loss 1.9256 Accuracy 0.5991\n",
      "Epoch 27 Batch 1400 Loss 1.9256 Accuracy 0.5991\n",
      "Epoch 27 Batch 1450 Loss 1.9256 Accuracy 0.5990\n",
      "Epoch 27 Batch 1500 Loss 1.9249 Accuracy 0.5991\n",
      "Epoch 27 Batch 1550 Loss 1.9249 Accuracy 0.5991\n",
      "Epoch 27 Batch 1600 Loss 1.9244 Accuracy 0.5993\n",
      "Epoch 27 Batch 1650 Loss 1.9242 Accuracy 0.5994\n",
      "Epoch 27 Batch 1700 Loss 1.9245 Accuracy 0.5994\n",
      "Epoch 27 Batch 1750 Loss 1.9248 Accuracy 0.5993\n",
      "Epoch 27 Batch 1800 Loss 1.9250 Accuracy 0.5992\n",
      "Epoch 27 Batch 1850 Loss 1.9250 Accuracy 0.5992\n",
      "Epoch 27 Batch 1900 Loss 1.9252 Accuracy 0.5991\n",
      "Epoch 27 Batch 1950 Loss 1.9254 Accuracy 0.5991\n",
      "Epoch 27 Batch 2000 Loss 1.9249 Accuracy 0.5991\n",
      "Epoch 27 Batch 2050 Loss 1.9251 Accuracy 0.5991\n",
      "Epoch 27 Batch 2100 Loss 1.9254 Accuracy 0.5991\n",
      "Epoch 27 Batch 2150 Loss 1.9257 Accuracy 0.5990\n",
      "Epoch 27 Batch 2200 Loss 1.9261 Accuracy 0.5989\n",
      "Epoch 27 Batch 2250 Loss 1.9259 Accuracy 0.5989\n",
      "Epoch 27 Batch 2300 Loss 1.9257 Accuracy 0.5989\n",
      "Epoch 27 Batch 2350 Loss 1.9258 Accuracy 0.5989\n",
      "Epoch 27 Batch 2400 Loss 1.9259 Accuracy 0.5989\n",
      "Epoch 27 Batch 2450 Loss 1.9263 Accuracy 0.5989\n",
      "Epoch 27 Batch 2500 Loss 1.9263 Accuracy 0.5989\n",
      "Epoch 27 Batch 2550 Loss 1.9263 Accuracy 0.5989\n",
      "Epoch 27 Batch 2600 Loss 1.9262 Accuracy 0.5989\n",
      "Epoch 27 Loss 1.9263 Accuracy 0.5989\n",
      "Time taken for 1 epoch: 162.85518288612366 secs\n",
      "\n",
      "Epoch 28 Batch 0 Loss 2.0371 Accuracy 0.5785\n",
      "Epoch 28 Batch 50 Loss 1.8986 Accuracy 0.6011\n",
      "Epoch 28 Batch 100 Loss 1.9100 Accuracy 0.6005\n",
      "Epoch 28 Batch 150 Loss 1.9097 Accuracy 0.6008\n",
      "Epoch 28 Batch 200 Loss 1.9103 Accuracy 0.6008\n",
      "Epoch 28 Batch 250 Loss 1.9074 Accuracy 0.6011\n",
      "Epoch 28 Batch 300 Loss 1.9070 Accuracy 0.6013\n",
      "Epoch 28 Batch 350 Loss 1.9071 Accuracy 0.6014\n",
      "Epoch 28 Batch 400 Loss 1.9100 Accuracy 0.6012\n",
      "Epoch 28 Batch 450 Loss 1.9086 Accuracy 0.6012\n",
      "Epoch 28 Batch 500 Loss 1.9095 Accuracy 0.6011\n",
      "Epoch 28 Batch 550 Loss 1.9104 Accuracy 0.6007\n",
      "Epoch 28 Batch 600 Loss 1.9103 Accuracy 0.6009\n",
      "Epoch 28 Batch 650 Loss 1.9120 Accuracy 0.6008\n",
      "Epoch 28 Batch 700 Loss 1.9124 Accuracy 0.6006\n",
      "Epoch 28 Batch 750 Loss 1.9130 Accuracy 0.6006\n",
      "Epoch 28 Batch 800 Loss 1.9138 Accuracy 0.6006\n",
      "Epoch 28 Batch 850 Loss 1.9134 Accuracy 0.6008\n",
      "Epoch 28 Batch 900 Loss 1.9134 Accuracy 0.6008\n",
      "Epoch 28 Batch 950 Loss 1.9137 Accuracy 0.6006\n",
      "Epoch 28 Batch 1000 Loss 1.9138 Accuracy 0.6006\n",
      "Epoch 28 Batch 1050 Loss 1.9135 Accuracy 0.6007\n",
      "Epoch 28 Batch 1100 Loss 1.9138 Accuracy 0.6006\n",
      "Epoch 28 Batch 1150 Loss 1.9140 Accuracy 0.6006\n",
      "Epoch 28 Batch 1200 Loss 1.9132 Accuracy 0.6007\n",
      "Epoch 28 Batch 1250 Loss 1.9129 Accuracy 0.6008\n",
      "Epoch 28 Batch 1300 Loss 1.9138 Accuracy 0.6006\n",
      "Epoch 28 Batch 1350 Loss 1.9132 Accuracy 0.6007\n",
      "Epoch 28 Batch 1400 Loss 1.9136 Accuracy 0.6007\n",
      "Epoch 28 Batch 1450 Loss 1.9137 Accuracy 0.6008\n",
      "Epoch 28 Batch 1500 Loss 1.9136 Accuracy 0.6008\n",
      "Epoch 28 Batch 1550 Loss 1.9140 Accuracy 0.6008\n",
      "Epoch 28 Batch 1600 Loss 1.9140 Accuracy 0.6008\n",
      "Epoch 28 Batch 1650 Loss 1.9140 Accuracy 0.6008\n",
      "Epoch 28 Batch 1700 Loss 1.9144 Accuracy 0.6007\n",
      "Epoch 28 Batch 1750 Loss 1.9150 Accuracy 0.6006\n",
      "Epoch 28 Batch 1800 Loss 1.9151 Accuracy 0.6005\n",
      "Epoch 28 Batch 1850 Loss 1.9155 Accuracy 0.6005\n",
      "Epoch 28 Batch 1900 Loss 1.9157 Accuracy 0.6004\n",
      "Epoch 28 Batch 1950 Loss 1.9159 Accuracy 0.6003\n",
      "Epoch 28 Batch 2000 Loss 1.9167 Accuracy 0.6002\n",
      "Epoch 28 Batch 2050 Loss 1.9166 Accuracy 0.6002\n",
      "Epoch 28 Batch 2100 Loss 1.9162 Accuracy 0.6003\n",
      "Epoch 28 Batch 2150 Loss 1.9170 Accuracy 0.6001\n",
      "Epoch 28 Batch 2200 Loss 1.9169 Accuracy 0.6002\n",
      "Epoch 28 Batch 2250 Loss 1.9176 Accuracy 0.6001\n",
      "Epoch 28 Batch 2300 Loss 1.9172 Accuracy 0.6002\n",
      "Epoch 28 Batch 2350 Loss 1.9176 Accuracy 0.6002\n",
      "Epoch 28 Batch 2400 Loss 1.9181 Accuracy 0.6001\n",
      "Epoch 28 Batch 2450 Loss 1.9180 Accuracy 0.6001\n",
      "Epoch 28 Batch 2500 Loss 1.9182 Accuracy 0.6001\n",
      "Epoch 28 Batch 2550 Loss 1.9179 Accuracy 0.6002\n",
      "Epoch 28 Batch 2600 Loss 1.9181 Accuracy 0.6002\n",
      "Epoch 28 Loss 1.9178 Accuracy 0.6002\n",
      "Time taken for 1 epoch: 163.07657623291016 secs\n",
      "\n",
      "Epoch 29 Batch 0 Loss 1.9113 Accuracy 0.5841\n",
      "Epoch 29 Batch 50 Loss 1.8989 Accuracy 0.6022\n",
      "Epoch 29 Batch 100 Loss 1.9024 Accuracy 0.6005\n",
      "Epoch 29 Batch 150 Loss 1.9020 Accuracy 0.6017\n",
      "Epoch 29 Batch 200 Loss 1.9021 Accuracy 0.6018\n",
      "Epoch 29 Batch 250 Loss 1.9013 Accuracy 0.6018\n",
      "Epoch 29 Batch 300 Loss 1.9020 Accuracy 0.6018\n",
      "Epoch 29 Batch 350 Loss 1.9024 Accuracy 0.6020\n",
      "Epoch 29 Batch 400 Loss 1.9031 Accuracy 0.6017\n",
      "Epoch 29 Batch 450 Loss 1.9069 Accuracy 0.6010\n",
      "Epoch 29 Batch 500 Loss 1.9065 Accuracy 0.6010\n",
      "Epoch 29 Batch 550 Loss 1.9070 Accuracy 0.6011\n",
      "Epoch 29 Batch 600 Loss 1.9051 Accuracy 0.6017\n",
      "Epoch 29 Batch 650 Loss 1.9048 Accuracy 0.6017\n",
      "Epoch 29 Batch 700 Loss 1.9036 Accuracy 0.6017\n",
      "Epoch 29 Batch 750 Loss 1.9037 Accuracy 0.6017\n",
      "Epoch 29 Batch 800 Loss 1.9055 Accuracy 0.6016\n",
      "Epoch 29 Batch 850 Loss 1.9053 Accuracy 0.6016\n",
      "Epoch 29 Batch 900 Loss 1.9061 Accuracy 0.6015\n",
      "Epoch 29 Batch 950 Loss 1.9069 Accuracy 0.6014\n",
      "Epoch 29 Batch 1000 Loss 1.9067 Accuracy 0.6015\n",
      "Epoch 29 Batch 1050 Loss 1.9061 Accuracy 0.6016\n",
      "Epoch 29 Batch 1100 Loss 1.9061 Accuracy 0.6016\n",
      "Epoch 29 Batch 1150 Loss 1.9056 Accuracy 0.6017\n",
      "Epoch 29 Batch 1200 Loss 1.9056 Accuracy 0.6017\n",
      "Epoch 29 Batch 1250 Loss 1.9063 Accuracy 0.6015\n",
      "Epoch 29 Batch 1300 Loss 1.9062 Accuracy 0.6015\n",
      "Epoch 29 Batch 1350 Loss 1.9063 Accuracy 0.6016\n",
      "Epoch 29 Batch 1400 Loss 1.9059 Accuracy 0.6016\n",
      "Epoch 29 Batch 1450 Loss 1.9063 Accuracy 0.6015\n",
      "Epoch 29 Batch 1500 Loss 1.9067 Accuracy 0.6015\n",
      "Epoch 29 Batch 1550 Loss 1.9070 Accuracy 0.6014\n",
      "Epoch 29 Batch 1600 Loss 1.9067 Accuracy 0.6015\n",
      "Epoch 29 Batch 1650 Loss 1.9068 Accuracy 0.6015\n",
      "Epoch 29 Batch 1700 Loss 1.9068 Accuracy 0.6016\n",
      "Epoch 29 Batch 1750 Loss 1.9066 Accuracy 0.6015\n",
      "Epoch 29 Batch 1800 Loss 1.9071 Accuracy 0.6015\n",
      "Epoch 29 Batch 1850 Loss 1.9079 Accuracy 0.6014\n",
      "Epoch 29 Batch 1900 Loss 1.9081 Accuracy 0.6014\n",
      "Epoch 29 Batch 1950 Loss 1.9080 Accuracy 0.6015\n",
      "Epoch 29 Batch 2000 Loss 1.9079 Accuracy 0.6015\n",
      "Epoch 29 Batch 2050 Loss 1.9079 Accuracy 0.6015\n",
      "Epoch 29 Batch 2100 Loss 1.9080 Accuracy 0.6014\n",
      "Epoch 29 Batch 2150 Loss 1.9080 Accuracy 0.6014\n",
      "Epoch 29 Batch 2200 Loss 1.9081 Accuracy 0.6014\n",
      "Epoch 29 Batch 2250 Loss 1.9084 Accuracy 0.6014\n",
      "Epoch 29 Batch 2300 Loss 1.9087 Accuracy 0.6014\n",
      "Epoch 29 Batch 2350 Loss 1.9083 Accuracy 0.6014\n",
      "Epoch 29 Batch 2400 Loss 1.9086 Accuracy 0.6014\n",
      "Epoch 29 Batch 2450 Loss 1.9083 Accuracy 0.6015\n",
      "Epoch 29 Batch 2500 Loss 1.9078 Accuracy 0.6016\n",
      "Epoch 29 Batch 2550 Loss 1.9080 Accuracy 0.6015\n",
      "Epoch 29 Batch 2600 Loss 1.9085 Accuracy 0.6014\n",
      "Epoch 29 Loss 1.9086 Accuracy 0.6014\n",
      "Time taken for 1 epoch: 164.11253333091736 secs\n",
      "\n",
      "Epoch 30 Batch 0 Loss 2.1313 Accuracy 0.5661\n",
      "Epoch 30 Batch 50 Loss 1.8886 Accuracy 0.6047\n",
      "Epoch 30 Batch 100 Loss 1.8944 Accuracy 0.6044\n",
      "Epoch 30 Batch 150 Loss 1.8900 Accuracy 0.6053\n",
      "Epoch 30 Batch 200 Loss 1.8893 Accuracy 0.6050\n",
      "Epoch 30 Batch 250 Loss 1.8908 Accuracy 0.6046\n",
      "Epoch 30 Batch 300 Loss 1.8897 Accuracy 0.6047\n",
      "Epoch 30 Batch 350 Loss 1.8890 Accuracy 0.6047\n",
      "Epoch 30 Batch 400 Loss 1.8933 Accuracy 0.6040\n",
      "Epoch 30 Batch 450 Loss 1.8960 Accuracy 0.6034\n",
      "Epoch 30 Batch 500 Loss 1.8976 Accuracy 0.6032\n",
      "Epoch 30 Batch 550 Loss 1.8986 Accuracy 0.6030\n",
      "Epoch 30 Batch 600 Loss 1.8991 Accuracy 0.6030\n",
      "Epoch 30 Batch 650 Loss 1.8998 Accuracy 0.6027\n",
      "Epoch 30 Batch 700 Loss 1.8997 Accuracy 0.6027\n",
      "Epoch 30 Batch 750 Loss 1.9005 Accuracy 0.6026\n",
      "Epoch 30 Batch 800 Loss 1.9009 Accuracy 0.6026\n",
      "Epoch 30 Batch 850 Loss 1.8995 Accuracy 0.6029\n",
      "Epoch 30 Batch 900 Loss 1.8989 Accuracy 0.6031\n",
      "Epoch 30 Batch 950 Loss 1.8987 Accuracy 0.6032\n",
      "Epoch 30 Batch 1000 Loss 1.8976 Accuracy 0.6035\n",
      "Epoch 30 Batch 1050 Loss 1.8980 Accuracy 0.6034\n",
      "Epoch 30 Batch 1100 Loss 1.8985 Accuracy 0.6033\n",
      "Epoch 30 Batch 1150 Loss 1.8987 Accuracy 0.6033\n",
      "Epoch 30 Batch 1200 Loss 1.8986 Accuracy 0.6033\n",
      "Epoch 30 Batch 1250 Loss 1.8998 Accuracy 0.6031\n",
      "Epoch 30 Batch 1300 Loss 1.8998 Accuracy 0.6030\n",
      "Epoch 30 Batch 1350 Loss 1.9000 Accuracy 0.6030\n",
      "Epoch 30 Batch 1400 Loss 1.8994 Accuracy 0.6032\n",
      "Epoch 30 Batch 1450 Loss 1.8989 Accuracy 0.6032\n",
      "Epoch 30 Batch 1500 Loss 1.8996 Accuracy 0.6031\n",
      "Epoch 30 Batch 1550 Loss 1.8990 Accuracy 0.6032\n",
      "Epoch 30 Batch 1600 Loss 1.8991 Accuracy 0.6032\n",
      "Epoch 30 Batch 1650 Loss 1.8993 Accuracy 0.6032\n",
      "Epoch 30 Batch 1700 Loss 1.8992 Accuracy 0.6031\n",
      "Epoch 30 Batch 1750 Loss 1.8996 Accuracy 0.6031\n",
      "Epoch 30 Batch 1800 Loss 1.9002 Accuracy 0.6030\n",
      "Epoch 30 Batch 1850 Loss 1.9005 Accuracy 0.6029\n",
      "Epoch 30 Batch 1900 Loss 1.9001 Accuracy 0.6030\n",
      "Epoch 30 Batch 1950 Loss 1.8995 Accuracy 0.6030\n",
      "Epoch 30 Batch 2000 Loss 1.8998 Accuracy 0.6031\n",
      "Epoch 30 Batch 2050 Loss 1.9002 Accuracy 0.6030\n",
      "Epoch 30 Batch 2100 Loss 1.9008 Accuracy 0.6029\n",
      "Epoch 30 Batch 2150 Loss 1.9007 Accuracy 0.6030\n",
      "Epoch 30 Batch 2200 Loss 1.9011 Accuracy 0.6029\n",
      "Epoch 30 Batch 2250 Loss 1.9012 Accuracy 0.6029\n",
      "Epoch 30 Batch 2300 Loss 1.9012 Accuracy 0.6029\n",
      "Epoch 30 Batch 2350 Loss 1.9013 Accuracy 0.6029\n",
      "Epoch 30 Batch 2400 Loss 1.9020 Accuracy 0.6028\n",
      "Epoch 30 Batch 2450 Loss 1.9018 Accuracy 0.6028\n",
      "Epoch 30 Batch 2500 Loss 1.9015 Accuracy 0.6028\n",
      "Epoch 30 Batch 2550 Loss 1.9014 Accuracy 0.6028\n",
      "Epoch 30 Batch 2600 Loss 1.9015 Accuracy 0.6028\n",
      "Saving checkpoint for epoch 30 at ./checkpoints/train/ckpt-6\n",
      "Epoch 30 Loss 1.9017 Accuracy 0.6027\n",
      "Time taken for 1 epoch: 163.43971514701843 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  \n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  # inp -> portuguese, tar -> english\n",
    "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "    train_step(inp, tar)\n",
    "    \n",
    "    if batch % 50 == 0:\n",
    "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "      \n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfcsSWswSdGV"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6APsFrgImLW"
   },
   "source": [
    "Для оценки используются следующие шаги:\n",
    "\n",
    "Закодируйте входное предложение с помощью русского токенизатора ( tokenizer_pt ). Кроме того, добавьте начальный и конечный токены, чтобы ввод был эквивалентен тому, с чем обучается модель. Это вход энкодера.\n",
    "Вход декодера - это start token == tokenizer_en.vocab_size .\n",
    "Рассчитайте маски заполнения и маски прогнозирования.\n",
    "Затем decoder выводит прогнозы, глядя на encoder output и собственные выходные данные (самовнимание).\n",
    "Выберите последнее слово и вычислите его argmax.\n",
    "Конкатентируйте предсказанное слово на вход декодера при передаче его в декодер.\n",
    "В этом подходе декодер предсказывает следующее слово на основе предсказанных им предыдущих слов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1677595714612,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "5buvMlnvyrFm"
   },
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "  start_token = [tokenizer_ru.vocab_size]\n",
    "  end_token = [tokenizer_ru.vocab_size + 1]\n",
    "  \n",
    "  # inp sentence is portuguese, hence adding the start and end token\n",
    "  inp_sentence = start_token + tokenizer_ru.encode(inp_sentence) + end_token\n",
    "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "  decoder_input = [tokenizer_en.vocab_size]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "  for i in range(MAX_LENGTH):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "    if predicted_id == tokenizer_en.vocab_size+1:\n",
    "      return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1677595714613,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "CN-BV43FMBej"
   },
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "  fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "  sentence = tokenizer_ru.encode(sentence)\n",
    "  \n",
    "  attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "  for head in range(attention.shape[0]):\n",
    "    ax = fig.add_subplot(2, 4, head+1)\n",
    "    \n",
    "    # plot the attention weights\n",
    "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 10}\n",
    "    \n",
    "    ax.set_xticks(range(len(sentence)+2))\n",
    "    ax.set_yticks(range(len(result)))\n",
    "    \n",
    "    ax.set_ylim(len(result)-1.5, -0.5)\n",
    "        \n",
    "    ax.set_xticklabels(\n",
    "        ['<start>']+[tokenizer_ru.decode([i]) for i in sentence]+['<end>'], \n",
    "        fontdict=fontdict, rotation=90)\n",
    "    \n",
    "    ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                        if i < tokenizer_en.vocab_size], \n",
    "                       fontdict=fontdict)\n",
    "    \n",
    "    ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1677595714614,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "lU2_yG_vBGza"
   },
   "outputs": [],
   "source": [
    "def translate(sentence, plot='decoder_layer4_block2'):\n",
    "  result, attention_weights = evaluate(sentence)\n",
    "  # print(attention_weights)\n",
    "  \n",
    "  predicted_sentence = tokenizer_en.decode([i for i in result \n",
    "                                            if i < tokenizer_en.vocab_size])  \n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "  if plot:\n",
    "    plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5m_4DBHaV7-"
   },
   "source": [
    "После 15-ти эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "executionInfo": {
     "elapsed": 3282,
     "status": "error",
     "timestamp": 1677595717879,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "QHzndZ1xNHKn",
    "outputId": "1fdf2c3f-4dc5-4730-db6c-0c9c7a9d6d92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Осенним вечером шёл дождь!\n",
      "Predicted translation: the eduard was raining .\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-ef1ec48eb702>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Осенним вечером шёл дождь!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-e48162765f0c>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(sentence, plot)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mplot_attention_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-e8a0b767726b>\u001b[0m in \u001b[0;36mplot_attention_weights\u001b[0;34m(attention, sentence, result, layer)\u001b[0m\n\u001b[1;32m     23\u001b[0m         fontdict=fontdict, rotation=90)\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n\u001b[0m\u001b[1;32m     26\u001b[0m                         if i < tokenizer_en.vocab_size], \n\u001b[1;32m     27\u001b[0m                        fontdict=fontdict)\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineStyles\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# First, the two-char styles.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlinestyle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_set_ticklabels\u001b[0;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1796\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Derived must override'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mpan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumsteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1799\u001b[0m         \u001b[0;34m\"\"\"Pan by *numsteps* (can be positive or negative).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumsteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[0;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1718\u001b[0m             \u001b[0;31m# if it is Text, get label content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1720\u001b[0;31m                 \u001b[0mget_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1721\u001b[0m             \u001b[0;31m# otherwise add the label to the list directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1722\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (10), usually from a call to set_ticks, does not match the number of ticklabels (9)."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAN0AAADSCAYAAADOksXPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUxElEQVR4nO3deZxdZX3H8c83k40sEISEgoBEQFZBIoostQqioCIqYqFiWxTjqy0VUauW2qJWW6tg64paFq0oFjC4VVlVEF8YIAuBsAkCQkQTZAshZJl8+8dzJtxMZjLn3HPPM5M7v/frdV9z75n7POc3d87vnuVZjmwTQshnzHAHEMJoE0kXQmaRdCFkFkkXQmaRdCFkFkkXQmaRdCFkFkkXQmaRdCFkljXplHxP0l451xvCSJJ7T/dq4CXAKZnXG8KIkTvp3klKuGMkjc287hBGhGxJJ2lbYB/bPwGuBt6Ya90hjCQ593RvBy4qnl9AHGKGzZikN0ma0k7ZnEn3DlKyYfsmYHtJO2VcfwgdIWlX4GLgpHbKZ0k6SdOAL9pe0rL4A8C2OdYfQoedDPwHaUdSWZaks/04cFu/ZVcBk3KsP4ROkdQDHE9Kuick7V+1jpyHl18ouSyEkey1wK9sLwfOJ12Rr6Txy/aSDgYOAaZLel/Lr7YEeppef7eQtA3wUeBQwMD1wMdt/3E44xqF3gl8tnh+GfAJSR+wvbpsBTn2dOOBKaQEn9ryeBJ4S4b1d4vvAEuB40if2zLgf4c1og6QNEvSy4smpRGtuDYxzfZ1ALafAS4FDq9UT46JiYrj4IttH9f4yrqUpNts79tv2a22XzhcMVUl6fP9FwFvBT4GXGH73vxR5ZelV4jtXkk75FhXF7tS0gmkS9WQ9nZXDGM87TgW+Jd+y46x/eXhCKYKSbM29Xvb80vXlWsKPknnAM8FLgFW9C23PSdLAJs5ScuBycA60jldD89+jra95XDFVpak+bZn9Vu2wPYBwxVTWZJ+VjydCBwI3ELaU+8H3Gz74LJ15ez/OBH4Ixse/xqIpCvB9tThjqEDdpd0NfAo8BDwI9KGO+LZfiWApDnALNu3Fq/3JV3gKi3bni7UI0nA24CZtv+16M2zve0bhzm00iS9mLSHngLMJF0Ueg2wC/CI7ZXDF105khbb3meoZZusI+Ph5UTS5dZ9SHs9AGy31ao/2hSH5+uAw23vJWlr4ErbLxnm0GqR9GlSz6Rziu6BI5qki0iH9RcWi94GTLF9Ytk6ch5efhO4k/TN9nFSsHdkXP/m7iDbsyQtALD9mKTxuVYuaVH/RSkM71ehjgm2V/Vb/APb19cOMJ+Tgb8BTiteXwecU6WCnEm3m+3jJR1r+xuSvg38IuP6h42k8wdaXnEvv6ZoenFR53TSni+XHlJvjDqukHS87WVFu9xZwHbA0bWjy6Rom/vP4tGWnEm3pvj5eHHy+XtgRsb1D6fXAA+Q9vZL26zj86QeEDMkfZLUZPCRzoRXylrgcWBVseG14yPA5ZIuBU4APmH7kg7Fl4WkQ0kXTp5HS/7Yfn7pOjKe050CfBd4IfB10sn0P9v+apYAhpGkMcBRpDGFPcAFxWDeqvXsCRxBOrS7xna2w3NJ9xfrnVT8vAF4b9UGbUnPB35I6sK22fWokXQncDowD+jtW16lO17OpJtp+76hlo1Ukl4+0PK+LkEl69gb+CAw3fbrKq7/OYOs/9Eq9XSCpAmknvbvtv2nFcrdSjo8ngrsSHFOX+W8cLhJmmv7oFp1ZEy6gRpG59l+cZYAapL0w+LpYaRz0b4LCW8oUXY2aXqKe0h7uQVtrP8+0gYrYHvg4WL9pQ9rOk3SG21/r8L7nweMI40uuRf4DIDtBxoJsAGSPkU6WpkDrL8oVKVHSo5RBnuSmgm2kvTmll9tSUvTwUhn+xhY34NiyETr5yukhNsJeEVqcqv2DW97Zt/z4ejFIWkS8H5gZ9vvkrQ76TyvisdIPZKmAlsBT9te1tlIG9e3lzuwZZmp0Ok5x4WUPYDXA9OAY1qWLwfelWH9ndbOocHMod9STtFMkLOp4Gu2Z5Om2pgH9HV3WkJKoB9VqO5q4KO2f1x8AV8j6au2v9TRoBvU1zOljsaTzvb3ge9LOtj2DU2vryktYwFntI4LtP3ZQYq0Wt6B9fcd3u4FfLuN8u02W/T9fbva/nNJJxblnlbfLru8U2wvKsrPkXQFG3eAHtEkbQf8G7CD7aOL8/SDbZ9Xto6cTQZvkrQYWAlcTuooerrtCzddbMTo6/v43y3Py3oE+APpb+/bUA1UOR87i9Qu91CbF5/abbb4OGn4zWpJW/BsO+GutJzTlGF7UbHR9vWiudH2h6rUMQJ8nbTX/6fi9d2kcY2lkw7bWR7AwuLnm4oAtwJuqVBeNddfq3xLPZPaKHMKcBPwd8DYGus+DDi5eD6d1A+zbNkxpMbti0jDg44uWW774ueRwLWkwbPfAu4HXlEx/reSEv8bwP8A9wFvybUNduj/f1Pxc0HLsoWV6sgY7OLi57nAUcXzUkkHbAFcBbynzXXXKl/UcTBwO/Db4vX+wJcrlJ8AvA+YC7ytjfWfSWrfurt4vQPwyzbq2Zv0bf1/bZTdBngd6Rx92zbK3wLMaHk9vcoX70h4AD8vPof5xeuXAddWqiNjsJ8i9b1cQLpsPB2YW6LcRNIJ+DpSY+TpFddbq3xLPXNJVx8XtCy7rWTZN7c8TgYWVd3YgIWkQ9PW9S+qUH428GNSz5YD2vj79x7oUbGOW/u9HtN/2Uh/ALOAXwJPFD/vBvarUke2czrbHy56lD/hNJL8adJI4kEV5xBfJG1svaT2kbMkjbX9maHWWbf8AH/Dg/2uHfQO9t5+jun3el7VdQOrbVtS3znV5Irl6zZbDNRzaF9g6woxXF5cPOmb6fsE0hfBZsP2fEl/RroqL+Au22uGKLaBLElXtPHsbvuWlsXbsImNthgKdDZwBumK3Vjg+6RDxU8VifPvTZUfwIOSDgEsaRypl3mpbli2T66wnsFcLOmrwDRJ7yJNdHpuhfK1mi08QM8TSZU6rNv+h6Kp4NBi0VeAXkl/STpEG9GN5P2248XFsp0l9XrDiZQ3XU+xy2xUsZHeSdoNryiWXQmcYfvmQd7/Y+AuUmKeStpjnUc6hv4gaTKbGbbP7nT5Qf6GbYHPAa8ifcNdSTpHHLIblqQLGKB9zxXHEko6knS7sWmkw9MvViy/P9CXPL/o9yVYmaTrbA/YPW6Q9/+g72nL4sNIw7zm2/59hbp2B8bZvr1smbqqbseDyTUx0RpJl5GuXl0gaWdS/8MBAy3efzNpF76A9E86FXgl6RtmKil5BpzqoW75QZwNnGr7MYBiEOnZlJtau68B+dOkhK9M0meAvyIl/muBgyTtavv0kuVPI3VG6PubLywavktN+Ks0R0vrF4eo3qNoLza8cYyAPW1XOsSUdAbps1gh6dqyn0FdVbfjTVWU6wR0T+C64vlHKHElkTSE4pOkiyB9j17gKeCIpsv3q2tBmWVV66hQ9h7SUKjHSBt7D8UV4ZLlFwGTW15PpsKFmEHq/EXF988vs6xMPaTTBFFcws/1aGc77v/INq267TtJU328gHQC/c0SZT7Kho3JkBqYj7F9TdPl+xlT7N2A9b3+qx4p1DmWf9L2UuB+28/Y7qVa43TfxaQ+vdSfFKjq37OPpHsk3ShpjqR30Gb/W9srnbb8rPOqtLMd95f7bqjnkU7+b3VxmDYU22cU3Y0+RNpDHWP72rIrrFu+xdnADZL6Bl0eT9qLDqllSMtuStMeVJ7qANizKNtaR5UeLRcAc4vDI0ijHkr3omj5G9YvIk0oVMUObDgx0fHAHsWwqdttP1IyhtbPoFQM2nBKf+DZLnySTnK1nlGVt+MNYil2k1kUV38eBo6zfXXFsmcCP7Xd1hQPdcsXdezNs73Jf+qSJ/HFkJaNuMLVug7VMYt04QLSoWHpIUadWP8g9f4tqc32kqE+zzoxFP///uU+Vvzu3a4wmLrOdgyZky6EkPdWWSEEIulCyG5Ykq6YviDKb8YxjPbydeoYrj1d3T94tJcfCTGM9vJt1xGHlyFk1sjVy/Ga4IkM3gl+DasYx4RBf/+C/Z7eZP3L/tjL9G0Gv3Pyr2+bssnyq/0M47XpNlmvG3zy5KHiH0rd8iMhhtFevkwdz7CC1V61UQeERhrHJzKZg3RE2+WvuGJhrfUfvdshtcoDrFtZs6NDNMVA5SlU+tnMP8O5g3R6isPLEDKLpAshs1JJJ+koSXcVnVU/3HRQIXSzIZNO6fZMXyLdzmhv4MSiD2IIoQ1l9nQvBe6x/Rvbq4HvMMTcJiGEwZVJuucCD7a8fqhYFkJoQ8eaDIouMbMBJjKpU9WG0HXK7OmWkKZt67NjsWwDtr9m+0DbB9ZtdAyhm5VJupuA3SXNVLpjzAnAD4YoE0IYxJCHl7bXSjoVuII01P5824sbjyyELlXqnM5pirTNaibeEEaq6JESQmaRdCFklnsKvjzq9m6Hzb6Hexi5Yk8XQmaRdCFkFkkXQmaRdCFkVmZoz/mSlkq6LUdAIXS7Mnu6rwNHNRxHCKPGkEln+zpgyLuNhhDKiXO6EDKL8XQhZNaxPV2MpwuhnDi8DCGzMk0GFwE3kG5T+5CkdzYfVgjdq8wg1hNzBBLCaBGHlyFkFkkXQmaNjKdbt/t4Vn5pZtvlj96tXpPDmBnb1CqfKqn3feSad/3xunrj+TSu/r/Wq1bVrGB4xyRqbP3PQHvv1n7Zu3854PLY04WQWSRdCJlF0oWQWSRdCJmVaRzfSdLPJN0uabGk03IEFkK3KnN5Zy3wftvzJU0F5km6yvbtDccWQlcqM57uYdvzi+fLgTuIW2WF0LZK53SSdgEOAOY2Ek0Io0DppJM0Bfgu8F7bTw7w+9mSbpZ089on6jUMh9DNSiWdpHGkhPuW7TkDvad1PN3YrbboZIwhdJUyVy8FnAfcYfuzzYcUQncrs6c7FHg7cLikhcXjtQ3HFULXKjOe7nqgA3fkCCFA9EgJIbtIuhAyi6QLIbNGBrGuXTGOpXP/pO3yu/T+rtb6vaJ+O6G227ZW+TGr1tQqv27ZI7XKa8fta5UHWPfAklrlvbbeZ6Cx4+qV7xmZ+5SRGVUIXSySLoTMIulCyCySLoTMynQDmyjpRkm3FINYP5YjsBC6VZmrl6uAw20/VXR8vl7ST2z/quHYQuhKZbqBGXiqeDmueAzvhIYhbMbKDu3pkbQQWApcZXujQayt4+l6V6zocJghdI9SSWe71/aLgB2Bl0rad4D3rB9P1zN5cofDDKF7VLp6aftx4GfAUY1EE8IoUObq5XRJ04rnWwBHAnc2HFcIXavM1cvtgW9I6iEl6cW2f9RsWCF0rzJXLxeRZgALIXRA9EgJIbNIuhAya2Q83diV8JzF7bef170ZoZcvr1UeQGtW1yr/+Kv3qlV+yiX1xrKt2H9GrfIAk++9v14FNW8KWffGlhpfbzwegB6tsS2t7R1wcezpQsgski6EzCLpQsgski6EzKrcQKRH0gJJ0TAeQg1V9nSnke5NF0KooezQnh2B1wHnNhtOCN2v7J7uv4APAuuaCyWE0aHMKIPXA0ttzxvifesHsa5ZFYNYQxhM2VtlvUHS/cB3SLfMurD/m1oHsY6bEINYQxjMkEln+x9t72h7F+AE4Ke2T2o8shC6VLTThZBZpR6ltn8O/LyRSEIYJWJPF0JmkXQhZCbXHPM0kC31HB805lVtl1/y3b1rrX/nf6o3Fg6g945f165jc6dx42uVf+rYerN8TL50o+lVNytzfQ1P+lH1Xx57uhAyi6QLIbNIuhAyi6QLIbNS7XRFF7DlQC+w1vaBTQYVQjer0jj+StuPNBZJCKNEHF6GkFnZpDNwpaR5kmY3GVAI3a7s4eVhtpdImgFcJelO29e1vqFIxtkAE5nU4TBD6B5lbwq5pPi5FLgMeOkA73l2PB0TOhtlCF2kzMjxyZKm9j0HXg3c1nRgIXSrMoeX2wGXSep7/7dtX95oVCF0sTL3p/sNsH+GWEIYFaLJIITMIulCyKyR+9MBoPbzeesLp9Rb95ql9coDaKNhUNU0ME4xN/XU+05+/C+eqlV+8qW1io9YsacLIbNIuhAyi6QLIbNIuhAyK3vXnmmSLpV0p6Q7JB3cdGAhdKuyVy8/B1xu+y2SxkP0aA6hXUMmnaStgJcDfw1gezVQf467EEapMoeXM4FlwAXF7Y/PLTo+hxDaUCbpxgKzgHNsHwCsAD7c/00b3J+OVR0OM4TuUSbpHgIest033e6lpCTcQIynC6GcMven+z3woKQ9ikVHALc3GlUIXazs1cu/B75VXLn8DXBycyGF0N1KJZ3thUDMdRlCB0SPlBAyi6QLIbNIuhAya2QQ67ppk1j5ihe3XX7SnHo3A+ytOwAVag3CBcC9tYqPmTq13upXrqxVPgVR7zPY6e331yrvsfU2z5VHbdSyVdmy/duPYfV5vxpweezpQsgski6EzCLpQsiszAzPe0ha2PJ4UtJ7M8QWQlcqM9nsXcCLACT1AEtI9zMIIbSh6uHlEcC9th9oIpgQRoOqSXcCcFETgYQwWpROuqKz8xuASwb5/frxdGtXrehUfCF0nSp7uqOB+bb/MNAvW8fTjZ0QA8tDGEyVpDuROLQMobayU/BNBo4E5jQbTgjdr+x4uhXANg3HEsKoED1SQsgski6EzCLpQsiskfF0PSvWMHXekrbLr60bQCduyFhzPFzPtK1qle99st4NFZ86rv6UNlv+8JZa5dc980yt8j3bzahV/neH9dQqD/CCL9zfdtmHHxl4IvTY04WQWSRdCJlF0oWQWdnG8dMlLZZ0m6SLJE1sOrAQulWZQazPBd4DHGh7X6CHNNoghNCGsoeXY4EtJI0l3RDyd82FFEJ3K3MDkSXAWcBvgYeBJ2xf2XRgIXSrMoeXWwPHkm4OuQMwWdJJA7xv/Xi61es6MOdiCF2qzOHlq4D7bC+zvYY00uCQ/m9qHU83fswWnY4zhK5RJul+C7xM0iRJIs2TckezYYXQvcqc080l3X11PnBrUeZrDccVQtcqO57uTODMhmMJYVSIHikhZBZJF0JmkXQhZCZ3YuxZ/0qlZcCmZoHeFnikxipGe/mREMNoL1+mjufZnr7RUtvZH8DNUT4+w825fJ064vAyhMwi6ULIbLiSrm7j+mgvPxJiGO3l266jkQspIYTBxeFlCJlF0oWQWSRdCJlF0oWQWSRdCJn9P1chqD/7/lukAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('Осенним вечером шёл дождь!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "executionInfo": {
     "elapsed": 2859,
     "status": "error",
     "timestamp": 1677598990089,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "oAMWA3xvCuDi",
    "outputId": "82816340-5cab-4363-c57f-c15879533139"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: он собирается домой\n",
      "Predicted translation: he gathers home .\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-919a9c75cc67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'он собирается домой'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-e48162765f0c>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(sentence, plot)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mplot_attention_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-e8a0b767726b>\u001b[0m in \u001b[0;36mplot_attention_weights\u001b[0;34m(attention, sentence, result, layer)\u001b[0m\n\u001b[1;32m     23\u001b[0m         fontdict=fontdict, rotation=90)\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n\u001b[0m\u001b[1;32m     26\u001b[0m                         if i < tokenizer_en.vocab_size], \n\u001b[1;32m     27\u001b[0m                        fontdict=fontdict)\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineStyles\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# First, the two-char styles.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlinestyle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_set_ticklabels\u001b[0;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1796\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Derived must override'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mpan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumsteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1799\u001b[0m         \u001b[0;34m\"\"\"Pan by *numsteps* (can be positive or negative).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumsteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[0;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1718\u001b[0m             \u001b[0;31m# if it is Text, get label content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1720\u001b[0;31m                 \u001b[0mget_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1721\u001b[0m             \u001b[0;31m# otherwise add the label to the list directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1722\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (6), usually from a call to set_ticks, does not match the number of ticklabels (5)."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('он собирается домой')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_QhGu_BlhGu"
   },
   "source": [
    "После 30 эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1677598990090,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "vVDReCSWh9ky"
   },
   "outputs": [],
   "source": [
    "translate('Осенним вечером шёл дождь!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "executionInfo": {
     "elapsed": 1872,
     "status": "error",
     "timestamp": 1677598994253,
     "user": {
      "displayName": "Михаил Демин",
      "userId": "14250540086915616791"
     },
     "user_tz": -600
    },
    "id": "jtDIiLQTh9kz",
    "outputId": "5fa63e5b-6324-4a19-a747-964b2b055bb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: он собирается домой\n",
      "Predicted translation: he gathers home .\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-919a9c75cc67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'он собирается домой'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-e48162765f0c>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(sentence, plot)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mplot_attention_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-e8a0b767726b>\u001b[0m in \u001b[0;36mplot_attention_weights\u001b[0;34m(attention, sentence, result, layer)\u001b[0m\n\u001b[1;32m     23\u001b[0m         fontdict=fontdict, rotation=90)\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n\u001b[0m\u001b[1;32m     26\u001b[0m                         if i < tokenizer_en.vocab_size], \n\u001b[1;32m     27\u001b[0m                        fontdict=fontdict)\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineStyles\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# First, the two-char styles.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlinestyle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_set_ticklabels\u001b[0;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1796\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Derived must override'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mpan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumsteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1799\u001b[0m         \u001b[0;34m\"\"\"Pan by *numsteps* (can be positive or negative).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumsteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[0;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1718\u001b[0m             \u001b[0;31m# if it is Text, get label content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1720\u001b[0;31m                 \u001b[0mget_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1721\u001b[0m             \u001b[0;31m# otherwise add the label to the list directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1722\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (6), usually from a call to set_ticks, does not match the number of ticklabels (5)."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('он собирается домой')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0069794296c54a0680417ff91692d115": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "02cb3d383bcb4187b59e0abd3c13dc8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "072bb88f18154b2fae3d0d1a67d7dbf9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a283e3a6add46b3a19188080c3e3ab8",
      "placeholder": "​",
      "style": "IPY_MODEL_0069794296c54a0680417ff91692d115",
      "value": " 3/3 [00:33&lt;00:00,  7.80s/ splits]"
     }
    },
    "0968600d30b24445880559d6c9e55b28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0bd984b8b5214dae8ee91dc057593385": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cb0a7163a7b4ce8b30fd32f27509b7e",
      "placeholder": "​",
      "style": "IPY_MODEL_e1af616dfbf44288803f43a591cbf31d",
      "value": " 0/5476 [00:00&lt;?, ? examples/s]"
     }
    },
    "10122b47d646469f9442f8618caca701": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b1e1a7b7d2644beac8d12317b3c6cf1",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ea5f172293234d9186007242bd1255ff",
      "value": 1
     }
    },
    "10de753360fa4f33bad5e0e0236b8840": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "12b6d2fb2bc642579b034fb35caa2f97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "1647854dc0dd4188aac4ff8166f0054e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f4a88886f324e7ca8a6bb9614eff7aa",
      "placeholder": "​",
      "style": "IPY_MODEL_2861d02bb55a438c9cd2027524a6a021",
      "value": " 206950/? [00:31&lt;00:00, 13894.79 examples/s]"
     }
    },
    "198500121c8d4e548fa30fb27a61d66d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c37032e90414083ad622ee7a0f67c05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac7eb7b615994d108aa6a18917686575",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_66a8456b82424baca6c7dadaa49c3fde",
      "value": 3
     }
    },
    "1ca03450ffdf48199297e446ed12087f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7e0a3c4299447dfaf89c020deed6ccf",
      "placeholder": "​",
      "style": "IPY_MODEL_73960e406dc24772b0ea3ba64b86bd24",
      "value": "Shuffling /root/tensorflow_datasets/ted_hrlr_translate/ru_to_en/1.0.0.incompleteU089BI/ted_hrlr_translate-validation.tfrecord*...:   0%"
     }
    },
    "1cf4b0c6ef49418caf1b9de0dfba4e71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "21a22c0cf1db4afe8b85c2a98e6b00ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e576cdba3d774476b38ebed2b61a58e6",
       "IPY_MODEL_e81784049f2649598ecb25dbef3b1d9b",
       "IPY_MODEL_cdcc6515657e4d24b0a19b2cf2a0bf4f"
      ],
      "layout": "IPY_MODEL_ca3c765e63cd41daa1827166ed1cb6c5"
     }
    },
    "2454cba57e8f4069b0b93e85d4128cb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "27b34af6e2964f8db01fc7c701acfbad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eaa755782de2433a876a898616058680",
      "placeholder": "​",
      "style": "IPY_MODEL_2454cba57e8f4069b0b93e85d4128cb6",
      "value": " 172362/208106 [00:00&lt;00:00, 361398.80 examples/s]"
     }
    },
    "2861d02bb55a438c9cd2027524a6a021": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2aed024b3eb74c269dbfeb49290e56e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84c26e7728364848854d6f386e86b7b4",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d1bff15c3c6a45fab96db3f29775f576",
      "value": 1
     }
    },
    "2f2f7364c8384e8db8c771d451e3c506": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2f4a88886f324e7ca8a6bb9614eff7aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "330c5ddbe46a4e38bc2e805495092721": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33e29c9596034eaeb9e30304d0771c5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "389902c6621c4903a2fc9cc28a9462d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7afad1c9c72347ec9046e0918373d395",
      "placeholder": "​",
      "style": "IPY_MODEL_8325d355b1914d159fd5a98c2278c1b3",
      "value": " 0/4805 [00:00&lt;?, ? examples/s]"
     }
    },
    "400d07b3cf754a369e73e51d7da0aede": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f86f6a5af4114b639972feca51a596dc",
      "max": 4805,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_547ec8c1c6324a718b332472acf8d80c",
      "value": 4805
     }
    },
    "402eefd4c38947c98bc1f9828415fef8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d977cae912f408e9c0910feefd5fb3d",
      "placeholder": "​",
      "style": "IPY_MODEL_c23f5624ca4f4e258ebb2152724959ff",
      "value": " 124/124 [00:13&lt;00:00, 20.05 MiB/s]"
     }
    },
    "41a0b54f4e404d568a36d122a072650f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af253ca7030b46438bf0e4b4b9c31332",
      "max": 208106,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e6261cf928d740ec90e1e4f03802a3cd",
      "value": 208106
     }
    },
    "4537216e76c443bbb7a91533cd471d31": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49bca3ba670146f2944f0059d4a5996e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "4b3d994eb2f84a61942a5fbb0c1aba6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b4ac4baf39a4e179b00e0ffb2003491": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf8db9d4ca9e41aaa61bc6a3d634f607",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_baf9018a95d34c4c93823b2440f4d5d7",
      "value": 1
     }
    },
    "4d977cae912f408e9c0910feefd5fb3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e332f8efc944611b10922101faa5912": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51f993bd0919435a82ccbccaab4313d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53d4209261ad4e70af7ba03419820055": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "547ec8c1c6324a718b332472acf8d80c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "574fa67d600244219b76d6330ba03294": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ca03450ffdf48199297e446ed12087f",
       "IPY_MODEL_400d07b3cf754a369e73e51d7da0aede",
       "IPY_MODEL_389902c6621c4903a2fc9cc28a9462d0"
      ],
      "layout": "IPY_MODEL_10de753360fa4f33bad5e0e0236b8840"
     }
    },
    "5a283e3a6add46b3a19188080c3e3ab8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60bd47c105bb4e559d195d28de04bc8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edc2628465824b6da1a2d30533ec2b21",
      "placeholder": "​",
      "style": "IPY_MODEL_9a256edddbcd402690c9aab72ea08f77",
      "value": " 5380/? [00:00&lt;00:00, 9917.42 examples/s]"
     }
    },
    "6168334214c541e490c4ba5d938f7a4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba510ab836d44957b63d6a1ceb08149d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_818a059008d04cb092c6c163649edebc",
      "value": 1
     }
    },
    "638e97f3846946e186c04f9c1095e3c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6492c10f01ca403b9a87b7905e4ae7a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_725b8ee7d6394aaf8876cd5d3eee5740",
       "IPY_MODEL_41a0b54f4e404d568a36d122a072650f",
       "IPY_MODEL_27b34af6e2964f8db01fc7c701acfbad"
      ],
      "layout": "IPY_MODEL_7f7fff9736a14c3c9ca53baa792dbbcd"
     }
    },
    "66a8456b82424baca6c7dadaa49c3fde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "66db343ecf5f4ceea10268dffa5b66c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51f993bd0919435a82ccbccaab4313d1",
      "placeholder": "​",
      "style": "IPY_MODEL_d2bdd5457f82497cb8bef321a792a0b3",
      "value": "Generating test examples...: "
     }
    },
    "67cfbc8ab04d4205865409b05fb9c9df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "725b8ee7d6394aaf8876cd5d3eee5740": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c936b834321e4432a2511d0a88b32070",
      "placeholder": "​",
      "style": "IPY_MODEL_b0178c8ffb934c1e9ea9bb808720fa29",
      "value": "Shuffling /root/tensorflow_datasets/ted_hrlr_translate/ru_to_en/1.0.0.incompleteU089BI/ted_hrlr_translate-train.tfrecord*...:  83%"
     }
    },
    "73960e406dc24772b0ea3ba64b86bd24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "769fcd195be6497db071b66c51c04beb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7afad1c9c72347ec9046e0918373d395": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ce640c71d1e4fd09e854a3ac2cb3e35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa8f84b22f0d4aab81fd83a2d383d9c7",
      "placeholder": "​",
      "style": "IPY_MODEL_b96fcb1426be4d76b1c992c8327bb71a",
      "value": "Dl Size...: 100%"
     }
    },
    "7f00f95f20c94794a83e64d86c990e8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_330c5ddbe46a4e38bc2e805495092721",
      "placeholder": "​",
      "style": "IPY_MODEL_0968600d30b24445880559d6c9e55b28",
      "value": "Extraction completed...: 100%"
     }
    },
    "7f7fff9736a14c3c9ca53baa792dbbcd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "8053bc0452664edda8b53c3b803c7136": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf7a853594d64daeb50129eb6e1fb3a7",
      "placeholder": "​",
      "style": "IPY_MODEL_4b3d994eb2f84a61942a5fbb0c1aba6a",
      "value": " 112/112 [00:13&lt;00:00, 17.13 file/s]"
     }
    },
    "807c368799124d4aa81cc6e489861059": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "818a059008d04cb092c6c163649edebc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8325d355b1914d159fd5a98c2278c1b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8327b27a9ed746b1b1e54037dc60e30f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_638e97f3846946e186c04f9c1095e3c2",
      "placeholder": "​",
      "style": "IPY_MODEL_864f18f033f641f2983f55f9906e039b",
      "value": "Generating train examples...: "
     }
    },
    "84c26e7728364848854d6f386e86b7b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "864f18f033f641f2983f55f9906e039b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8af46e271ba04628af052f047d06cf13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02cb3d383bcb4187b59e0abd3c13dc8c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c97931f8652b415cb4894ecf42a80818",
      "value": 1
     }
    },
    "8cb0a7163a7b4ce8b30fd32f27509b7e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cf3457cc9714ec79adb02b610225199": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_66db343ecf5f4ceea10268dffa5b66c4",
       "IPY_MODEL_2aed024b3eb74c269dbfeb49290e56e7",
       "IPY_MODEL_60bd47c105bb4e559d195d28de04bc8f"
      ],
      "layout": "IPY_MODEL_53d4209261ad4e70af7ba03419820055"
     }
    },
    "8e233332962e4ba88ae5dbb9cab7c57e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94beada069b94d8baa1d8c5b321f5edb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "960a9f9023ec4180b943732f4b4ebf67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a256edddbcd402690c9aab72ea08f77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a9d098f0d7e4881b19b91e7ae8efe63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b1e1a7b7d2644beac8d12317b3c6cf1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "a1b88cc9e6ca48c5a997ba53acaba2b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aab35f63459c4545b632a37611a246cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8327b27a9ed746b1b1e54037dc60e30f",
       "IPY_MODEL_10122b47d646469f9442f8618caca701",
       "IPY_MODEL_1647854dc0dd4188aac4ff8166f0054e"
      ],
      "layout": "IPY_MODEL_e0b3ceebe6e149b9a4d745a88c2c8138"
     }
    },
    "ac7eb7b615994d108aa6a18917686575": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ada68a0628784e8b9e8bea348ee8e9fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "af253ca7030b46438bf0e4b4b9c31332": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aff8f76bb80b4037805914bcddb903a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "b0178c8ffb934c1e9ea9bb808720fa29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b13217db84ea4ea08ecfd06162de7f34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7f00f95f20c94794a83e64d86c990e8d",
       "IPY_MODEL_6168334214c541e490c4ba5d938f7a4e",
       "IPY_MODEL_8053bc0452664edda8b53c3b803c7136"
      ],
      "layout": "IPY_MODEL_4537216e76c443bbb7a91533cd471d31"
     }
    },
    "b83a3c1cbec84df7b80ab123a7f1faf1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bf7f083e184f47ddb7bee9b270a50e26",
       "IPY_MODEL_1c37032e90414083ad622ee7a0f67c05",
       "IPY_MODEL_072bb88f18154b2fae3d0d1a67d7dbf9"
      ],
      "layout": "IPY_MODEL_49bca3ba670146f2944f0059d4a5996e"
     }
    },
    "b96fcb1426be4d76b1c992c8327bb71a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba510ab836d44957b63d6a1ceb08149d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "ba970f4409ca42d39f3ab4be715f2324": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d5ebb5979a1e4aebbbdd41c17f1ca5ec",
       "IPY_MODEL_caab20b977a74d9584334c406117853b",
       "IPY_MODEL_0bd984b8b5214dae8ee91dc057593385"
      ],
      "layout": "IPY_MODEL_12b6d2fb2bc642579b034fb35caa2f97"
     }
    },
    "baf9018a95d34c4c93823b2440f4d5d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bf7f083e184f47ddb7bee9b270a50e26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94beada069b94d8baa1d8c5b321f5edb",
      "placeholder": "​",
      "style": "IPY_MODEL_807c368799124d4aa81cc6e489861059",
      "value": "Generating splits...: 100%"
     }
    },
    "c23f5624ca4f4e258ebb2152724959ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c898ecbd94cc4f2bb4ad7d0441a2dd4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ce30224b3e1d4405a7221d51e286fccb",
       "IPY_MODEL_4b4ac4baf39a4e179b00e0ffb2003491",
       "IPY_MODEL_d282fa4be526420089d7e40e1720954f"
      ],
      "layout": "IPY_MODEL_aff8f76bb80b4037805914bcddb903a2"
     }
    },
    "c936b834321e4432a2511d0a88b32070": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c97931f8652b415cb4894ecf42a80818": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c99fdcf7799d45af847eee0b5565304a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca3c765e63cd41daa1827166ed1cb6c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "caab20b977a74d9584334c406117853b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e233332962e4ba88ae5dbb9cab7c57e",
      "max": 5476,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2f2f7364c8384e8db8c771d451e3c506",
      "value": 5476
     }
    },
    "cdcc6515657e4d24b0a19b2cf2a0bf4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_769fcd195be6497db071b66c51c04beb",
      "placeholder": "​",
      "style": "IPY_MODEL_33e29c9596034eaeb9e30304d0771c5a",
      "value": " 1/1 [00:13&lt;00:00,  6.82s/ url]"
     }
    },
    "ce30224b3e1d4405a7221d51e286fccb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67cfbc8ab04d4205865409b05fb9c9df",
      "placeholder": "​",
      "style": "IPY_MODEL_c99fdcf7799d45af847eee0b5565304a",
      "value": "Generating validation examples...: "
     }
    },
    "cf7a853594d64daeb50129eb6e1fb3a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf8db9d4ca9e41aaa61bc6a3d634f607": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "d1bff15c3c6a45fab96db3f29775f576": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d282fa4be526420089d7e40e1720954f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e332f8efc944611b10922101faa5912",
      "placeholder": "​",
      "style": "IPY_MODEL_a1b88cc9e6ca48c5a997ba53acaba2b9",
      "value": " 4204/? [00:00&lt;00:00, 8678.22 examples/s]"
     }
    },
    "d2bdd5457f82497cb8bef321a792a0b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d48da2b6fffd4ba2b9e6095f62048b9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "d5ebb5979a1e4aebbbdd41c17f1ca5ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a9d098f0d7e4881b19b91e7ae8efe63",
      "placeholder": "​",
      "style": "IPY_MODEL_1cf4b0c6ef49418caf1b9de0dfba4e71",
      "value": "Shuffling /root/tensorflow_datasets/ted_hrlr_translate/ru_to_en/1.0.0.incompleteU089BI/ted_hrlr_translate-test.tfrecord*...:   0%"
     }
    },
    "e0b3ceebe6e149b9a4d745a88c2c8138": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "e1af616dfbf44288803f43a591cbf31d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e576cdba3d774476b38ebed2b61a58e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_960a9f9023ec4180b943732f4b4ebf67",
      "placeholder": "​",
      "style": "IPY_MODEL_f9097ae79f88464cbb00ddbb84ff7a7c",
      "value": "Dl Completed...: 100%"
     }
    },
    "e6261cf928d740ec90e1e4f03802a3cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e7e0a3c4299447dfaf89c020deed6ccf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e81784049f2649598ecb25dbef3b1d9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d48da2b6fffd4ba2b9e6095f62048b9a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ada68a0628784e8b9e8bea348ee8e9fa",
      "value": 1
     }
    },
    "ea5f172293234d9186007242bd1255ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eaa755782de2433a876a898616058680": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edc2628465824b6da1a2d30533ec2b21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f337addcdd864668a0287d5c98a8057b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7ce640c71d1e4fd09e854a3ac2cb3e35",
       "IPY_MODEL_8af46e271ba04628af052f047d06cf13",
       "IPY_MODEL_402eefd4c38947c98bc1f9828415fef8"
      ],
      "layout": "IPY_MODEL_198500121c8d4e548fa30fb27a61d66d"
     }
    },
    "f86f6a5af4114b639972feca51a596dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9097ae79f88464cbb00ddbb84ff7a7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa8f84b22f0d4aab81fd83a2d383d9c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
